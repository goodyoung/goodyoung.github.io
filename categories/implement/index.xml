<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Implement - Category - Good Young</title>
        <link>https://goodyoung.github.io/categories/implement/</link>
        <description>Implement - Category - Good Young</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 08 Jul 2024 21:01:50 &#43;0900</lastBuildDate><atom:link href="https://goodyoung.github.io/categories/implement/" rel="self" type="application/rss+xml" /><item>
    <title>[Paper Review]Rich feature hierarchies for accurate object detection and semantic segmentation</title>
    <link>https://goodyoung.github.io/posts/paper/r-cnn/</link>
    <pubDate>Mon, 08 Jul 2024 21:01:50 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/r-cnn/</guid>
    <description><![CDATA[Abstract 최근 몇 년간 Object-Detection 분야가 정체 상태에 있었다. 가장 성능이 좋은 방법론은 low-level image feature와 high-level context를 섞는 것이다. 본 논문에서는 간단하고 확장 가능한 object-algorithm을 제시한다. - 이는 VOC2012에서 SOTA 결과 대비 30%나 향상된 mAP를 보여준다. 본 논문에서는 두가지 방법을 사용한다 - high-capacity cnn을 하위의 region proposal에 적용시킨다 - data가 부족할 때, 사전 학습 된 모델을 도메인 특화 미세 조정을 하면 성능이 크게 향상된다 따라서 region proposal을 cnn과 결합했기 때문에 R-CNN(Regions with CNN features)라고 한다.
Introduction 지난 10년간 visual recognition task에서의 진전은 SIFT와 HOG의 사용에 의존되어 왔다.
둘 다 컴퓨터 비전에서 널리 사용되는 두 가지 이미지 특징 추출 기법이다. SIFT: 다양한 스케일과 회전에 대해 불변인 키포인트와 불변인 특징을 만드는 기법 HOG: 이미지의 지역적인 형태나 외곽선을 표현하는 방법으로, 물체 탐지, 특히 사람 탐지에 사용된다. 2010~2012년가지 소폭적인 개선만 이루어 졌다. AlexNet의 개발로 인하여 CNN이 크게 향상이 되었다. 그 후 Classification이 Detection의 결과에 어느정도의 영향을 미치는지에 대해 관건이었다. 본 논문은 HOG와 같은 기법들과 비교하여 CNN이 Object-Detection 성능을 향상시켰음을 시사한다. 이러한 결과를 얻기 위하여 두가지 문제에 집중하였다. - deep network에서의 localizing object - 작은 크기의 detection data로 높은 capacity model로 훈련하기
classification과는 달리 객체 탐지에서는 localization이 문제이다. 이를 해결하기 위한 방법은 2가지 방법이 있다. - regression problem으로 설정 - 실용적으로 좋지 않다. (30%의 결과가 나온다) - sliding-window detector를 구축 - 본 논문의 CNN은 좀 더 깊은(다섯 개의 CNN layer) layer를 구축하였는데 이는 높은 spatial resolution을 유지하기 어렵다. - 따라서 이는 객체의 정확한 위치를 찾는데 어려움이 있다는 것이고 이 역시 아직 남아있는 과제임을 나타낸다.
대신에 본 논문은 이러한 문제를 recognition using region을 통해 해결하려고 한다. Region-Proposal을 통해 2000개의 카테고리를 만들고 이를 CNN을 사용해 고정적인 길이의 특징 벡터를 추출 한다. 이때 입력되는 이미지의 사이즈도 고정되어야 하기 때문에 아핀 변환 등으로 이미지를 추출한 후 입력으로 사용한다. 그 후 이를 선형 SVM으로 분류한다.
이는 영역의 크기에 상관없이 동일한 크기로 변환이 된다. (Figure 1). 본 논문에서는 이를 Region-Proposal과 CNN을 같이 사용하므로 R-CNN이라고 한다.
두번째의 문제는 라벨 데이터의 부족, 비지도 사전 훈련을 허용. - 지도학습의 미세 조정
ILSVRC인 임의의 큰 데이터로 지도 학습을 한 모델에 PASCAL의 작은 데이터를 domain 특화 미세 조정을 하는 패러다임을 제시한다. 미세조정을 하면서 33%가 올랐다.
Object Detection with R-CNN ]]></description>
</item>
<item>
    <title>[Paper Review]Fully Convolutional Networks for Semantic Segmentation(FCN) &amp; Implement</title>
    <link>https://goodyoung.github.io/posts/paper/fcn/</link>
    <pubDate>Sun, 14 Apr 2024 16:25:24 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/fcn/</guid>
    <description><![CDATA[개요 Semantic Segmentation 문제를 해결하기 위해 제안된 딥러닝 모델인 Fully Convolutional Networks(이하 FCN) 논문 리뷰를 해보려고 한다. Abstract FCN은 convolutional network 자체로 end-to-end 학습, pixels-to-pixels을 훈련을 하고 semantic segmentation에서 state-of-the-art(이하 SOTA)를 달성했다.
이때 나오는 end-to-end 학습이란 독립적인 것이 아니라 하나의 모델에서 작업이 다 끝나고, 모델의 모든 filter들이 학습이 가능한 학습을 하는 학습 방법이라고 생각하면 된다. [그림 1] end-to-end 학습 end-to-end 학습이 아닌 모델인 pattern recognition모델은 사람들이 직접 filter를 설계하여 classifier만 학습을 하는 방법이다. 본 논문의 핵심 아이디어는 임의의 크기인 input과 input과 같은 크기의 output을 생성하는 fully convolutional network를 구축하는 것이다. 또한 기존의 classification networks(AlexNet, VGG net, GoogLeNet)을 통해 transfer learning을 통한 fine-tuning을 진행하였다. 마지막으로 모델의 deep layer에서 얻은 의미(Semantic) 정보와 shallow layer에서 얻은 외관(Appearance)정보를 섞는 skip architecture를 정의하였다. [그림 2] CNN layers Semantic information deep, coarse(굵다) layer
CNN에서 제일 deep한 위치에 있는 layer들이 객체의 외관은 파악하기 힘든 반면에 feature들이 활성화가 된 부분을 보면 의미가 있는 정보를 나타낸다. Appearance information shallow, fine layer
CNN의 첫 번째 layer에 있는 filter들은 보통 edge feature들을 추출하기 때문에 윤곽과 관련된 feature들을 추출한다. Introduction Convolutional networks의 등장으로 인해 classification, local task(object detection, key-point등)와 같은 분야에서 엄청난 발전을 이룰 수 있었다. 이러한 Convolutional networks의 다음 단계는 segmentation을 위한 모든 pixel에 대한 예측이다. 또한 기존의 방법들 (patchwise training, pre-post processing)등의 수고로움을 해결할 수 있다고 나와있다. 이때 설명하는 patchwise training이란 FCN이 나오기 전 segmentation 학습 방법론 이다. [그림 3] Patchwise training Patchwise learning 방식 특정 크기의 patch를 설정 및 CNN input 이때의 input -&gt; CNN에 의해 classification이 된다. 이때 특정 class로 분류가 되었다면, 해당 patch 중앙에 위치한 pixel을 분류된 class로 분류한다. 이 과정을 슬라이딩 윈도우 방식으로 모든 픽셀을 반복한다. 따라서 Patchwise learning의 방법에는 여러 단점이 생기게 된다. 많은 계산량 patch끼리 겹칠 때의 중복 계산의 우려, patch의 크기를 크게할 때 분류가 애매한 상황 patch 크기를 줄여주면 low resolution(해상도가 낮음)의 문제 마지막으로 FCN이 등장하기 전 semantic한 정보와 location한 정보를 어떻게 잘 조합할 지 몰랐다. 이를 해결하기 위해서 skip architecture가 나오게 된다. Fully convolutional networks 이제까진 기존 CNN에 대한 설명과 FCN이 나오기전의 모델들의 단점들을 살펴보며 FCN 모델의 우수성을 추상적으로 설명했다. 이젠 FCN의 알고리즘을 구체적으로 설명 해보려고 한다. Adapting classifiers for dense prediction [그림 4] FC -&gt; Convolutional layers 전형적인 분류 net(LeNet, AlexNet &hellip;)은 FC층 때문에 고정적인 input size와 non-spatial output을 가진다. 입력 이미지의 크기에 비례하여 FC층에 들어가기 위해 flatten되는 neuron의 수가 비례하기 때문에 input size가 고정적이다. 이때 flatten 되기 때문에 이미지의 공간적 정보의 손실이 있게 된다. 따라서 이러한 linear한 FC층을 [그림 1]처럼 Fully Convolutional한 구조로 변경을 하였다. 이로써 모든 layer에 Conv를 적용하여 ground truth를 각 layer의 출력으로부터 얻을 수 있어 forward와 backward가 계산 효율성에서 장점을 얻는다. 또한 단점이었던 공간 정보의 손실이 없어지는 것도 해결하였다. convolutionalization된 층의 resulting map에 해당되는 특정 위치가 특정 patch 상의 CNN 결과랑 같게 된다. 지금까진 FCN구조의 encoder 부분을 설명한 것과 같다. 다음으론 output map(coarse output)으로 부터 dense prediction을 하는 방법을 알아 볼 것 이다. Shift-and-stitch is filter rarefaction dense prediction을 하기 위해 output map을 upscaling을 해야 한다. upscaling을 하기 위한 방법으로 본문에선 shift-and-stitch방법을 고려했다고 나타난다. [그림 5] shift and stitch 그림을 토대로 max pooling을 하고 위치 정보를 저장하여 원래의 이미지 크기로 upscaling이 가능하다. 하지만 계산 비용이 큰 단점이 있게 된다.]]></description>
</item>
</channel>
</rss>
