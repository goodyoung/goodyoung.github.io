<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Implement - Category - Good Young</title>
        <link>https://goodyoung.github.io/categories/implement/</link>
        <description>Implement - Category - Good Young</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 14 Apr 2024 16:25:24 &#43;0900</lastBuildDate><atom:link href="https://goodyoung.github.io/categories/implement/" rel="self" type="application/rss+xml" /><item>
    <title>[Paper Review]Fully Convolutional Networks for Semantic Segmentation(FCN) &amp; Implement</title>
    <link>https://goodyoung.github.io/posts/paper/fcn/</link>
    <pubDate>Sun, 14 Apr 2024 16:25:24 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/fcn/</guid>
    <description><![CDATA[개요 Semantic Segmentation 문제를 해결하기 위해 제안된 딥러닝 모델인 Fully Convolutional Networks(이하 FCN) 논문 리뷰를 해보려고 한다. Abstract FCN은 convolutional network 자체로 end-to-end 학습, pixels-to-pixels을 훈련을 하고 semantic segmentation에서 state-of-the-art(이하 SOTA)를 달성했다.
이때 나오는 end-to-end 학습이란 독립적인 것이 아니라 하나의 모델에서 작업이 다 끝나고, 모델의 모든 filter들이 학습이 가능한 학습을 하는 학습 방법이라고 생각하면 된다. [그림 1] end-to-end 학습 end-to-end 학습이 아닌 모델인 pattern recognition모델은 사람들이 직접 filter를 설계하여 classifier만 학습을 하는 방법이다. 본 논문의 핵심 아이디어는 임의의 크기인 input과 input과 같은 크기의 output을 생성하는 fully convolutional network를 구축하는 것이다. 또한 기존의 classification networks(AlexNet, VGG net, GoogLeNet)을 통해 transfer learning을 통한 fine-tuning을 진행하였다. 마지막으로 모델의 deep layer에서 얻은 의미(Semantic) 정보와 shallow layer에서 얻은 외관(Appearance)정보를 섞는 skip architecture를 정의하였다. [그림 2] CNN layers Semantic information deep, coarse(굵다) layer
CNN에서 제일 deep한 위치에 있는 layer들이 객체의 외관은 파악하기 힘든 반면에 feature들이 활성화가 된 부분을 보면 의미가 있는 정보를 나타낸다. Appearance information shallow, fine layer
CNN의 첫 번째 layer에 있는 filter들은 보통 edge feature들을 추출하기 때문에 윤곽과 관련된 feature들을 추출한다. Introduction Convolutional networks의 등장으로 인해 classification, local task(object detection, key-point등)와 같은 분야에서 엄청난 발전을 이룰 수 있었다. 이러한 Convolutional networks의 다음 단계는 segmentation을 위한 모든 pixel에 대한 예측이다. 또한 기존의 방법들 (patchwise training, pre-post processing)등의 수고로움을 해결할 수 있다고 나와있다. 이때 설명하는 patchwise training이란 FCN이 나오기 전 segmentation 학습 방법론 이다. [그림 3] Patchwise training Patchwise learning 방식 특정 크기의 patch를 설정 및 CNN input 이때의 input -&gt; CNN에 의해 classification이 된다. 이때 특정 class로 분류가 되었다면, 해당 patch 중앙에 위치한 pixel을 분류된 class로 분류한다. 이 과정을 슬라이딩 윈도우 방식으로 모든 픽셀을 반복한다. 따라서 Patchwise learning의 방법에는 여러 단점이 생기게 된다. 많은 계산량 patch끼리 겹칠 때의 중복 계산의 우려, patch의 크기를 크게할 때 분류가 애매한 상황 patch 크기를 줄여주면 low resolution(해상도가 낮음)의 문제 마지막으로 FCN이 등장하기 전 semantic한 정보와 location한 정보를 어떻게 잘 조합할 지 몰랐다. 이를 해결하기 위해서 skip architecture가 나오게 된다. Fully convolutional networks 이제까진 기존 CNN에 대한 설명과 FCN이 나오기전의 모델들의 단점들을 살펴보며 FCN 모델의 우수성을 추상적으로 설명했다. 이젠 FCN의 알고리즘을 구체적으로 설명 해보려고 한다. Adapting classifiers for dense prediction [그림 4] FC -&gt; Convolutional layers 전형적인 분류 net(LeNet, AlexNet &hellip;)은 FC층 때문에 고정적인 input size와 non-spatial output을 가진다. 입력 이미지의 크기에 비례하여 FC층에 들어가기 위해 flatten되는 neuron의 수가 비례하기 때문에 input size가 고정적이다. 이때 flatten 되기 때문에 이미지의 공간적 정보의 손실이 있게 된다. 따라서 이러한 linear한 FC층을 [그림 1]처럼 Fully Convolutional한 구조로 변경을 하였다. 이로써 모든 layer에 Conv를 적용하여 ground truth를 각 layer의 출력으로부터 얻을 수 있어 forward와 backward가 계산 효율성에서 장점을 얻는다. 또한 단점이었던 공간 정보의 손실이 없어지는 것도 해결하였다. convolutionalization된 층의 resulting map에 해당되는 특정 위치가 특정 patch 상의 CNN 결과랑 같게 된다. 지금까진 FCN구조의 encoder 부분을 설명한 것과 같다. 다음으론 output map(coarse output)으로 부터 dense prediction을 하는 방법을 알아 볼 것 이다. Shift-and-stitch is filter rarefaction dense prediction을 하기 위해 output map을 upscaling을 해야 한다. upscaling을 하기 위한 방법으로 본문에선 shift-and-stitch방법을 고려했다고 나타난다. [그림 5] shift and stitch 그림을 토대로 max pooling을 하고 위치 정보를 저장하여 원래의 이미지 크기로 upscaling이 가능하다. 하지만 계산 비용이 큰 단점이 있게 된다.]]></description>
</item>
</channel>
</rss>
