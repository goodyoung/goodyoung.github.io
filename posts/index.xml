<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - Good Young</title>
        <link>https://goodyoung.github.io/posts/</link>
        <description>All Posts | Good Young</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 27 Aug 2025 19:15:17 &#43;0900</lastBuildDate><atom:link href="https://goodyoung.github.io/posts/" rel="self" type="application/rss+xml" /><item>
    <title>[CS236] 9. GANs - 1</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture9/</link>
    <pubDate>Wed, 27 Aug 2025 19:15:17 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture9/</guid>
    <description><![CDATA[개요 이번 포스트에서는 CS236 강의의 8강을 설명한다. 우리는 지금까지 여러 생성 모델들을 배웠다. AutoRegreesive Model, Variational Autoencoder, Normalizing Flow. 이들은 모두 실제 데이터 분포 $p_\text{data}$ 에 제일 가까운 $p_\theta$ 를 찾으려고 했다. 가장 가까운 $\theta$ 를 찾기 위하여 Maximum log-likelihood(MLE)를 학습 목표로 삼았다. 그렇다면, 높은 log-likelihood가 무조건 좋은 품질의 생성을 의미할까? 아니다. likelihood가 낮더라도 sampling의 품질은 꽤 좋을 수 있다. 그래서 이번 lecture에서는 MLE에 기반하지 않는 다양한 종류의 훈련 목적 함수를 알아볼 것이다. 높은 likelihood -&gt; 나쁜 품질은 어떻게 하면 될까? 자세한 내용은 아래 toggle을 확인하면 된다.
높은 likelihood -> 나쁜 품질 예시 아래의 슬라이드를 보면, 99퍼센트의 noise를 추출하는 $p_\theta$ 이지만 높은 차원으로 갈 수록이 모델은 실제 $p_\text{data}$ 를 나타내는 예시를 볼 수 있다. 그렇게 되면 이 모델은 MLE는 매우 좋을 것이며, 샘플의 품질은 매우 나쁠 것이다. 그렇다면 낮은 likelihood -&gt; 좋은 품질은 어떻게 하면 될까? 그 방법은 모델을 overfitting을 하면 된다.
결론적으로 기존과 달리, 우리는 위 그림의 $d(p_\text{data}||p_\theta)$ 의 다른 대안을 알아볼 것이다. Two-Sample Test 그렇다면 어떤 다른 방법이 있을까. 바로 두 개의 분포에서 생성한 결과를 가지고 그 생성한 결과가 서로 같다면 귀무가설(두 분포가 같다)을 받아드리고, 다르다면 기각하는 방식으로 MLE 없이 두 개의 분포 유사도를 측정할 수 있는 Two-Sample Test 방식이 있다. 두 분포가 같음을 측정할 때 만약 두 분포의 평균만 사용한다면, 우리는 분포의 확률조차도 구할 필요가 없는 것이다.
하지만, 통계적으로 고차원의 데이터에서 단지 평균만으로 측정한다면, 올바른 측정이 어렵다. 위와 같이 생각해야할 것들이 많기 때문이다. (단지, 평균만 같아도 두 분포가 같다고 할 수 없는 것(왼쪽 첫번째 그림) 처럼)
그렇다면 자동적으로 이 두 분포의 차이를 어떻게 알까? 방법은 분류기를 학습하는 것이다. (GAN에서 Discriminator 역할) 본질적으로는, 우리가 딥러닝 분류기의 역할은 두(여러) 그룹의 샘플을 구별하고 구분할 수 있는 특징을 자동적으로 분류하는 것이다. 이를 Two-Sample Test에 적용시키겠다는 것이다. Generative Adversarial Network (GAN) Discriminator 1일 때 real, 0일 때 fake 를 구별하는 2진 분류기가 있다고 하자. 그렇게 되면 우리가 사용할 통계량은 이 분류기의 loss일 것이다.(loss가 적으면 잘 구별한다는 것이고, 높으면 구별하기 어렵다는 것으로 해석할 수 있다.) 땨라서 이 분류기의 목표는 이 통계량을 최대화하거나 loss를 최소화하는 것이다. $$ \begin{aligned} \max_{D_\phi} V(p_\theta, D_\phi) &amp;= \mathbb{E_{x \sim p_{\text{data}}}}[\log D_\phi(x)] + \mathbb{E_{x \sim p_\theta}}[\log(1 - D_\phi(x))] \\ &amp;\approx \sum_{x \in S_1} \log D_\phi(x) + \sum_{x \in S_2} \log(1 - D_\phi(x)) \end{aligned} $$
$p_\theta$: Fixed generative model $p_\text{data}$: 데이터 셋 $D_\phi(x)$: Discriminator 이것은 고정된 생성 모델이 있을 때, 분류기의 목적 함수이다. 따라서 오직 분류기의 최적화 관점만 생각해야한다. 이 분류기는 $S1$에 대해서 1(real, 진짜로 인식)로 , $S2$에 대해서 0(fake, 가짜로 인식)로 잘 분류할 수 있게 학습하도록 한다. 이렇기 때문에 $D_\phi(x)$ 의 값은 샘플 $x$ 가 실제 데이터 분포에 속할 확률을 나타내는 것으로 해석할 수 있다. (데이터 분포와 유사하면 1, 아니면 0이기 때문이다.) $$ D_\theta^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_\theta(x)} $$
그래서 위의 Discriminator 식을 최적화 한다면 위와 같은 식으로 표현할 수 있는데, 이는 x가 Discriminator에 들어왔을 때 전체 분포의 확률 중에 실제 데이터 분포일 확률을 나타낸다. 따라서, 만약 $p_\text{data} = p_\theta$ 라면($p_\text{data}$와 $p_\theta$의 분포가 같다면) 값은 1/2이 나올 것이다. Generator 그렇다면 Discriminator를 속이기 위해 Generator ($p_\theta$)를 최적화 하는 방법을 정의해보자. Flow-model 처럼 유사하게 동작하지만, 역변환은 필요 없다. 쉬운 분포 p(z)에서 z를 뽑고 $G_\theta$ 에 넣어 x를 생성하는 것에 초점이 맞춰져 있다.]]></description>
</item>
<item>
    <title>[CS236] 8. Normalizing Flows - 2</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture8/</link>
    <pubDate>Sun, 10 Aug 2025 22:59:41 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture8/</guid>
    <description><![CDATA[개요 이번 포스트에서는 CS236 강의의 8강을 설명한다. 이전 포스트에서는 change of variable 공식을 사용하여 공식을 선형적인 예시부터, 비선형적인 예시까지 확장해보았다. 이번 포스트에서는 공식을 가지고 더 나아가보겠다. Normalizing Flow Models Flow Model은 위와 같이 결정적인 함수 식에 의하여 정해진다. 우리는 이에 대해서 배웠고 관련 공식도 배웠다. 이를 실제 neural network 모델에 사용하려면 어떻게 할까? $$\mathbf{z_m} = f_\theta^{m} \circ \cdots \circ f_\theta^{1}(\mathbf{z_0}) = f_\theta^{m}\big(f_\theta^{m-1}(\cdots(f_\theta^{1}(\mathbf{z_0})))\big) \triangleq f_\theta(\mathbf{z_0})$$
시작을 쉬운 분포 $z_0$ 으로 시작한다. 여러 간단한 invertible layer인 $f_\theta$ 를 여러 레이어로 쌓아서 $f_\theta(\mathbf{z}_0)$ 를 만든다. 그렇게 되면 매우 유연한 transform을 얻을 수 있다. 그리고 $x = z_m$ 이된다. 그럼 위 변환을 change of variable에 적용하게 되면 아래와 같은 수식을 얻을 수 있다. $$p_X(\mathbf{x};\theta) = p_Z\left( f_\theta^{-1}(\mathbf{x}) \right) \prod_{m=1}^{M}\left| \det\left( \frac{\partial (f_\theta^m)^{-1}(\mathbf{z_m})}{\partial \mathbf{z_m}} \right) \right|$$
각 개별 레이어의 야코비안 행렬식을 얻어 곱하면, 해당 행렬식을 얻을 수 있게 된다. 그리고 각 함수 $f$가 invertible 하기 때문에, $f^{-1}$ 을 계산할 수 있다. 여기서 각 개별 레이어마다 change of variable은 같지만 $\theta$ 는 다르다는 것을 유의해야한다. Learning and Inference 우리는 지금까지 Normalizing Flow 가 어떻게 생겼는지에 대해서 알아왔다. 그럼 어떻게 각 데이터 셋마다 $\theta$ 를 최적화 시킬까? 즉, 학습을 어떻게 할까? 우리는 VAE와는 달리 change of variable 공식 떄문에 $p_\theta$ 에 직접 접근할 수 있기 때문에, AutoRegreesive Model 처럼 특정 데이터 셋의 log-likelihood를 최대화 하는 $\theta$ 를 찾으면 된다. 그래서 log-likelihood의 식은 아래와 같게 표현이 될 수 있다. $$\max_{\theta} \log p_X(\mathcal{D}; \theta) = \sum_{x \in \mathcal{D}} \log p_Z \big( f_\theta^{-1}(x) \big) + \log \left| \det \left( \frac{\partial f_\theta^{-1}(x)}{\partial x} \right) \right|$$
양쪽 항 다 미분이 가능하기 때문에, gradient인 $\nabla_\theta \log p_X(x;\theta)$ 는 구할 수 있어서 최적화 또한 문제없다. 만약 추론(inference)에서 sampling을 해야된다면 이는, VAE와 같게 $z \sim p_Z(z) \quad x = f_\theta(z)$ 으로 구할 수 있다. z도 latent variable이긴 하지만, VAE의 z와 같은 역할을 한다고 볼 수는 없다. Normalizing Flow에서 z는 x와 차원이 같기 때문이다. 이 과정을 하기 위해서는 $f_\theta$ 를 invertible하고 jacobian 행렬 계산이 용이하도록 parameterized 해야한다. (여러 모델들을 보면서 어떻게 parameterized가 되는지 살펴볼 것이다.) Triangular Jacobian 자, 그럼 지금까지 배운 flow model의 조건들에 대해서 살펴보겠다. p(z) 는 샘플링과, likelihood 계산이 효율적으로 가능한 분포를 선택해야한다. 또한 tractable한 Invertible transformation 을 해야한다. 자코비안 행렬식 계산이 빨라야한다. 기존의 자코비안 행렬식은 nXn 행렬이다. 이는 $O(n^3)$ 의 시간복잡도를 지니고 있다. 따라서 이를 해결하기 위하여 행렬식의 구조를 변형해야한다. 기존 자코비안 행렬식에 시간복잡도가 오래걸린다는 단점을 해결하기 위하여, 기존의 자코비안 행렬식을 먼저 봐보자. 아래의 식과 같다. $$ x = (x_1, \cdots, x_n) = f(z) = (f_1(z), \cdots, f_n(z)) $$
$$ J = \frac{\partial f}{\partial z} = \begin{pmatrix} \frac{\partial f_1}{\partial z_1} &amp; \cdots &amp; \frac{\partial f_1}{\partial z_n} \\ \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_n}{\partial z_1} &amp; \cdots &amp; \frac{\partial f_n}{\partial z_n} \end{pmatrix} $$
위 식에서 우리는 해당 행렬을 상삼각, 하삼각 행렬을 만들면 행렬식의 계산이 $O(n)$ 으로 빨라지게 된다. 그렇게 하기 위해서 가정이 필요하다. 바로 $x_i = f_i(z)$ 가 $z_1, &hellip;, z_i$ 까지만 의존하게 된다면 위 행렬식은 하삼각 행렬이 된다. 하삼각 행렬의 determinant는 대각선 원소들의 곱이기 때문에 $O(n)$ 으로 계산이 된다. $x_2 = f_2(z_1, z_2) \quad \Rightarrow \quad \frac{\partial x_2}{\partial z_3} = 0$ 만약 상삼각 행렬을 만들고 싶다면 $z_i, &hellip;, z_n$ 까지 의존하게 하면 된다.]]></description>
</item>
<item>
    <title>[CS236] 7. Normalizing Flows - 1</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture7/</link>
    <pubDate>Thu, 07 Aug 2025 15:51:03 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture7/</guid>
    <description><![CDATA[개요 이번 포스트에서는 CS236 강의의 7강 뒤부분을 설명한다. 이전 포스트에서는 Latent Variable Models 중 VAE에 대한 내용을 배웠다. VAE는 $p_\theta(x) = \int p_\theta(x,z)dz$ 으로 모든 z에 대한 계산이 어렵다는 단점이 있다. (우리는 이 단점을 ELBO로 해결을 했었다.) 그렇기 때문에 이번 포스트에서는 VAE 말고 latent variable z를 사용한 다른 생성 모델을 살펴볼 것이다. 기존 VAE는 neural network 를 통해 x를 구했다. ($p(x|z) = \mathcal{N}(\mu_\theta(z), \Sigma_\theta(z))$) 하지만 이 방법은 확률론적이기 때문에, 같은 z여도 다른 x를 내놓을 수 있다. 하지만 Latent Variable Models 중 하나인 Flow Model은 $x = f_\theta(z), z = f_\theta^{-1}(x)$ 로 invertible 하고 결정론적인 함수를 도입한다. 해당 함수를 사용하면 x에 대응하는 오직 고유한 z가 있기 때문에, 더이상 모든 z에 대한 계산을 할 필요가 없어진다. (no enumeration) 기존 VAE는 모든 z를 계산할 수 없기 떄문에, 정보의 손실이 있을 수 있지만 Flow Model을 사용한다면, 고유한 z와 x가 있기 때문에 정보의 손실이 없다. Change of Variables 공식 Flow Model에 들어가기 앞서, 필요한 기본적인 개념들을 정리할 필요가 있다. 연속 확률 변수(Continuous Random Variable) X에 대한 기본 개념을 아래와 같이 정리할 수 있다.
연속 확률 변수 기본 개념 X를 연속 확률 변수라고 하자.
누적 분포 함수(Cumulative Distribution Function, CDF)는 다음과 같이 정의된다:
$$F_X(a) = P(X \leq a)$$
확률 밀도 함수(Probability Density Function, pdf)는 누적 분포 함수의 도함수로 표현되며 다음과 같다:
CDF는 누적된 확률을 나타내는 함수이기 때문에, 특정 값에서 값이 얼마나 자주 나오는지에 대한 정보를 직접적으로 알 수 없다. 따라서 CDF를 미분함으로써 변화율을 얻고, 특정 값 주변 구간에서 값이 얼마나 자주 발생하는지를 나타내는 확률 밀도 함수(pdf) 를 정의한다. $$p_X(a) = F&rsquo;_X(a) = \frac{dF_X(a)}{da}$$
실제로는 특정한 분포 형태(parameterized densities)를 가정하고 사용하게 되며, 대표적으로는 다음과 같은 분포들이 있다:
Gaussian 분포 (정규분포): 확률 밀도 함수는 다음과 같다: $$X \sim \mathcal{N}(\mu, \sigma), \quad p_X(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right)$$ Uniform 분포 (균등분포): 확률 밀도 함수는 다음과 같다:$$X \sim \mathcal{U}(a, b), \quad p_X(x) = \frac{1}{b - a} \cdot \mathbf{1}[a \leq x \leq b] $$ X가 단일 스칼라 값이 아닌 연속 확률 벡터(즉, 다변량 확률 변수)인 경우에는, 공동 확률 밀도 함수(Joint Probability Density Function)를 사용한다.
예를 들어, 다변량 정규분포(Multivariate Gaussian)의 경우 확률 밀도 함수는 다음과 같다:
$$p_X(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^n |\Sigma|}} \exp\left( -\frac{1}{2} (\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu) \right)$$
( \mu )는 평균 벡터 ( \Sigma )는 공분산 행렬 ( n )은 차원 수 만약 z가 [0,2] 구간에서 uniform random variable 이라고 가정하자. 이때 PDF는 $p_z$ 이다. 그렇다면 $p_z(1)$ 은 무엇일까? $p_z(1) = \frac{1}{2}$ 이다. (모르겠으면 위 기본 개념을 살펴보면 될 것 같다.) 이때 $x = 4z$ 라고 한다면 $p_x(4)$ 는 무엇일까? $p_x(4) = p(x = 4) = p(4z = 4) = p(z = 1) = p_z(1) = \frac{1}{2}$ 일까? 아니다. x는 [0,8] 구간에서 uniform random variable이므로, $p_x(4) = \frac{1}{8}$ 이다. 이는, 확률 밀도 함수(PDF)에서 단순히 값을 대입하는것이 아니라 변화율을 고려해야한다는 직관을 보여준다. 이를 해결하기 위하여 variable을 변경하는 공식을 대입해보자. 만약 $X= f(Z)$ 이고 f가 단조함수라면 $Z = f^{-1}(X) = h(X)$ 라고 표현할 수 있을 때 공식은 아래와 같다. $$p_X(x) = p_z(h(x))|h^{\prime}(x)|$$
이게 확률 자체가 아니라 PDF이기 때문에 위의 공식을 적용해야한다. PDF는 &ldquo;면적을 길이당 확률로 나눈 값&quot;이라서, 변수 변환으로 길이가 늘어나면, 그 구간에 퍼진 확률은 같아야 하니까 밀도는 도함수만큼 줄어야 확률 질량이 보존된다.]]></description>
</item>
<item>
    <title>[CS236] 6. Latent Variable Models-2</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture6/</link>
    <pubDate>Sat, 26 Jul 2025 14:23:31 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture6/</guid>
    <description><![CDATA[개요 이번 포스트에서는 CS236 강의의 6강 내용과 7강의 앞부분을 설명한다. 7강에 VAE 내용이 포함이 되었기 때문이다. 지난 포스트에서 Latent Variable Model에서 z라는 latent variable이 여러개 있을 때 Mixture of Gaussian이 된다는 점, 그 수많은 분포에서 x의 값을 구하는 방법(marginal likelihood) 등에 대해서 배웠고 그 분포를 최적화 하는 과정에서 Evidence Lower Bound(ELBO) 개념이 나오게 되었다. ELBO 개념이 나오면서, 수식들을 전개했는데 이어서 설명하겠다. Evidence Lower Bound(ELBO) - 2 $$ \begin{aligned} \log p(x; \theta) &amp;\geq \sum_{z} q(z) \log \left( \frac{p_\theta(x, z)}{q(z)} \right) \\ &amp;= \sum_{z} q(z) \log p_\theta(x, z) - \sum_{z} q(z) \log q(z) \\ &amp;= \sum_{z} q(z) \log p_\theta(x, z) + H(q) \ \text{(H(q) is entropy)} \\ \end{aligned} $$ $$ \begin{aligned} &amp;\text{Equality holds if } q = p(z \mid x; \theta)\\ &amp;\log p(x; \theta) = \sum_{z} q(z) \log p(z, x; \theta) + H(q) \end{aligned} $$
지난 포스트에서 위 식이 나오게 된 이유를 간단하게 정리해보겠다. 우리는 latent variable z를 직접 관측할 수 없기 때문에, 이를 추론하기 위하여 보조의 분포 q를 도입했다. 이때 x는 관측할 수 있는 부분이고 z는 보이지 않는 부분이다. 이 상황에서 우리는 x만 관찰될 때 z 분포를 근사하고자 하며, 이 과정에서 $logp(x)$ 를 직접 계산하기 어렵기 때문에, 이 식을 최적화 가능한 ELBO 식이 등장하게 나오게 된 것이다. 이제 본론으로 넘어와서, 2번째 식을 살펴보자면 $\sum_{z} q(z) \log p_\theta(x, z)$ 이 항은 q모델을 사용하여 z부분을 추론할 때 x,z 부분이 모두 관찰될 떄의 평균 로그 확률이다. (모든 것이 관찰된다. 이는 본질적으로 생성 모델이다.) $\sum_{z} q(z) \log q(z)$ 이 항은 q함수이고, q의 entropy라고 볼 수 있다. (q가 얼마나 무작위적인지 알려주는 양이다.) $$D_{\mathrm{KL}}(q(z) \parallel p(z \mid x; \theta)) = - \sum_{z} q(z) \log p(z, x; \theta) + \log p(x; \theta) - H(q) \geq 0$$
이제 Equality 부분을 설명할 것이다. KL 식을 전개하면 위와 같은 식을 얻을 수 있는데 오른쪽 항에서 $\log p(z, x; \theta)$ 만 남기고 다 넘기면 ELBO의 식과 동일해지는 것을 확인할 수 있다. 그렇다면 어떻게 전개를 하면 위와 같은 식이 나왔을까? KL의 값은 항상 0보다 크거나 같다의 성질을 이용한다. 그 후, 기존 KL의 식에서 $p(z \mid x; \theta)$ 을 Bayes 정리를 활용해서 $p(z \mid x; \theta) = \frac{p(x, z; \theta)}{p(x; \theta)}$ 로 변형하여 식 전개하면 위와 같은 식이 나온다. 그렇기 때문에 만약 $ q = p(z \mid x; \theta)$ 라면 KL의 값이 0이 되기 때문에 부등식이 등식이 되는 것이다. 하지만 우리는 $p(z|x;\theta)$가 계산이 불가능하다는 것을 안다. GMM (lecture 5 12-17)에서 심층 가우시안 분포를 사용해 $p_\theta(x|z)$ 는 z의 분포가 정해져 있었기 때문에 구할 수 있었다. (lecture 5 16) 하지만 $p(z|x;\theta) = \frac{p(z)p_\theta(x|z)}{p_\theta(x)}$ 이기 때문에, $p(x)$ 를 구할 수 없다.(lecture 5 23) 따라서 $p(z|x;\theta)$ 도 계산이 불가능하다. 사실 따지고 보면 만약 posterior가 계산이 가능했으면 위 ELBO식도 필요가 없다. 결국, q분포가 $p(z \mid x; \theta)$에 최대한 가까운 q를 선택해야 하는 것을 알 수 있다. 이는 앞으로 나올 Variational Inference의 이론적 도구로써 작용이 될 것이다. 정리하자면 추정이 불가능한 분포를 근사하는 q를 두어 이 분포를 최적화하여 가장 강력한 lower bound를 찾는 것이 최종 목표인 것이다. 따라서 q의 역할을 하는 별도의 신경망을 두고, p와 q를 공동으로 최적화하여 ELBO를 최대화 시킨다. 조금 더 나아가, VAE의 인코더는 q가 되고 디코더는 p가 된다. Variational Inference Variational Auto Encoder(VAE) 모델에서는 decoder인 $p(x|z) = \mathcal{N}(\mu_\theta(z), \Sigma_\theta(z))$ 의 neural network가 있으면 이것을 뒤집은 encoder의 역할을 하는 $p(z|x;\theta)$ 를 계산하여 x가 주어지고 이 x를 생성할 가능성이 높은 z를 찾으려고 한다.]]></description>
</item>
<item>
    <title>[CS236] 5. Latent Variable Models-1</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture5/</link>
    <pubDate>Mon, 14 Jul 2025 17:24:25 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture5/</guid>
    <description><![CDATA[개요 이번 포스트에서는 CS236 강의의 5강 내용을 정리한다. Autoregressive 구조는 장/단점을 지닌다. 장점은 likelihood를 평가하여 maximum likelihood를 구할 수 있어 훈련이 비교적 쉽다. 반면, 단점은 순서대로 생성하여 생성 시간이 오래걸린다. 그리고 비지도 학습을 사용하여 데이터의 특징을 추출하는 것이 명확하지 않다. 이 점이 잠재 변수 모델을 사용해서 해결할 수 있는 일 중 하나이다. 이번 챕터에서는 이 latent variable(잠재 변수)가 있을 때 생성 모델이 추론과 학습을 수행하는 방법에 대해서 설명할 것이다. Latent Variable Model 위 그림과 같이 사람 이미지와 같은 이미지 데이터 안에는 단순히 픽셀 데이터가 아니라 그 안에 성별, 눈 색깔 등의 여러 변동성 큰 정보들이 포함되어 있다. 하지만 이 모든 정보들을 annotated 하여 이용하기 쉽지 않다. 그렇기 떄문에 latent variable에 원본 데이터 상에 숨겨진 특징들이 존재하게 된다. 만약 특정한 특징을 나타내는 latent variable(z)을 사용하여 생성하게 되면, 우린 더욱 더 유연한 생성 모델을 얻을 수 있을 것 이다. 그래서 이 latent variable(z)을 반영하여 모델의 확률 분포 $p(x,z)$를 구하는 Latent Variable Model에 대해서 알아볼 것이다. 왼쪽 그림은 Latent Variable Model을 간략하게 나타낸 구조이고 오른쪽 그림은 베이지안 네트워크일 때를 나타낸다. 우리는 $x$와 $z$의 결합 분포인 $p(x,z) = p(z)p(x|z)$ 를 구하게 될 것이고 이것이 베이지안 네트워크로 가면 $p(x,z) = p(z_1)p(x|z_1)+&hellip;+p(z_k)p(x|z_k)$ 가 될 것이다. 이렇게 잠재변수 z를 포함한 모델링을 사용하면 x만을 활용한 것보다 쉽다. 또한 만약 z의 특징을 각각 추출할 수 있다면, 그것을 이용해서 다른 종류의 task에도 이용이 가능하다. (ex)eyeColor = Blue만 식별 가능) 하지만 현실적으로 모든 z중에 특정 z만 따로 추출하는 것이 어렵다는 것이다.(이 말은 위에서 현실적으로 모든 z의 확률을 구할 수 없어서 베이지안 네트워크를 사용하기 어려울 수 있다는 말과 동일하다.) 따라서 우리는 이 문제를 해결하기 위하여 단순한 z(가우시안) 만을 가정하여 deep neural network(모든 각각의 관계의 정보를 따로따로 확인하지 않아도 모든 정보를 고려해줄 수 있다.) 를 사용하여 이 z를 예측하려고 한다. $z \sim \mathcal{N}(0,1)$ $p(x|z) = \mathcal{N}(\mu_\theta(z), \Sigma_\theta(z))$ 이 문제는 비지도학습의 representation learning이기 때문애 학습 시 z에 대해서 잘 학습(z의 특징을 잘 추출)되기를 희망하게 된다. (이 모델이 어떤 z를 추출할지 명확하지 않다.) 만약 학습이 잘된다면, z의 분포를 클러스터링 하여 우리가 원하는 클러스터에 해당하는 z의 값($p(z)$)을 구할 수 있고 이 z를 가지고 새로운 데이터 $p_\theta(x,z)$를 만들어낼 수 있게 된다. 다음 챕터에서 이에 대해 더 자세히 설명할 것이다. Mixture of Gaussians (GMM,VAE) 그렇다면 z를 어떻게 예측 하는 방법에 대해서 자세히 알아볼 필요가 있다. 데이터의 분포를 확인하면 위 그림과 같을 것이다. 그 후, $K$개의 가우시안 분포(혼합 성분)를 나눌 수 있다. 그럼 생성 과정에선 K개 중 하나를 선택하여 그 K에 해당하는 평균, 공분산을 따르는 가우시안 분포에서 x를 샘플링한다. (이는 VAE에서 생성 과정에서도 동일하다.) $\mathbf{z} \sim \text{Categorical}(1, \cdots, K)$ $\mathbf{x} \sim p(\mathbf{x} \mid \mathbf{z} = k) = \mathcal{N}(\mu_k, \Sigma_k)$ (likelihood) 이 방법은 생성 과정 뿐 아니라, x가 주어졌을 때 어떤 z에 속하는지 맞출 수 있는 추론 과정에도 (posterior $p(z|x)$) 사용할 수 있다. (clustering, unsupervised representation learning) 또한 Mixture of Gaussians의 전체 확률 ($p(x)$)도 구할 수 있는데 다음과 같은 식으로 가능하다. $p(\mathbf{x}) = \sum_{z} p(\mathbf{x}, z) = \sum_{z} p(z) \cdot p(\mathbf{x} \mid z) = \sum_{k=1}^{K} p(z=k) \cdot \mathcal{N}(\mathbf{x}; \mu_k, \Sigma_k)$ 이때 얻을 수 있는 직관은 simple한 $p(x|z)$를 활용하여 복잡한 혼합 모델($p(x)$)을 구할 수 있다는 것이다. 지금까진 z를 어떻게 예측을 할지에 대해서 알아보았다. 이 Mixture of Gaussians에서는 Neural Network(NN)를 사용하지 않아 z의 수가 많아지면 계산하기 어려운 단점이 있다.]]></description>
</item>
<item>
    <title>[CS236] 4. Maximum Likelihood Learning</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture4/</link>
    <pubDate>Mon, 30 Jun 2025 17:00:38 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture4/</guid>
    <description><![CDATA[개요 이번 포스트에서는 CS236 강의의 4강 내용을 정리한다. 3강에선 데이터셋의 분포를 학습하여 Model Family를 파라미터화 하는 방법을 배웠다. 이번 4강에서는 데이터셋에 대하여 모델 파라미터 $\theta$ 를 찾는 방법을 배우게 된다. 3강에서 다뤘던 내용을 다시 한 번 살펴보자. 데이터가 실제 분포 $P_\text{data}$ 로부터 추출된 m개의 샘플 $\mathcal{D}$ 가 있다고 가정을 해보자. 그럼 생성 모델의 목표는 모델 $\mathcal{M}$ 에서 $P_\text{data}$ 와 가능한 가장 가까운 $P_\theta$ 를 학습하는 것이다. 이때의 모델 $\mathcal{M}$ 은 Bayes net이 될 수 있고, FVSBN이 될 수 있는 것 이다. 하지만 $P_\theta$ 가 완전히 실제 분포를 포착할 순 없다. 왜냐하면 제한된 data의 문제와 컴퓨팅 파워 문제가 있기 때문이다. 784개의 이진 픽셀로 이루어진 이미지를 생각해보면, 가능한 모든 이미지는 $\text{2}^\text{784} \approx \text{10}^\text{236}$ 가지이다. 대략 백만 개의 샘플로는 이 공간을 거의 다룰 수 없다. 그래서 우리는 $P_\text{data}$ 의 분포를 잘 근사하는 $P_\theta$ 를 선택해야한다. 그렇다면 어떤 것이 잘 근사하는 모델($P_\theta$)일까? 잘 근사하는 모델은 우리가 하려는 task에 따라 다르다. (Density Estimation에서는 전체 확률 분포를 잘 근사하는 것이 중요, Specific Prediction Task은 특정 예측을 만드는 분포(조건부 확률)가 중요, Structure or Knowledge Discovery 모델 그 자체의 구조가 중요) 생성의 관점에선 어떤 확률적 추론 쿼리에 답해야 하기 때문에 우린 전체 분포를 배워야한다. 따라서 학습을 Density Estimation 문제로 볼 수 있다. 여기서 말하는 확률적 추론 쿼리(any probabilistic inference query)란 확률 분포로부터 도출되는 질문들(조건부 확률, 마진, 샘플링 등)을 의미한다. 그래서 우리의 목표는 $P_\text{data}$ 에 가장 가까운 $P_\theta$ 를 만드는 것이 제일 중요하다. 그렇다면 가까운 정도를 어떻게 평가할까? 다음 챕터에서 설명 할 것이다. Kullback-Leibler divergence(KL-divergence) 어떤 두 분포간의 가까운 정도를 측정하기 위하여 Kullback-Leibler divergence(KL-divergence)지표를 사용하게 된다. 수식은 아래와 같다. $$D_{\text{KL}}(p || q) = \sum_x p(x) \log \frac{p(x)}{q(x)}$$
KL-Divergence는 몇가지 특징이 있다. $D_{\text{KL}}(p || q) \geq 0$ 이고, 같을 땐 $p = q$ 일 때 이다. $D_{\text{KL}}(p || q) \not = D_{\text{KL}}(q || p)$ 으로 비대칭적인 성질을 지닌다. 이 지표는 정보이론 관점에서 p와 q에 기반한 압축 방식이 얼마나 잘되는지 보여준다. (p가 진짜 분포이고 q가 학습한 분포) q의 분포로 p를 인코딩을 했을 때 생기는 비트 낭비량을 확인할 수 있다. 우리의 목표는 $P_\theta$ 가 $P_\text{data}$ 와 가깝도록 만드는 것이기 때문에 $D_{\text{KL}}(P_\text{data} || P_\theta)$ 로 표현할 수 있다. 따라서 KL-Divergence의 값을 확인하여 data를 잘 압축할 수 있는 모델을 선정해야한다. KL이 작을수록, 압축 손실도 작아짐 → 더 나은 모델 $$ D_\text{KL}(P_\text{data} || P_\theta) = \mathbb{E_{x \sim P_\text{data}}}[\log P_\text{data}(x)] - \mathbb{E_{x \sim P_\text{data}}}[\log P_\theta(x)] $$
위 KL을 다음과 같이 분해가 가능하고, 앞 항은 $P_\theta$ 에 영향받지 않는 상수이기 때문에 두번째 항에 집중을 할 것이다. 그렇게 되면 수식은 아래와 같아진다. $$ argmin_\theta \ D_(P_\text{data} || P_\theta) = argmin_\theta -\mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)] = argmax_\theta \ \mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)] $$
그럼 이제 KL을 최소화 하기 위하여 두번째 항을 최대화 하는것이 목표이다. 이 수식을 통하여 알 수 있는 KL의 특징이 있다. 바로 두 모델 간 KL을 비교했을 때 누가 가까운지는 알지만 얼마나 가까운지 (정확한 거리)는 모른다는 것이다. $D_(P_\text{data} || P_{\theta_{1}}) - D_(P_\text{data} || P_{\theta_{2}})$ 가 계산이 되면 상수(첫번째 항)가 사라져서 거리를 모르게 된다. 이제 이 수식을 풀려고 보니, 정리된 수식의 모든 $P_\text{data}$를 우리는 일반적으로 (expected log-likelihood) 구할 수 없다. 왜냐하면 현실에선 이 기대값을 계산할 수 없으므로 주어진 데이터 샘플의 평균으로 근사 해야한다. (empirical log-likelihood) 따라서 데이터 샘플의 평균으로 근사하면 아래와 같은 식이 나오고, 그것을 최대화 하는 $\theta$를 찾는 방향으로 학습을 진행하면 된다.]]></description>
</item>
<item>
    <title>[CS236] 3. Autoregressive Models</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture3/</link>
    <pubDate>Wed, 07 May 2025 22:58:36 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture3/</guid>
    <description><![CDATA[개요 CS236: Deep Generative Models (Stanford)는 스탠포드 대학교에서 진행하는 딥러닝 기반 생성 모델(Deep Generative Models) 에 대한 심화 강의이다. 이번 포스트에서는 CS236 강의의 3강 내용을 정리한다. 3강에서는 주어진 데이터셋 D의 분포를 학습하여, 이로부터 새로운 샘플을 생성하는 방법을 배운다. 그렇게 하기 위해서 2가지 절차가 진행되어야 한다: Model Family를 파라미터화 (3강에서 다룰 내용) 데이터셋 D에 대하여 모델 파라미터 $\theta$ 를 찾는 방법 (4강에서 다룰 내용) Autoregressive Models $$ \begin{aligned} p(x_1, x_2, \ldots, x_{784}) &amp;= p(x_1),p(x_2 \mid x_1),p(x_3 \mid x_1, x_2), \cdots, p(x_{784} \mid x_1, \ldots, x_{783}) \\ p(x_1, \cdots, x_{784}) &amp;= p_{\text{CPT}}(x_1; \alpha_1) \cdot p_{\text{logit}}(x_2 \mid x_1; \alpha_2) \cdot p_{\text{logit}}(x_3 \mid x_1, x_2; \alpha_3) \cdots p_{\text{logit}}(x_n \mid x_1, \cdots, x_{n-1}; \alpha_n) \\ \end{aligned} $$
Autoregressive Model은 각 픽셀을 이전 픽셀들에 대한 조건부 확률로 예측하는 모델이다. 이러한 조건부 확률을 계산을 하기 위해서 Chain rule factorization을 사용한다. 하지만 이때 모든 확률 조건들을 저장할 수 없다. 따라서 어떤 신경모델, 함수를 사용하여 조건문을 모델링 하려고 한다. 위의 두번째 수식 처럼 logistic regression 함수를 이용한 방법이 그 예시이다. $$ \begin{aligned} p_{\text{CPT}}(X_1 = 1; \alpha_1) = \alpha_1 &amp;, p(X_1 = 0) = 1 - \alpha_1, \\ p_{\text{logit}}(X_2 = 1 \mid x_1; \alpha_2) &amp;= \sigma(\alpha_2^0 + \alpha_2^1 x_1), \\ p_{\text{logit}}(X_3 = 1 \mid x_1, x_2; \alpha_3) &amp;= \sigma(\alpha_3^0 + \alpha_3^1 x_1 + \alpha_3^2 x_2) \end{aligned} $$
MNIST 데이터셋으로 Autoregressive Model을 구성하는 수식을 살펴보게 되면 위의 수식과 같다. 첫번째 픽셀이 black or white인지 조건부 확률 테이블(CPT)에서 값을 받아 배정된다.(보통 black) 그 후 순서에 따라 각 값을 예측하게 된다. Fully Visible Sigmoid Belief Network (FVSBN) 초창기 autoregressive model인 FVSBN은 chain rule을 이용해 확률분포를 나타낸 이후, 많은 컴퓨팅 파워를 요구하는 조건부 확률을 매개변수화한 이후 logistic regression 알고리즘을 적용해 학습하는 생성모델 알고리즘이다. 만약 pixel이 4개라고 가정을 하면, 이전 픽셀에 따라서 값이 다른 것을 확인할 수 있다. 이 모델의 경우 파라미터는 $1+2+3+\cdot\cdot\cdot+n \approx n^2/2$ 인 것도 확인할 수 있다. FVSBN에서 sampling하는 방법이다. 랜덤한 난수를 먼저 생성하고, 그 난수($\bar{x_1}$)로부터 $\bar{x_2}$ 가 나오게 된다. 하지만 FVSBN의 sampling 결과가 좋진 않다. Neural Autoregressive Density Estimation (NADE) NADE는 많은 컴퓨팅 파워를 요구하는 FVSBN의 한계를 보완하기 위해서 logistic regression 대신 Neural Network를 사용한 모델이다. $$ \begin{aligned} h_i &amp;= \sigma(W_{\cdot,&lt;i} x_{&lt;i} + c) \\ \hat{x_i} = p(x_i \mid x_1, \ldots, x_{i-1}) &amp;= \sigma(\alpha^\top h_i + b_i) \end{aligned} $$
위 수식의 $h_i$는 neural network를 의미한다. NADE는 Weight Sharing(Weight tying)기법을 활용하여 계산량을 대폭 줄였다. Weight Sharing은 학습 과정에서 은닉층($h_i$)에서 사용하는 가중치 $w_i$를 동일하게 유지하는 방법이다. 층이 깊어질수록 기존 가중치 벡터 (W)에 열벡터 하나만 추가하는 것으로 생각하면 된다. 이런 결과로 계산 복잡도가 O(n)으로 줄어든 것을 확인할 수 있다. 위 사진이 NADE의 생성 결과인데, 왼쪽이 sample이고 오른쪽이 생성 결과이다. 이미지 구조(분포)를 꽤나 잘 파악하고 있는 것으로 확인할 수 있다. 생성의 작동 방식은 왼쪽 sample에서 픽셀 값을 가져오고 NADE가 계산을 통하여 확률 값이 나오게 된다. 따라서 각 픽셀에 대한 확률 값이기 때문에 오른쪽 샘플의 결과는 0~1사이의 확률값이기때문에 이미지가 부드러워 보인다. 지금까지는 이진 데이터만 다루었다. 하지만 color 이미지와 같은 범주형 변수일 때는 어떻게 작동 할까? $x_i \in {0, \ldots, K}$ 인 다항 변수의 모델링이 필요할 것이다. 다항 변수의 모델링을 하기 위해서 각 $x_i$에 softmax를 취하여 범주형 확률 분포를 만들어주면 기존의 조건부 확률을 계산할 수 있게 된다.]]></description>
</item>
<item>
    <title>[CS236] 2. Background</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture2/</link>
    <pubDate>Sun, 20 Apr 2025 09:32:32 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture2/</guid>
    <description><![CDATA[개요 CS236: Deep Generative Models (Stanford)는 스탠포드 대학교에서 진행하는 딥러닝 기반 생성 모델(Deep Generative Models) 에 대한 심화 강의이다. 이번 포스트에서는 CS236 강의의 2강 내용을 정리한다. 2강에서는 말그대로 Generative 분야를 공부하기 전에 필요한 배경 지식을 설명하고 있다. 조건부 독립 (conditional independence) generative model vs discriminative model 생성 모델이란 주어진 데이터(x)의 확률 분포(p(x))를 학습하여 샘플링하여 유사한 데이터를 생성해내는 것이다. ($x ~ p(x)$) 이런 확률 분포 p(x)에 대하여 여러 활용을 할 수 있는데, 아래는 그 활용에 대해서 나타낸다. 밀도 추정: 데이터 유사도 기반 이상 탐지 (원하는 object엔 p(x)가 높다.) Unsupervised representation learning: 공통된 특징 추출 그럼 이제 이러한 데이터의 확률분포 p(x)를 어떻게 표현을 할 것이냐가 먼저이다. Representation p(x) 확률 분포의 표현은 여러가지이다. 베르누이 분포와 범주형(categorical)분포는 위 사진과 같이 표현할 수 있다. 만약 3개의 discrete random variable인 이미지 데이터라면, $p(R = r, G = g, B = b)$의 joint distribution을 구하기 위하여 $256 * 256 * 256 - 1$의 파라미터가 발생한다. 이때 말하는 파라미터란 무엇인가? 파라미터란 확률 분포를 정의하기 위해 필요한 개별 확률값을 의미한다. $X_1, X_2 \in {0, 1}$ 의 변수가 있다고 가정할 때 가능한 조합은 4가지 ((0,0), &hellip; (1,1))이다. 각 조합에 대해 확률 값을 지정해야 하지만, 전체 확률 합은 1이어야 하므로 4개 중 3개만 자유롭게 정하면 나머지 하나는 자동으로 정해진다. 따라서 이 경우 $4 - 1 = 3$ 개의 파라미터를 가진다. 만약 n개의 binary(Bernoulli) random variable이라면 가능한 image의 수는 $2 \times 2 \times &hellip; \times 2 = 2^n$ (n: pixel 수)일 것이다. 그럼 이때 이 분포에서 sampling을 한다면 특정 분포의 joint distribution $p(x_1,&hellip;,x_n)$은 $2^n - 1$의 파라미터가 필요하다. 따라서 random variable의 수에 따라 파라미터의 수가 기하급수적으로 증가한다는 사실을 알 수 있다. 이 모든 값들을 컴퓨터에 저장하기엔 무리가 있다. 그렇기 때문에 수학적 가정이 필요한 순간이다. 그래서 독립성 가정(Independence Assumption)을 하겠다. $X_1, &hellip; , X_n$ 베르누이 분포를 만족하는 확률 변수들이 있다고 가정했을 때 $p(x_1, &hellip; , x_n) = p(x_1)\dot\dot\dot p(x_n)$ 을 만족한다. 이 경우, 가능한 상태(이미지)는 동일하게 $2^n$이고 joint distribution의 파라미터는 $n$이다. Marginal distribution $p(x_1)$의 파라미터가 1이다. 따라서 $1 + 1 + &hellip; + 1$이기 때문에 파라미터는 n이 된다. 독립성 가정은 너무 strong해서 위의 그림 처럼 모든 값이 독립적으로 무작위 값을 선택하여 샘플링 결과가 안좋다. $$p(S_1 \cap S_2 \cap \cdots \cap S_n) = p(S_1) \cdot p(S_2 \mid S_1) \cdot \cdots \cdot p(S_n \mid S_1 \cap \cdots \cap S_{n-1})$$ $$p(S_1 \mid S_2) = \frac{p(S_1 \cap S_2)}{p(S_2)} = \frac{p(S_2 \mid S_1) \cdot p(S_1)}{p(S_2)} $$
따라서 다른 가정이 필요하여 두가지 중요한 rule(공식)이 있다. 위는 순서대로 Chain rule (probability)와 Bayes' rule의 식이다. $$p(x_1, x_2, \ldots, x_n) = p(x_1) \cdot p(x_2 \mid x_1) \cdot p(x_3 \mid x_1, x_2) \cdots p(x_n \mid x_1, \ldots, x_{n-1})$$
Chain Rule을 사용하면 위의 식이 된다. 이때 파라미터는 $1+2+&hellip;+2^\text{n-1} = 2^n - 1$이다. 여전히 exponential하다는 것을 알 수 있다. 이 chain rule을 사용한 식에 conditional independence를 가정을 한다. $$p(x_1, x_2, \ldots, x_n) = p(x_1) \cdot p(x_2 \mid x_1) \cdot p(x_3 \mid x_2) \cdots p(x_n \mid x_{n-1})$$
그렇게 되면 위의 식과 같아지고 파라미터는 $2n - 1$로 해결이 가능해졌다. ($X_{i+1} \perp {X_1, \ldots, X_{i-1}} \mid X_i$ 이렇게도 표기한다.) Bayes Network Chain rule을 통해 모든 확률변수의 joint distribution을 표현할 수 있지만, 이때 conditional independence를 활용하면 필요한 파라미터 수를 대폭 줄일 수 있다.]]></description>
</item>
<item>
    <title>[Paper Review]Diffusion Models Beat GANs on Image Synthesis(ADM-G)</title>
    <link>https://goodyoung.github.io/posts/paper/dm-gans/</link>
    <pubDate>Fri, 28 Feb 2025 16:42:40 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/dm-gans/</guid>
    <description><![CDATA[개요 GAN 대비 Diffusion Model(DM)의 이미지 생성 성능을 비교하며, DM이 GAN을 능가하는 이유를 분석한 Diffusion Models Beat GANs 논문을 리뷰할 것이다. Introduction 요즘의 생성 모델은 많이 발전해오고 있다. 하지만 그 중에도 발전 가능성이 아직 많다. 생성 모델이 더욱 발전 한다면, 사용할 수 있는 분야가 셀 수 없이 많다. GAN은 여러 평가 지표 (FID, Inception Score, Precision, &hellip; 등)에 의하여 image generation에서 SOTA를 달성하고 있다. 하지만 이 평가 지표는 다양성을 완전히 포착하지 않고, likelihood-based model보다 더 다양성을 포착하지 않는다. 또한, GAN은 최적의 하이퍼 파라미터와 정규화를 하지 않으면 모델이 붕괴하기 때문에 훈련이 어렵다. 이러한 GAN의 단점 때문에 다른 domain에 적용하기에도 어렵고, 확장시키기도 어려워졌다. 그 결과 likelihood-based model이 GAN의 sampling image quality와 비슷하게 발전해왔다. likelihood-based model도 결국 단점이 있었는데, sampling 시 GAN보다 매우 느리고 sample quality 또한 기대에 미치진 못한다. Likelihood-based model의 한 종류인 Diffusion model이 등장하여 확장성도 있고, 높은 품질을 만들어내는 성능을 보였주었다. CIFAR-10에서 SOTA를 달성했지만 다른 어려운 dataset(LSUN, ImageNet)에 대해서는 GAN에 밀려있었다. 논문 저자들이 Improved Denoising Diffusion Probabilistic Models에서 diffusion model의 신뢰성을 증가시키는 연구를 했지만 FID가 GAN에 비하여 경쟁력 있지는 않았었다. 본 논문에선 GAN과 Diffusion model이 차이가 나는 두 가지 요인에서 비롯된다고 가정한다. 최근 GAN 연구에서 사용된 모델 아키텍처는 광범위하게 탐색되고 최적화되었다. GAN은 다양성(diversity)과 정확성(fidelity) 사이에서 trade-off의 균형을 조절한다. 따라서 GAN은 높은 품질의 샘플을 생성하는 대신 전체 데이터 분포를 완전히 포괄하지는 못한다. GAN은 Generator, Discriminator로 나뉘어져 있으므로 둘 간 균형을 조정한다. 본 논문에선 이 두 가지의 요인을 Diffusion model에도 적용하고자 한다. 먼저 모델의 아키텍쳐를 개선하고, 이후 다양성과 정확성 간의 trade-off의 균형을 조절 할 수 있는 기법을 개발한다. 이 결과 본 논문에서 제안한 diffusion model이 새로운 SOTA를 달성하며, GAN을 이기게 되었다. Background 이번 단락에서는 Diffusion model 중 DDPM에 대한 간단한 배경을 설명하고 있다. Diffusion model에 대한 자세한 설명은 해당 링크에서 보면 될 것 같다. DDPM에서의 목표는 조금 더 덜 노이즈가 포함된 $x_\text{t-1}$ 를 $x_t$에서 생성하는 과정을 학습하게 된다. DDPM에서 학습하기 위한 loss로 실제 변분 하한(Variational Lower Bound) $L_\text{vlb}$를 단순화한 $L_\text{simple}$이 성능이 좋음을 관찰하였다. 이런 훈련 절차와 샘플링 절차는 denoising score matching model과 동일하다고 한다. 다음으로, 조금 더 나은 diffusion model을 설명하게 되는데 기존 DDPM에서는 reverse process에서의 분산 $\Sigma_\theta(x_t, t)$ 을 고정된 값으로 설정하였는데, 이런 고정된 분산이 샘플링 단계 수가 적을 때 성능이 낮아질 수 있다. 따라서 $\Sigma_\theta(x_t, t)$ 를 파라미터화 하여 해결하려고 했고, 훈련 loss 또한 $L_\text{vlb}$ 과 $L_\text{simple}$ 를 함께 사용하는 hybrid objective로 해결한다. 본 논문에서도 해당 objecive와 parameterization을 사용한다. 또한 DDIM의 Non-Markovian 과정으로 인한 샘플링 스텝을 줄이는 방법 또한 본 논문에서 사용한다. 마지막으로 샘플 품질을 평가하는 metrics에 관한 설명으로 이어진다. Metrics 중 Inception Score(IS)는 ImageNet 클래스 분포를 얼마나 잘 학습했는지를 측정하는 메트릭이다. 개별 샘플이 특정 클래스의 예제를 얼마나 그럴듯하게 평가하면서도, 모델이 전체 dataset 클래스 분포를 잘 반영했는지 측정한다. 이런 IS도 한계점이 있는데, 아래는 IS의 한계점을 설명한 것이다. 모든 클래스에 대한 전체 분포를 얼마나 잘 커버하는지 평가하지 못한다. 데이터셋의 일부를 단순히 암기한 모델도 높은 IS 점수를 가질 수 있다. Fréchet Inception Distance (FID)는 IS보다 더 다양성을 잘 평가할 수 있는 방법이다. Inception-V3 모델의 latent space에서 두 이미지 분포 간 거리를 측정하여 두 이미지 분포 간의 symmetric measure of distance를 측정하게 된다. sFID라는 변형 버전은 기존 FID보다 공간적 특성을 고려하여 더 정교한 평가가 가능하다.]]></description>
</item>
<item>
    <title>[Paper Review]High-Resolution Image Synthesis with Latent Diffusion Models(LDM)</title>
    <link>https://goodyoung.github.io/posts/paper/ldm/</link>
    <pubDate>Mon, 17 Feb 2025 17:57:23 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/ldm/</guid>
    <description><![CDATA[개요 DDPM 이후, 고해상도 이미지 생성을 위해 효율적인 latent space에서 확산 과정을 수행하는 LDM에 대해 논문 리뷰를 할 것이다. Introduction 이미지 합성(Image synthesis)은 최근 가장 빠르게 발전이 되어왔지만, 많은 컴퓨터 계산 비용이 크다. 특히 고해상도 복원 문제는 AR(Autoregressive) 기반 모델들이 자주 사용하지만 모델 수십억 개의 파라미터를 요구한다. GAN은 학습 방식의 한계 때문에 multi-modal 분포에서는 모델링 하는데 한계가 있다. 이러한 가운데, Diffusion model이 이미지 합성의 여러 분야에서 뛰어난 성과(SOTA)를 보여줬다. Diffusion 모델은 다른 모델들과 다르게 모델 붕괴(model collapse), 학습 불안정성, 많은 파라미터에서 강점을 지닌다. 이러한 Diffusion 모델도 문제점이 있는데, Diffusion 모델은 mode-covering 성질을 갖고 있다. 그래서 데이터의 모든 세부 패턴을 학습하려는 경향이 있어서 많은 연산 자원을 필요로 하게 된다. Reweighted Variational Objective 방법이 연산을 줄이려고 하지만 여전히 계산량이 많다. A100 기준으로 50,000개의 샘플을 생성하는데 5일이 걸린다. 이러한 문제는 두 가지 영향을 보여준다. 첫 번째로는 훈련 시 거대한 컴퓨팅 자원을 필요로 하므로 일반 연구자나 소규모 연구팀에게 접근성이 낮다. 두 번째로는 추론 시 높은 비용과 시간을 소모하여 학습 뿐 아니라 샘플링 시에도 매우 비효율적이다.' 따라서 이 두 가지의 문제를 해결하기 위한 것이 핵심이다. 본 논문은 pixel space에서 이미 학습된 diffusion 모델을 분석하는 것 부터 시작한다. 기존의 DM은 픽셀 단위에서 학습을 진행 하였다. 이미지 자체에 대해서 훈련하는 방식이였다. 위 그림과 같이 모든 likelihood-based 모델들의 학습 과정은 두 단계로 나뉠 수 있다. 첫 번째로 높은 주파수 영역의 세부사항을 제거하며 압축을 수행하는 지각적 압축 단계이고, 두 번째로는 실제 생성 모델이 데이터의 의미적이고 개념적인 구성을 학습하는 단계이다. 본 논문은 위 두 단계와 동일하지만, 계산적으로는 더욱 효율적인 공간을 사용하는 모델을 제안한다. 본 논문에서 모델은 두 단계를 제안한다. 첫 번째로 autoencoder를 학습하여 pixel space와 지각적으로 동일하지만, 더욱 효율적인 저차원의 잠재 공간을 만든다. 두 번째로는 추가적인 공간 압축에 의존할 필요 없이 잠재 공간에서 diffusion 모델을 학습시켜 공간적 차원성(spatial dimensionality)에 대해 더 나은 확장성을 갖고 있다. 이미지 자체에 노이즈를 추가하여 학습을 했던 방식과 달리, 잠재 공간에서 학습을 하자는 것이다. 이러한 복잡성 감소 때문에 단 한 번의 네트워크 실행으로도 효율적인 이미지 생성을 할 수 있고, 본 논문은 이 모델을 Latent Diffsion Models(LDMs) 라고 부른다. 이 방법의 장점은 방대한 autoencoder를 한 번만 학습을 하게 된다면, 이를 통해 나온 latent space를 여러 DM 모델의 훈련에 사용할 수 있게 된다. 이는 곧 여러 task에서도 재사용할 수 있게 된다는 것이다. 마지막으로 본 논문의 주요 contribution에 대해 정리한다. Transformer만으로 이루어진 접근법들과 달리 더 높은 차원의 데이터에도 효율적으로 적용할 수 있다.
여러 task(inpainting 등)에서 계산 비용을 크게 감소 시키면서 경쟁력 있는 성능을 달성하였다.
기존 연구는 재구성(reconstruction)과 생성(generative)능력 사이의 차이를 조절하는 것이 중요했지만, 본 논문의 모델은 그것이 필요 없다.
두 가지를 분리해서 해결했기 때문이다. Autoencoder는 오직 **재구성(압축과 복원)**만 담당한다. Diffusion 모델은 오직 **이미지 생성(새로운 이미지 합성)**만 담당한다. 초해상도와 같은 고밀도 작업에서도 적용이 가능하다.
cross attention을 기반으로 하는 매커니즘을 개발하여 multi-modal data에도 사용할 수 있다.
Method Introduction에서도 설명이 되어있듯이, 기존 DM은 pixel space에서 매우 비용이 큰 연산을 수행해야한다는 단점이 있다. 이를 해결하기 위하여 압축과 생성 단계를 분리 하였고, 압축 단계는 계산 비용이 작은 autoencoder를 사용한다. 이를 통해 계산 효율성이 증가하고, 반복적으로 사용할 수 있는 latent space를 제공하여 범용적인 압축 모델이 된다. 또한 본 논문은 UNet의 Inductive bias를 활용하여 공간적 구조를 잘 표현하기 때문에, 과도하게 압축하지 않고도 효과적으로 이미지를 잘 생성해낼 수 있게 된다.]]></description>
</item>
</channel>
</rss>
