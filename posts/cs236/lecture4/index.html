<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[CS236] 4. Maximum Likelihood Learning - Good Young</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="[CS236] 4. Maximum Likelihood Learning" />
<meta property="og:description" content="개요 이번 포스트에서는 CS236 강의의 4강 내용을 정리한다. 3강에선 데이터셋의 분포를 학습하여 Model Family를 파라미터화 하는 방법을 배웠다. 이번 4강에서는 데이터셋에 대하여 모델 파라미터 $\theta$ 를 찾는 방법을 배우게 된다. 3강에서 다뤘던 내용을 다시 한 번 살펴보자. 데이터가 실제 분포 $P_\text{data}$ 로부터 추출된 m개의 샘플 $\mathcal{D}$ 가 있다고 가정을 해보자. 그럼 생성 모델의 목표는 모델 $\mathcal{M}$ 에서 $P_\text{data}$ 와 가능한 가장 가까운 $P_\theta$ 를 학습하는 것이다. 이때의 모델 $\mathcal{M}$ 은 Bayes net이 될 수 있고, FVSBN이 될 수 있는 것 이다. 하지만 $P_\theta$ 가 완전히 실제 분포를 포착할 순 없다. 왜냐하면 제한된 data의 문제와 컴퓨팅 파워 문제가 있기 때문이다. 784개의 이진 픽셀로 이루어진 이미지를 생각해보면, 가능한 모든 이미지는 $\text{2}^\text{784} \approx \text{10}^\text{236}$ 가지이다. 대략 백만 개의 샘플로는 이 공간을 거의 다룰 수 없다. 그래서 우리는 $P_\text{data}$ 의 분포를 잘 근사하는 $P_\theta$ 를 선택해야한다. 그렇다면 어떤 것이 잘 근사하는 모델($P_\theta$)일까? 잘 근사하는 모델은 우리가 하려는 task에 따라 다르다. (Density Estimation에서는 전체 확률 분포를 잘 근사하는 것이 중요, Specific Prediction Task은 특정 예측을 만드는 분포(조건부 확률)가 중요, Structure or Knowledge Discovery 모델 그 자체의 구조가 중요) 생성의 관점에선 어떤 확률적 추론 쿼리에 답해야 하기 때문에 우린 전체 분포를 배워야한다. 따라서 학습을 Density Estimation 문제로 볼 수 있다. 여기서 말하는 확률적 추론 쿼리(any probabilistic inference query)란 확률 분포로부터 도출되는 질문들(조건부 확률, 마진, 샘플링 등)을 의미한다. 그래서 우리의 목표는 $P_\text{data}$ 에 가장 가까운 $P_\theta$ 를 만드는 것이 제일 중요하다. 그렇다면 가까운 정도를 어떻게 평가할까? 다음 챕터에서 설명 할 것이다. Kullback-Leibler divergence(KL-divergence) 어떤 두 분포간의 가까운 정도를 측정하기 위하여 Kullback-Leibler divergence(KL-divergence)지표를 사용하게 된다. 수식은 아래와 같다. $$D_{\text{KL}}(p || q) = \sum_x p(x) \log \frac{p(x)}{q(x)}$$
KL-Divergence는 몇가지 특징이 있다. $D_{\text{KL}}(p || q) \geq 0$ 이고, 같을 땐 $p = q$ 일 때 이다. $D_{\text{KL}}(p || q) \not = D_{\text{KL}}(q || p)$ 으로 비대칭적인 성질을 지닌다. 이 지표는 정보이론 관점에서 p와 q에 기반한 압축 방식이 얼마나 잘되는지 보여준다. (p가 진짜 분포이고 q가 학습한 분포) q의 분포로 p를 인코딩을 했을 때 생기는 비트 낭비량을 확인할 수 있다. 우리의 목표는 $P_\theta$ 가 $P_\text{data}$ 와 가깝도록 만드는 것이기 때문에 $D_{\text{KL}}(P_\text{data} || P_\theta)$ 로 표현할 수 있다. 따라서 KL-Divergence의 값을 확인하여 data를 잘 압축할 수 있는 모델을 선정해야한다. KL이 작을수록, 압축 손실도 작아짐 → 더 나은 모델 $$ D_\text{KL}(P_\text{data} || P_\theta) = \mathbb{E_{x \sim P_\text{data}}}[\log P_\text{data}(x)] - \mathbb{E_{x \sim P_\text{data}}}[\log P_\theta(x)] $$
위 KL을 다음과 같이 분해가 가능하고, 앞 항은 $P_\theta$ 에 영향받지 않는 상수이기 때문에 두번째 항에 집중을 할 것이다. 그렇게 되면 수식은 아래와 같아진다. $$ argmin_\theta \ D_(P_\text{data} || P_\theta) = argmin_\theta -\mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)] = argmax_\theta \ \mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)] $$
그럼 이제 KL을 최소화 하기 위하여 두번째 항을 최대화 하는것이 목표이다. 이 수식을 통하여 알 수 있는 KL의 특징이 있다. 바로 두 모델 간 KL을 비교했을 때 누가 가까운지는 알지만 얼마나 가까운지 (정확한 거리)는 모른다는 것이다. $D_(P_\text{data} || P_{\theta_{1}}) - D_(P_\text{data} || P_{\theta_{2}})$ 가 계산이 되면 상수(첫번째 항)가 사라져서 거리를 모르게 된다. 이제 이 수식을 풀려고 보니, 정리된 수식의 모든 $P_\text{data}$를 우리는 일반적으로 (expected log-likelihood) 구할 수 없다. 왜냐하면 현실에선 이 기대값을 계산할 수 없으므로 주어진 데이터 샘플의 평균으로 근사 해야한다. (empirical log-likelihood) 따라서 데이터 샘플의 평균으로 근사하면 아래와 같은 식이 나오고, 그것을 최대화 하는 $\theta$를 찾는 방향으로 학습을 진행하면 된다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://goodyoung.github.io/posts/cs236/lecture4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-06-30T17:00:38+09:00" />
<meta property="article:modified_time" content="2025-06-30T17:00:38+09:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[CS236] 4. Maximum Likelihood Learning"/>
<meta name="twitter:description" content="개요 이번 포스트에서는 CS236 강의의 4강 내용을 정리한다. 3강에선 데이터셋의 분포를 학습하여 Model Family를 파라미터화 하는 방법을 배웠다. 이번 4강에서는 데이터셋에 대하여 모델 파라미터 $\theta$ 를 찾는 방법을 배우게 된다. 3강에서 다뤘던 내용을 다시 한 번 살펴보자. 데이터가 실제 분포 $P_\text{data}$ 로부터 추출된 m개의 샘플 $\mathcal{D}$ 가 있다고 가정을 해보자. 그럼 생성 모델의 목표는 모델 $\mathcal{M}$ 에서 $P_\text{data}$ 와 가능한 가장 가까운 $P_\theta$ 를 학습하는 것이다. 이때의 모델 $\mathcal{M}$ 은 Bayes net이 될 수 있고, FVSBN이 될 수 있는 것 이다. 하지만 $P_\theta$ 가 완전히 실제 분포를 포착할 순 없다. 왜냐하면 제한된 data의 문제와 컴퓨팅 파워 문제가 있기 때문이다. 784개의 이진 픽셀로 이루어진 이미지를 생각해보면, 가능한 모든 이미지는 $\text{2}^\text{784} \approx \text{10}^\text{236}$ 가지이다. 대략 백만 개의 샘플로는 이 공간을 거의 다룰 수 없다. 그래서 우리는 $P_\text{data}$ 의 분포를 잘 근사하는 $P_\theta$ 를 선택해야한다. 그렇다면 어떤 것이 잘 근사하는 모델($P_\theta$)일까? 잘 근사하는 모델은 우리가 하려는 task에 따라 다르다. (Density Estimation에서는 전체 확률 분포를 잘 근사하는 것이 중요, Specific Prediction Task은 특정 예측을 만드는 분포(조건부 확률)가 중요, Structure or Knowledge Discovery 모델 그 자체의 구조가 중요) 생성의 관점에선 어떤 확률적 추론 쿼리에 답해야 하기 때문에 우린 전체 분포를 배워야한다. 따라서 학습을 Density Estimation 문제로 볼 수 있다. 여기서 말하는 확률적 추론 쿼리(any probabilistic inference query)란 확률 분포로부터 도출되는 질문들(조건부 확률, 마진, 샘플링 등)을 의미한다. 그래서 우리의 목표는 $P_\text{data}$ 에 가장 가까운 $P_\theta$ 를 만드는 것이 제일 중요하다. 그렇다면 가까운 정도를 어떻게 평가할까? 다음 챕터에서 설명 할 것이다. Kullback-Leibler divergence(KL-divergence) 어떤 두 분포간의 가까운 정도를 측정하기 위하여 Kullback-Leibler divergence(KL-divergence)지표를 사용하게 된다. 수식은 아래와 같다. $$D_{\text{KL}}(p || q) = \sum_x p(x) \log \frac{p(x)}{q(x)}$$
KL-Divergence는 몇가지 특징이 있다. $D_{\text{KL}}(p || q) \geq 0$ 이고, 같을 땐 $p = q$ 일 때 이다. $D_{\text{KL}}(p || q) \not = D_{\text{KL}}(q || p)$ 으로 비대칭적인 성질을 지닌다. 이 지표는 정보이론 관점에서 p와 q에 기반한 압축 방식이 얼마나 잘되는지 보여준다. (p가 진짜 분포이고 q가 학습한 분포) q의 분포로 p를 인코딩을 했을 때 생기는 비트 낭비량을 확인할 수 있다. 우리의 목표는 $P_\theta$ 가 $P_\text{data}$ 와 가깝도록 만드는 것이기 때문에 $D_{\text{KL}}(P_\text{data} || P_\theta)$ 로 표현할 수 있다. 따라서 KL-Divergence의 값을 확인하여 data를 잘 압축할 수 있는 모델을 선정해야한다. KL이 작을수록, 압축 손실도 작아짐 → 더 나은 모델 $$ D_\text{KL}(P_\text{data} || P_\theta) = \mathbb{E_{x \sim P_\text{data}}}[\log P_\text{data}(x)] - \mathbb{E_{x \sim P_\text{data}}}[\log P_\theta(x)] $$
위 KL을 다음과 같이 분해가 가능하고, 앞 항은 $P_\theta$ 에 영향받지 않는 상수이기 때문에 두번째 항에 집중을 할 것이다. 그렇게 되면 수식은 아래와 같아진다. $$ argmin_\theta \ D_(P_\text{data} || P_\theta) = argmin_\theta -\mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)] = argmax_\theta \ \mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)] $$
그럼 이제 KL을 최소화 하기 위하여 두번째 항을 최대화 하는것이 목표이다. 이 수식을 통하여 알 수 있는 KL의 특징이 있다. 바로 두 모델 간 KL을 비교했을 때 누가 가까운지는 알지만 얼마나 가까운지 (정확한 거리)는 모른다는 것이다. $D_(P_\text{data} || P_{\theta_{1}}) - D_(P_\text{data} || P_{\theta_{2}})$ 가 계산이 되면 상수(첫번째 항)가 사라져서 거리를 모르게 된다. 이제 이 수식을 풀려고 보니, 정리된 수식의 모든 $P_\text{data}$를 우리는 일반적으로 (expected log-likelihood) 구할 수 없다. 왜냐하면 현실에선 이 기대값을 계산할 수 없으므로 주어진 데이터 샘플의 평균으로 근사 해야한다. (empirical log-likelihood) 따라서 데이터 샘플의 평균으로 근사하면 아래와 같은 식이 나오고, 그것을 최대화 하는 $\theta$를 찾는 방향으로 학습을 진행하면 된다."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://goodyoung.github.io/posts/cs236/lecture4/" /><link rel="prev" href="https://goodyoung.github.io/posts/cs236/lecture3/" /><link rel="next" href="https://goodyoung.github.io/posts/cs236/lecture5/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[CS236] 4. Maximum Likelihood Learning",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/goodyoung.github.io\/posts\/cs236\/lecture4\/"
        },"genre": "posts","keywords": "KL-Divergence, CS236","wordcount":  1141 ,
        "url": "https:\/\/goodyoung.github.io\/posts\/cs236\/lecture4\/","datePublished": "2025-06-30T17:00:38+09:00","dateModified": "2025-06-30T17:00:38+09:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "GoodYoung"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Good Young">GoodYoung Dev Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Good Young">GoodYoung Dev Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[CS236] 4. Maximum Likelihood Learning</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://goodyoung.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>GoodYoung</a></span>&nbsp;<span class="post-category">included in <a href="/categories/dl/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>DL</a>&nbsp;<a href="/categories/theory/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Theory</a>&nbsp;<a href="/categories/lecture/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Lecture</a>&nbsp;<a href="/categories/deep-generative-models/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Deep Generative Models</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2025-06-30">2025-06-30</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;1141 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;6 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#kullback-leibler-divergencekl-divergence">Kullback-Leibler divergence(KL-divergence)</a></li>
    <li><a href="#gradient-descent">Gradient Descent</a></li>
    <li><a href="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
    <li><a href="#drawback">Drawback</a></li>
    <li><a href="#summary">Summary</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- image format
<div style="text-align:center;">
<img src="/images/cs231n/lecture4/back-1.png" height="100%" width="80%"> </div>
 -->
<h2 id="개요">개요</h2>
<ol start="0">
<li>이번 포스트에서는 <code>CS236</code> 강의의 4강 내용을 정리한다.</li>
</ol>
<br>
<ol>
<li>3강에선 데이터셋의 분포를 학습하여 <code>Model Family</code>를 파라미터화 하는 방법을 배웠다.</li>
</ol>
<br>
<ol start="2">
<li>이번 4강에서는 <code>데이터셋</code>에 대하여 모델 파라미터 $\theta$ 를 찾는 방법을 배우게 된다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs236/lecture4/first.png" height="85%" width="80%"> </div>
<ol start="3">
<li>3강에서 다뤘던 내용을 다시 한 번 살펴보자. 데이터가 실제 분포 $P_\text{data}$ 로부터 추출된 m개의 샘플 $\mathcal{D}$ 가 있다고 가정을 해보자.</li>
</ol>
<br>
<ol start="4">
<li>그럼 생성 모델의 목표는 모델 $\mathcal{M}$ 에서 $P_\text{data}$ 와 가능한 가장 가까운 $P_\theta$ 를 학습하는 것이다.</li>
</ol>
<ul>
<li>이때의 모델 $\mathcal{M}$ 은 <code>Bayes net</code>이 될 수 있고, <code>FVSBN</code>이 될 수 있는 것 이다.</li>
</ul>
<br>
<ol start="5">
<li>하지만 $P_\theta$ 가 완전히 실제 분포를 포착할 순 없다. 왜냐하면 <code>제한된 data의 문제</code>와 <code>컴퓨팅 파워 문제</code>가 있기 때문이다.</li>
</ol>
<ul>
<li>784개의 이진 픽셀로 이루어진 이미지를 생각해보면, 가능한 모든 이미지는 $\text{2}^\text{784} \approx \text{10}^\text{236}$ 가지이다. 대략 백만 개의 샘플로는 이 공간을 거의 다룰 수 없다.</li>
</ul>
<br>
<ol start="6">
<li>그래서 우리는 $P_\text{data}$ 의 분포를 잘 근사하는 $P_\theta$ 를 선택해야한다. 그렇다면 어떤 것이 잘 근사하는 모델($P_\theta$)일까?</li>
</ol>
<ul>
<li>잘 근사하는 모델은 우리가 하려는 task에 따라 다르다. (<code>Density Estimation</code>에서는 전체 확률 분포를 잘 근사하는 것이 중요, <code>Specific Prediction Task</code>은 특정 예측을 만드는 분포(조건부 확률)가 중요, <code>Structure or Knowledge Discovery</code> 모델 그 자체의 구조가 중요)</li>
</ul>
<br>
<ol start="7">
<li><code>생성의 관점</code>에선 어떤 <code>확률적 추론 쿼리</code>에 답해야 하기 때문에 우린 <code>전체 분포</code>를 배워야한다. 따라서 학습을 <code>Density Estimation</code> 문제로 볼 수 있다.</li>
</ol>
<ul>
<li>여기서 말하는 확률적 추론 쿼리(<em>any probabilistic inference query</em>)란 <code>확률 분포</code>로부터 도출되는 질문들(조건부 확률, 마진, 샘플링 등)을 의미한다.</li>
</ul>
<br>
<ol start="8">
<li>그래서 우리의 목표는 $P_\text{data}$ 에 <strong>가장 가까운</strong> $P_\theta$ 를 만드는 것이 제일 중요하다. 그렇다면 <code>가까운 정도</code>를 어떻게 평가할까? 다음 챕터에서 설명 할 것이다.</li>
</ol>
<h2 id="kullback-leibler-divergencekl-divergence">Kullback-Leibler divergence(KL-divergence)</h2>
<ol start="9">
<li>어떤 두 분포간의 <strong>가까운 정도를 측정</strong>하기 위하여 <code>Kullback-Leibler divergence(KL-divergence)</code>지표를 사용하게 된다. 수식은 아래와 같다.</li>
</ol>
<p>$$D_{\text{KL}}(p || q) = \sum_x p(x) \log \frac{p(x)}{q(x)}$$</p>
<br>
<ol start="10">
<li><code>KL-Divergence</code>는 몇가지 특징이 있다.</li>
</ol>
<ul>
<li>$D_{\text{KL}}(p || q) \geq 0$ 이고, 같을 땐 $p = q$ 일 때 이다.</li>
<li>$D_{\text{KL}}(p || q) \not = D_{\text{KL}}(q || p)$ 으로 비대칭적인 성질을 지닌다.</li>
<li>이 지표는 <code>정보이론 관점</code>에서 p와 q에 기반한 <strong>압축 방식</strong>이 얼마나 잘되는지 보여준다. (p가 진짜 분포이고 q가 학습한 분포)
<ul>
<li>q의 분포로 p를 인코딩을 했을 때 생기는 <strong>비트 낭비량을 확인할 수 있다.</strong></li>
</ul>
</li>
</ul>
<br>
<ol start="11">
<li>우리의 목표는 $P_\theta$ 가 $P_\text{data}$ 와 가깝도록 만드는 것이기 때문에 $D_{\text{KL}}(P_\text{data} || P_\theta)$ 로 표현할 수 있다.</li>
</ol>
<br>
<ol start="12">
<li>따라서 <code>KL-Divergence</code>의 값을 확인하여 data를 잘 압축할 수 있는 모델을 선정해야한다.</li>
</ol>
<ul>
<li><strong>KL이 작을수록, 압축 손실도 작아짐 → 더 나은 모델</strong></li>
</ul>
<br>
<p>$$ D_\text{KL}(P_\text{data} || P_\theta) = \mathbb{E_{x \sim P_\text{data}}}[\log P_\text{data}(x)] - \mathbb{E_{x \sim P_\text{data}}}[\log P_\theta(x)] $$</p>
<ol start="13">
<li>위 KL을 다음과 같이 분해가 가능하고, 앞 항은 $P_\theta$ 에 영향받지 않는 상수이기 때문에 두번째 항에 집중을 할 것이다. 그렇게 되면 수식은 아래와 같아진다.</li>
</ol>
<br>
<p>$$
argmin_\theta \ D_(P_\text{data} || P_\theta) = argmin_\theta -\mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)] = argmax_\theta \ \mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)]
$$</p>
<ol start="14">
<li>그럼 이제 KL을 최소화 하기 위하여 <strong>두번째 항을 최대화</strong> 하는것이 목표이다.</li>
</ol>
<br>
<ol start="15">
<li>이 수식을 통하여 알 수 있는 KL의 특징이 있다. 바로 두 모델 간 KL을 비교했을 때 <strong>누가 가까운지는 알지만</strong> <strong>얼마나 가까운지 (정확한 거리)는 모른다는 것이다.</strong></li>
</ol>
<ul>
<li>$D_(P_\text{data} || P_{\theta_{1}}) - D_(P_\text{data} || P_{\theta_{2}})$ 가 계산이 되면 상수(첫번째 항)가 사라져서 <strong>거리를 모르게 된다.</strong></li>
</ul>
<br>
<ol start="16">
<li>이제 이 수식을 풀려고 보니, 정리된 수식의 <strong>모든</strong> $P_\text{data}$를 우리는 일반적으로 <strong>(expected log-likelihood)</strong> 구할 수 없다.  왜냐하면 현실에선 이 기대값을 <strong>계산할 수 없으므로</strong> <code>주어진 데이터 샘플의 평균</code>으로 <strong>근사 해야한다. (empirical log-likelihood)</strong> 따라서 데이터 샘플의 평균으로 근사하면 아래와 같은 식이 나오고, 그것을 최대화 하는 $\theta$를 찾는 <strong>방향으로 학습을 진행하면 된다.</strong></li>
</ol>
<ul>
<li>이 아이디어는 <code>monte carlo 추정</code>에서 나왔다.</li>
<li>샘플 수가 많아질수록 무작위성은 줄어들고 함수의 실제 기대값에 가까워진다. (분산도 작아진다. -&gt; 근사치가 점점 신뢰 가능해진다.)</li>
</ul>
<p>$$E_D [\log P_\theta(x)] = \frac{1}{|D|} \sum_{x \in D} \log P_\theta(x)$$</p>
<p>$$max_\theta \ \frac{1}{|D|} \sum_{x \in D} \log P_\theta(x)$$</p>
<hr>
<h2 id="gradient-descent">Gradient Descent</h2>
<ol start="17">
<li>지금까지 했던 <code>KL-Divergence</code>와 <code>Monte Carlo</code>의 개념을 <code>Autoregreesive Model</code>에 적용시켜서 학습 데이터 $D$에 대해 $p_\theta(x)$를 근사하게 만들면 다음과 같다.</li>
</ol>
<br>
<p>$$
P_\theta(x) = \prod_{i=1}^n p_{\text{neural}}(x_i \mid x_{&lt;i}; \theta_i)
$$</p>
<p>$$
\log \mathcal{L}(\theta, D) = \sum_{j=1}^m \sum_{i=1}^n \log p_{\text{neural}}(x_i^{(j)} \mid x_{&lt;i}^{(j)}; \theta_i)
$$</p>
<ul>
<li>$j$: Datapoint, $i$: Datapoint의 변수</li>
</ul>
<br>
<ol start="18">
<li>하지만 이것은 <code>closed form</code>이 아니여서 최적화가 필요하다. 최적화를 하는 방식은 <code>경사 하강법(gradient descent)</code>를 이용하는 것이다.</li>
</ol>
<ul>
<li><code>비선형/비볼록</code>이라 <code>closed-form</code>인 경우 경사 하강법을 이용하면 꽤 잘 풀리는 경우가 많다.</li>
</ul>
<br>
<ol start="19">
<li>다음은 해당 식을 가지고 <strong>경사 하강법</strong>을 하는 단계이다.</li>
</ol>
<ul>
<li>$\theta_0$: 랜덤 초기화</li>
<li>$\nabla_\theta \log \mathcal{L}(\theta, D)$: 기울기 계산</li>
<li>$\theta_{t+1} = \theta_t + \alpha_t \nabla_\theta \log \mathcal{L}(\theta, D)$: 의 식을 가지고 업데이트</li>
<li>t가 T에 수렴할 때 까지 반복. (최적화의 $\theta$로 수렴하게 된다.)</li>
</ul>
<hr>
<h2 id="stochastic-gradient-descent">Stochastic Gradient Descent</h2>
<ol start="20">
<li>위와 같이 경사하강법으로 하게 되면 파라미터의 공유가 없다면, 모든 데이터 포인트를 각각 분리해서 최적화 한다. 이게 <strong>데이터 포인트의 수가 많아지면</strong> 오버헤드가 생길 수 있다.</li>
</ol>
<br>
<ol start="21">
<li>따라서 <code>Stochastic Gradient Descent</code>가 나오게 되었다. 이 방법은 모든 데이터셋을 최적화에 활용하는 것이 아니라, 데이터셋 $D$를 나눈 배치(미니 배치)에서 하나의 데이터를 가지고 파라미터를 업데이트 하는 방법이다.</li>
</ol>
<ul>
<li>이 방법은 확률적 근사를 한 것이고, 위에서 나온 <code>Monte Carlo</code>의 방법과 같다.</li>
</ul>
<br>
<p>$$
\nabla_\theta \ell(\theta) = \sum_{j=1}^m \sum_{i=1}^n \nabla_\theta \log p_{\text{neural}}(x_i^{(j)} \mid x_{&lt;i}^{(j)}; \theta_i)
$$</p>
<ol start="22">
<li>위은 gradient 식을 다시 나타낸 것인데 위 식에서 $D$가 만약에 클 때 <code>Monte Carlo</code>를 사용하여 식을 변형할 것이다. 그렇게 되면 아래의 식과 같이 된다.</li>
</ol>
<br>
<p>$$
\begin{aligned}
\nabla_\theta \ell(\theta) &amp;=m\sum_{j=1}^m\frac{1}{m} \sum_{i=1}^n \nabla_\theta \log p_{\text{neural}}(x_i^{(j)} \mid x_{&lt;i}^{(j)}; \theta_i) (by \ \text{Monte Carlo})\\
&amp;= m \cdot \mathbb{E_{x^{(j)} \sim D}} \left[ \sum_{i=1}^n \nabla_\theta \log p_{\text{neural}}(x_i^{(j)} \mid x_{&lt;i}^{(j)}; \theta_i) \right]
\end{aligned}
$$</p>
<ol start="23">
<li>위 식을 보면 <code>uniform 분포</code>라는 가정과 함께 데이터셋에서 샘플을 추출할 수 있고, 해당 <strong>샘플에 대해서만</strong> 기울기를 평가하고 모델 학습에 이 비선형성을 부여할 수 있게 된다.</li>
</ol>
<hr>
<h2 id="drawback">Drawback</h2>
<ol start="24">
<li>지금까지의 학습 방식들은 쉽게 과적합을 할 수 있는 문제가 있다. 따라서 모델이 unseen data에 대해서 잘 맞추는 <code>generalization</code>이 제일 중요하다.</li>
</ol>
<br>
<ol start="25">
<li>일반화를 하기 위해 학습에서 <code>정규화</code>를 해야한다.</li>
</ol>
<ul>
<li>너무 정규화를 진행하면 모델이 단순해지는 한계인 bias가 일어나고(under-fitting), 정규화를 하지 않으면 모델이 너무 데이터에 fit해지는 한계인 variance(over-fitting)이 일어난다.</li>
</ul>
<br>
<ol start="26">
<li>이런 것을 막기 위해선 <code>weight sharing</code>, <code>regularization</code>, <code>hold-out (k-fold)</code>등의 방법이 있다.</li>
</ol>
<hr>
<h2 id="summary">Summary</h2>
<ol start="27">
<li>긴 흐름을 단순화하여 정리할 필요가 있어보여 이번 챕터를 정리하려고 한다.</li>
</ol>
<br>
<ol start="28">
<li>이번 챕터에서는 생성 모델의 학습 방법에 대해 다루었다. <strong>생성 모델의 목표는</strong> $P_\text{data}$를 잘 근사하는(가까운) $P_\theta$를 만드는 것이 중요한데 두 분포가 잘 근사하는(가까운) 정도를 측정하기 위하여 <code>KL-Divergence</code>가 도입되었다.</li>
</ol>
<br>
<ol start="29">
<li><code>KL-divergence</code>의 수식을 전개해 보면,이를 최소화하는 것은 결국 다음 <code>log-likelihood 기대값</code>을 <strong>최대화하는</strong> 문제와 같다는 것을 알 수 있다: ($argmax_\theta \ \mathbb{E_{x \sim P_{\text{data}}}} [\log P_\theta(x)]$)</li>
</ol>
<br>
<ol start="30">
<li>식을 풀려고 봤더니 $P_\text{data}$ 때문에 식을 직접적으로 계산할 수 없다. 이를 해결하기 위해 <code>monte-carlo</code>추정을 사용한다. 이는 모든 $P_\text{data}$를 사용하는 것이 아닌 그 중에 샘플을 추출한 데이터 샘플의 평균을 사용하여 기대값을 근사하는 방법(기대값 -&gt; 평균)이다. 이 방법을 사용하면 <code>MLE(Maximum Likelihood Estimation)</code>의 수식이 나오게 되는 것이다. ($max_\theta \ \frac{1}{|D|} \sum_{x \in D} \log P_\theta(x)$)</li>
</ol>
<br>
<ol start="31">
<li>이렇게 배운 학습 방식들을 <code>Autoregressive Model</code> 구조에 맞게 적용해보려고 한다. (학습 데이터 D에 대해 $p_\theta(x)$를 $p_\text{data}$에 근사하게 학습할 수 있다.) ($\log \mathcal{L}(\theta, D) = \sum_{j=1}^m \sum_{i=1}^n \log p_{\text{neural}}(x_i^{(j)} \mid x_{&lt;i}^{(j)}; \theta_i)$)</li>
</ol>
<br>
<ol start="32">
<li>하지만 이때 유도된 식은 계산할 수 없어서, <code>경사 하강법(gradient descent)</code>을 사용하여 파라미터($\theta$) 최적화를 진행한다.</li>
</ol>
<br>
<ol start="33">
<li>이 <code>경사 하강법(gradient descent)</code>은 데이터 양이 많아지게 되면 모든 데이터 포인트를 분리해서 계산하여 오버 헤드가 생긴다는 단점을 지니고 있어, <code>확률적 경사 하강법(stochastic gradient descent)</code>을 사용해 배치마다 하나의 데이터를 사용하여 파라미터 최적화를 진행하는 방법도 있다.</li>
</ol>
<br>
<ol start="34">
<li>난 여기까지 정리하면서 의문이 들었다. 왜 Autoregressive Model에서만 최적해를 못구해서 경사 하강법이 나온 것인가?</li>
</ol>
<ul>
<li>내가 남긴 의문에 찾은 답을 하자면 다음과 같다.</li>
<li>동전 예제, 이항 분포처럼 <strong>단순한 경우엔</strong> <code>Monte Carlo 근사</code>만 해도 최적화가 가능(직접 미분해서 최대화의 지점을 찾을 수 있음)</li>
<li><code>Autoregressive Model</code> 처럼 구조가 복잡한 경우엔 <code>경사 하강법</code>으로 해결해야 한다. (미분은 가능하지만, 해석적으로 $\theta$를 찾을 수 없기 때문)</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://deepgenerativemodels.github.io/" target="_blank" rel="noopener noreffer ">https://deepgenerativemodels.github.io/</a></li>
<li><a href="https://www.youtube.com/watch?v=tRArbBf-AbI&amp;list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&amp;index=3&amp;t=4s" target="_blank" rel="noopener noreffer ">https://www.youtube.com/watch?v=tRArbBf-AbI&list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&index=3&t=4s</a></li>
<li><a href="https://wikidocs.net/228835" target="_blank" rel="noopener noreffer ">https://wikidocs.net/228835</a></li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2025-06-30</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://goodyoung.github.io/posts/cs236/lecture4/" data-title="[CS236] 4. Maximum Likelihood Learning" data-hashtags="KL-Divergence,CS236"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://goodyoung.github.io/posts/cs236/lecture4/" data-hashtag="KL-Divergence"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://goodyoung.github.io/posts/cs236/lecture4/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://goodyoung.github.io/posts/cs236/lecture4/" data-title="[CS236] 4. Maximum Likelihood Learning"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://goodyoung.github.io/posts/cs236/lecture4/" data-title="[CS236] 4. Maximum Likelihood Learning"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://goodyoung.github.io/posts/cs236/lecture4/" data-title="[CS236] 4. Maximum Likelihood Learning"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://goodyoung.github.io/posts/cs236/lecture4/" data-title="[CS236] 4. Maximum Likelihood Learning" data-description=""><i class="fab fa-blogger fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/kl-divergence/">KL-Divergence</a>,&nbsp;<a href="/tags/cs236/">CS236</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/cs236/lecture3/" class="prev" rel="prev" title="[CS236] 3. Autoregressive Models"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[CS236] 3. Autoregressive Models</a>
            <a href="/posts/cs236/lecture5/" class="next" rel="next" title="[CS236] 5. Latent Variable Models">[CS236] 5. Latent Variable Models<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
  
</footer>
</div>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"goodylung/blog-comment"}},"lightgallery":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-86432198-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body>
</html>
