<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[CS236] 6. Latent Variable Models-2 - Good Young</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="[CS236] 6. Latent Variable Models-2" />
<meta property="og:description" content="개요 이번 포스트에서는 CS236 강의의 6강 내용과 7강의 앞부분을 설명한다. 7강에 VAE 내용이 포함이 되었기 때문이다. 지난 포스트에서 Latent Variable Model에서 z라는 latent variable이 여러개 있을 때 Mixture of Gaussian이 된다는 점, 그 수많은 분포에서 x의 값을 구하는 방법(marginal likelihood) 등에 대해서 배웠고 그 분포를 최적화 하는 과정에서 Evidence Lower Bound(ELBO) 개념이 나오게 되었다. ELBO 개념이 나오면서, 수식들을 전개했는데 이어서 설명하겠다. Evidence Lower Bound(ELBO) - 2 $$ \begin{aligned} \log p(x; \theta) &amp;\geq \sum_{z} q(z) \log \left( \frac{p_\theta(x, z)}{q(z)} \right) \\ &amp;= \sum_{z} q(z) \log p_\theta(x, z) - \sum_{z} q(z) \log q(z) \\ &amp;= \sum_{z} q(z) \log p_\theta(x, z) &#43; H(q) \ \text{(H(q) is entropy)} \\ \end{aligned} $$ $$ \begin{aligned} &amp;\text{Equality holds if } q = p(z \mid x; \theta)\\ &amp;\log p(x; \theta) = \sum_{z} q(z) \log p(z, x; \theta) &#43; H(q) \end{aligned} $$
지난 포스트에서 위 식이 나오게 된 이유를 간단하게 정리해보겠다. 우리는 latent variable z를 직접 관측할 수 없기 때문에, 이를 추론하기 위하여 보조의 분포 q를 도입했다. 이때 x는 관측할 수 있는 부분이고 z는 보이지 않는 부분이다. 이 상황에서 우리는 x만 관찰될 때 z 분포를 근사하고자 하며, 이 과정에서 $logp(x)$ 를 직접 계산하기 어렵기 때문에, 이 식을 최적화 가능한 ELBO 식이 등장하게 나오게 된 것이다. 이제 본론으로 넘어와서, 2번째 식을 살펴보자면 $\sum_{z} q(z) \log p_\theta(x, z)$ 이 항은 q모델을 사용하여 z부분을 추론할 때 x,z 부분이 모두 관찰될 떄의 평균 로그 확률이다. (모든 것이 관찰된다. 이는 본질적으로 생성 모델이다.) $\sum_{z} q(z) \log q(z)$ 이 항은 q함수이고, q의 entropy라고 볼 수 있다. (q가 얼마나 무작위적인지 알려주는 양이다.) $$D_{\mathrm{KL}}(q(z) \parallel p(z \mid x; \theta)) = - \sum_{z} q(z) \log p(z, x; \theta) &#43; \log p(x; \theta) - H(q) \geq 0$$
이제 Equality 부분을 설명할 것이다. KL 식을 전개하면 위와 같은 식을 얻을 수 있는데 오른쪽 항에서 $\log p(z, x; \theta)$ 만 남기고 다 넘기면 ELBO의 식과 동일해지는 것을 확인할 수 있다. 그렇다면 어떻게 전개를 하면 위와 같은 식이 나왔을까? KL의 값은 항상 0보다 크거나 같다의 성질을 이용한다. 그 후, 기존 KL의 식에서 $p(z \mid x; \theta)$ 을 Bayes 정리를 활용해서 $p(z \mid x; \theta) = \frac{p(x, z; \theta)}{p(x; \theta)}$ 로 변형하여 식 전개하면 위와 같은 식이 나온다. 그렇기 때문에 만약 $ q = p(z \mid x; \theta)$ 라면 KL의 값이 0이 되기 때문에 부등식이 등식이 되는 것이다. 하지만 우리는 $p(z|x;\theta)$가 계산이 불가능하다는 것을 안다. GMM (lecture 5 12-17)에서 심층 가우시안 분포를 사용해 $p_\theta(x|z)$ 는 z의 분포가 정해져 있었기 때문에 구할 수 있었다. (lecture 5 16) 하지만 $p(z|x;\theta) = \frac{p(z)p_\theta(x|z)}{p_\theta(x)}$ 이기 때문에, $p(x)$ 를 구할 수 없다.(lecture 5 23) 따라서 $p(z|x;\theta)$ 도 계산이 불가능하다. 사실 따지고 보면 만약 posterior가 계산이 가능했으면 위 ELBO식도 필요가 없다. 결국, q분포가 $p(z \mid x; \theta)$에 최대한 가까운 q를 선택해야 하는 것을 알 수 있다. 이는 앞으로 나올 Variational Inference의 이론적 도구로써 작용이 될 것이다. 정리하자면 추정이 불가능한 분포를 근사하는 q를 두어 이 분포를 최적화하여 가장 강력한 lower bound를 찾는 것이 최종 목표인 것이다. 따라서 q의 역할을 하는 별도의 신경망을 두고, p와 q를 공동으로 최적화하여 ELBO를 최대화 시킨다. 조금 더 나아가, VAE의 인코더는 q가 되고 디코더는 p가 된다. Variational Inference Variational Auto Encoder(VAE) 모델에서는 decoder인 $p(x|z) = \mathcal{N}(\mu_\theta(z), \Sigma_\theta(z))$ 의 neural network가 있으면 이것을 뒤집은 encoder의 역할을 하는 $p(z|x;\theta)$ 를 계산하여 x가 주어지고 이 x를 생성할 가능성이 높은 z를 찾으려고 한다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://goodyoung.github.io/posts/cs236/lecture6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-07-26T14:23:31+09:00" />
<meta property="article:modified_time" content="2025-07-26T14:23:31+09:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[CS236] 6. Latent Variable Models-2"/>
<meta name="twitter:description" content="개요 이번 포스트에서는 CS236 강의의 6강 내용과 7강의 앞부분을 설명한다. 7강에 VAE 내용이 포함이 되었기 때문이다. 지난 포스트에서 Latent Variable Model에서 z라는 latent variable이 여러개 있을 때 Mixture of Gaussian이 된다는 점, 그 수많은 분포에서 x의 값을 구하는 방법(marginal likelihood) 등에 대해서 배웠고 그 분포를 최적화 하는 과정에서 Evidence Lower Bound(ELBO) 개념이 나오게 되었다. ELBO 개념이 나오면서, 수식들을 전개했는데 이어서 설명하겠다. Evidence Lower Bound(ELBO) - 2 $$ \begin{aligned} \log p(x; \theta) &amp;\geq \sum_{z} q(z) \log \left( \frac{p_\theta(x, z)}{q(z)} \right) \\ &amp;= \sum_{z} q(z) \log p_\theta(x, z) - \sum_{z} q(z) \log q(z) \\ &amp;= \sum_{z} q(z) \log p_\theta(x, z) &#43; H(q) \ \text{(H(q) is entropy)} \\ \end{aligned} $$ $$ \begin{aligned} &amp;\text{Equality holds if } q = p(z \mid x; \theta)\\ &amp;\log p(x; \theta) = \sum_{z} q(z) \log p(z, x; \theta) &#43; H(q) \end{aligned} $$
지난 포스트에서 위 식이 나오게 된 이유를 간단하게 정리해보겠다. 우리는 latent variable z를 직접 관측할 수 없기 때문에, 이를 추론하기 위하여 보조의 분포 q를 도입했다. 이때 x는 관측할 수 있는 부분이고 z는 보이지 않는 부분이다. 이 상황에서 우리는 x만 관찰될 때 z 분포를 근사하고자 하며, 이 과정에서 $logp(x)$ 를 직접 계산하기 어렵기 때문에, 이 식을 최적화 가능한 ELBO 식이 등장하게 나오게 된 것이다. 이제 본론으로 넘어와서, 2번째 식을 살펴보자면 $\sum_{z} q(z) \log p_\theta(x, z)$ 이 항은 q모델을 사용하여 z부분을 추론할 때 x,z 부분이 모두 관찰될 떄의 평균 로그 확률이다. (모든 것이 관찰된다. 이는 본질적으로 생성 모델이다.) $\sum_{z} q(z) \log q(z)$ 이 항은 q함수이고, q의 entropy라고 볼 수 있다. (q가 얼마나 무작위적인지 알려주는 양이다.) $$D_{\mathrm{KL}}(q(z) \parallel p(z \mid x; \theta)) = - \sum_{z} q(z) \log p(z, x; \theta) &#43; \log p(x; \theta) - H(q) \geq 0$$
이제 Equality 부분을 설명할 것이다. KL 식을 전개하면 위와 같은 식을 얻을 수 있는데 오른쪽 항에서 $\log p(z, x; \theta)$ 만 남기고 다 넘기면 ELBO의 식과 동일해지는 것을 확인할 수 있다. 그렇다면 어떻게 전개를 하면 위와 같은 식이 나왔을까? KL의 값은 항상 0보다 크거나 같다의 성질을 이용한다. 그 후, 기존 KL의 식에서 $p(z \mid x; \theta)$ 을 Bayes 정리를 활용해서 $p(z \mid x; \theta) = \frac{p(x, z; \theta)}{p(x; \theta)}$ 로 변형하여 식 전개하면 위와 같은 식이 나온다. 그렇기 때문에 만약 $ q = p(z \mid x; \theta)$ 라면 KL의 값이 0이 되기 때문에 부등식이 등식이 되는 것이다. 하지만 우리는 $p(z|x;\theta)$가 계산이 불가능하다는 것을 안다. GMM (lecture 5 12-17)에서 심층 가우시안 분포를 사용해 $p_\theta(x|z)$ 는 z의 분포가 정해져 있었기 때문에 구할 수 있었다. (lecture 5 16) 하지만 $p(z|x;\theta) = \frac{p(z)p_\theta(x|z)}{p_\theta(x)}$ 이기 때문에, $p(x)$ 를 구할 수 없다.(lecture 5 23) 따라서 $p(z|x;\theta)$ 도 계산이 불가능하다. 사실 따지고 보면 만약 posterior가 계산이 가능했으면 위 ELBO식도 필요가 없다. 결국, q분포가 $p(z \mid x; \theta)$에 최대한 가까운 q를 선택해야 하는 것을 알 수 있다. 이는 앞으로 나올 Variational Inference의 이론적 도구로써 작용이 될 것이다. 정리하자면 추정이 불가능한 분포를 근사하는 q를 두어 이 분포를 최적화하여 가장 강력한 lower bound를 찾는 것이 최종 목표인 것이다. 따라서 q의 역할을 하는 별도의 신경망을 두고, p와 q를 공동으로 최적화하여 ELBO를 최대화 시킨다. 조금 더 나아가, VAE의 인코더는 q가 되고 디코더는 p가 된다. Variational Inference Variational Auto Encoder(VAE) 모델에서는 decoder인 $p(x|z) = \mathcal{N}(\mu_\theta(z), \Sigma_\theta(z))$ 의 neural network가 있으면 이것을 뒤집은 encoder의 역할을 하는 $p(z|x;\theta)$ 를 계산하여 x가 주어지고 이 x를 생성할 가능성이 높은 z를 찾으려고 한다."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://goodyoung.github.io/posts/cs236/lecture6/" /><link rel="prev" href="https://goodyoung.github.io/posts/cs236/lecture5/" /><link rel="next" href="https://goodyoung.github.io/posts/cs236/lecture7/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[CS236] 6. Latent Variable Models-2",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/goodyoung.github.io\/posts\/cs236\/lecture6\/"
        },"genre": "posts","keywords": "Latent Variable Models, VAE, CS236","wordcount":  2617 ,
        "url": "https:\/\/goodyoung.github.io\/posts\/cs236\/lecture6\/","datePublished": "2025-07-26T14:23:31+09:00","dateModified": "2025-07-26T14:23:31+09:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "GoodYoung"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Good Young">GoodYoung Dev Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Good Young">GoodYoung Dev Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[CS236] 6. Latent Variable Models-2</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://goodyoung.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>GoodYoung</a></span>&nbsp;<span class="post-category">included in <a href="/categories/dl/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>DL</a>&nbsp;<a href="/categories/theory/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Theory</a>&nbsp;<a href="/categories/lecture/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Lecture</a>&nbsp;<a href="/categories/deep-generative-models/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Deep Generative Models</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2025-07-26">2025-07-26</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;2617 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;13 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#evidence-lower-boundelbo---2">Evidence Lower Bound(ELBO) - 2</a></li>
    <li><a href="#variational-inference">Variational Inference</a></li>
    <li><a href="#stochastic-variational-inference-svi">Stochastic Variational Inference (SVI)</a></li>
    <li><a href="#reparameterization-trick">Reparameterization Trick</a></li>
    <li><a href="#amortized-inference">Amortized Inference</a></li>
    <li><a href="#autoencoder-perspective">Autoencoder Perspective</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- image format
<div style="text-align:center;">
<img src="/images/cs231n/lecture4/back-1.png" height="100%" width="80%"> </div>
 -->
<h2 id="개요">개요</h2>
<ol start="0">
<li>이번 포스트에서는 <code>CS236</code> 강의의 <code>6강</code> 내용과 <code>7강</code>의 앞부분을 설명한다.</li>
</ol>
<ul>
<li>7강에 <code>VAE</code> 내용이 포함이 되었기 때문이다.</li>
</ul>
<br>
<ol>
<li>지난 포스트에서 <code>Latent Variable Model</code>에서 z라는 latent variable이 여러개 있을 때 <code>Mixture of Gaussian</code>이 된다는 점, 그 수많은 분포에서 x의 값을 구하는 방법(<code>marginal likelihood</code>) 등에 대해서 배웠고 그 분포를 최적화 하는 과정에서 <code>Evidence Lower Bound(ELBO)</code> 개념이 나오게 되었다.</li>
</ol>
<br>
<ol start="2">
<li>ELBO 개념이 나오면서, 수식들을 전개했는데 이어서 설명하겠다.</li>
</ol>
<hr>
<h2 id="evidence-lower-boundelbo---2">Evidence Lower Bound(ELBO) - 2</h2>
<p>$$
\begin{aligned}
\log p(x; \theta) &amp;\geq \sum_{z} q(z) \log \left( \frac{p_\theta(x, z)}{q(z)} \right) \\
&amp;= \sum_{z} q(z) \log p_\theta(x, z) - \sum_{z} q(z) \log q(z) \\
&amp;= \sum_{z} q(z) \log p_\theta(x, z) + H(q) \ \text{(H(q) is entropy)} \\
\end{aligned}
$$
$$
\begin{aligned}
&amp;\text{Equality holds if } q = p(z \mid x; \theta)\\
&amp;\log p(x; \theta) = \sum_{z} q(z) \log p(z, x; \theta) + H(q)
\end{aligned}
$$</p>
<ol start="3">
<li>지난 포스트에서 위 식이 나오게 된 이유를 간단하게 정리해보겠다. 우리는 <code>latent variable z</code>를 직접 관측할 수 없기 때문에, 이를 추론하기 위하여 <code>보조의 분포 q</code>를 도입했다. 이때 x는 관측할 수 있는 부분이고 <strong>z는 보이지 않는 부분이다.</strong> 이 상황에서 우리는 x만 관찰될 때 z 분포를 근사하고자 하며, 이 과정에서 $logp(x)$ 를 직접 계산하기 어렵기 때문에, 이 식을 최적화 가능한 ELBO 식이 등장하게 나오게 된 것이다.</li>
</ol>
<br>
<ol start="4">
<li>이제 본론으로 넘어와서, 2번째 식을 살펴보자면 $\sum_{z} q(z) \log p_\theta(x, z)$ 이 항은 q모델을 사용하여 z부분을 추론할 때 x,z 부분이 모두 관찰될 떄의 평균 로그 확률이다. (모든 것이 관찰된다. 이는 본질적으로 <code>생성 모델</code>이다.) $\sum_{z} q(z) \log q(z)$ 이 항은 q함수이고, q의 entropy라고 볼 수 있다. (q가 얼마나 무작위적인지 알려주는 양이다.)</li>
</ol>
<br>
<p>$$D_{\mathrm{KL}}(q(z) \parallel p(z \mid x; \theta)) = - \sum_{z} q(z) \log p(z, x; \theta) + \log p(x; \theta) - H(q) \geq 0$$</p>
<ol start="5">
<li>이제 Equality 부분을 설명할 것이다. KL 식을 전개하면 위와 같은 식을 얻을 수 있는데 오른쪽 항에서 $\log p(z, x; \theta)$ 만 남기고 다 넘기면 <code>ELBO</code>의 식과 <strong>동일해지는 것을 확인할 수 있다.</strong>
<ul>
<li>그렇다면 어떻게 전개를 하면 위와 같은 식이 나왔을까?</li>
<li>KL의 값은 <strong>항상 0보다 크거나 같다</strong>의 성질을 이용한다.</li>
<li>그 후, 기존 KL의 식에서 $p(z \mid x; \theta)$ 을 Bayes 정리를 활용해서 $p(z \mid x; \theta) = \frac{p(x, z; \theta)}{p(x; \theta)}$ 로 변형하여 식 전개하면 위와 같은 식이 나온다.</li>
</ul>
</li>
</ol>
<br>
<ol start="6">
<li>그렇기 때문에 만약 $ q = p(z \mid x; \theta)$ 라면 KL의 값이 0이 되기 때문에 <strong>부등식이 등식</strong>이 되는 것이다.</li>
</ol>
<br>
<ol start="7">
<li>하지만 우리는 $p(z|x;\theta)$가 <strong>계산이 불가능하다는 것을 안다.</strong>
<ul>
<li><code>GMM (lecture 5 12-17)</code>에서 심층 가우시안 분포를 사용해 $p_\theta(x|z)$ 는 <strong>z의 분포가 정해져 있었기 때문에</strong> 구할 수 있었다. <code>(lecture 5 16)</code></li>
<li>하지만 $p(z|x;\theta) = \frac{p(z)p_\theta(x|z)}{p_\theta(x)}$ 이기 때문에, $p(x)$ 를 구할 수 없다.<code>(lecture 5 23)</code></li>
<li>따라서 $p(z|x;\theta)$ 도 계산이 불가능하다. 사실 따지고 보면 만약 posterior가 계산이 가능했으면 위 <code>ELBO</code>식도 <strong>필요가 없다.</strong></li>
</ul>
</li>
</ol>
<br>
<ol start="8">
<li>결국, q분포가 $p(z \mid x; \theta)$에 <strong>최대한 가까운 q를 선택해야</strong> 하는 것을 알 수 있다. 이는 앞으로 나올 <code>Variational Inference</code>의 <code>이론적 도구로써</code> 작용이 될 것이다.
<ul>
<li>정리하자면 <code>추정이 불가능한 분포를 근사하는 q</code>를 두어 이 분포를 최적화하여 <code>가장 강력한 lower bound</code>를 찾는 것이 최종 목표인 것이다.</li>
<li>따라서 q의 역할을 하는 <strong>별도의 신경망을 두고</strong>, p와 q를 <strong>공동으로 최적화하여</strong> <code>ELBO</code>를 최대화 시킨다.</li>
<li>조금 더 나아가, <code>VAE</code>의 인코더는 q가 되고 디코더는 p가 된다.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="variational-inference">Variational Inference</h2>
<ol start="9">
<li><code>Variational Auto Encoder(VAE)</code> 모델에서는 <code>decoder</code>인 $p(x|z) = \mathcal{N}(\mu_\theta(z), \Sigma_\theta(z))$ 의 <code>neural network</code>가 있으면 이것을 뒤집은 <code>encoder</code>의 역할을 하는 $p(z|x;\theta)$ 를 계산하여 x가 주어지고 이 x를 생성할 가능성이 높은 z를 찾으려고 한다. 하지만 확률 모델을 단순히 뒤집는 것이 <strong>쉬운 문제는 아니다.</strong> 따라서 이를 해결하기 위한 방법은 지금까지 우리가 배워왔던 방법을 이용하면 된다.</li>
</ol>
<br>
<ol start="10">
<li>우리는 <code>ELBO</code>식을 보면서 <strong>계산 불가능한 식</strong>을 보조 분포를 정의하여 계산 불가능한 식의 분포를 근사하여 추론하는 방법을 배웠다.</li>
</ol>
<br>
<ol start="11">
<li>따라서 이를 적용하기 위하여 우리는 <code>latent variable z</code>에 대한 분포군을 정의할 것이다. 분포 q를 아래와 같이 정의할 수 있다.
<ul>
<li>$q(z;\phi) = \mathcal{N}(\phi_1, \phi_2)$</li>
<li>variational parameter $\phi$ 의 집합을 통해 매개변수화될 것이다.</li>
<li>이를 활용하여 <code>ELBO</code>를 활용하여 q와 p 모두 <strong>공동으로 최적화 하려고 한다.</strong></li>
</ul>
</li>
</ol>
<br>
<ol start="12">
<li>바로 이 내용이 <code>Varaiational Inference</code>이다. 반복해서 정리하자면, 우리가 알고있지만 <strong>계산하기 어려운</strong> <code>posterior 분포</code>를 대신하여 <code>추론 가능한 분포 q</code>를 도입하고 이를 <strong>최대한 가깝게 근사</strong>하게 시도하는 방법이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs236/lecture6/vae-1.png" height="50%" width="50%"> </div>
<ol start="13">
<li>좀 더 간단하게 시각화를 통하여 이해해보면, <code>파란색: p(z|x)</code> 분포가 있으면, 이것에 최대한 <code>비슷한 가우시안 분포</code>를 찾으려고 하는 것이다. 이걸 vae 관점으로 생각해보면 비슷한 가우시안 분포를 찾을 때 parameter $\phi$ 를 사용하여 최적화 하는 것이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs236/lecture6/elbo.png" height="50%" width="50%"> </div>
<p>$$
\begin{aligned}
\log p(\mathbf{x}; \theta)
&amp;\geq \sum_{z} q(z; \phi) \log p(z, \mathbf{x}; \theta) + H(q(z; \phi))
= \mathcal{L}(\mathbf{x}; \theta, \phi) \quad \text{(ELBO)} \\
\log p(\mathbf{x}; \theta)
&amp;= \mathcal{L}(\mathbf{x}; \theta, \phi) + D_{KL}(q(z; \phi) \parallel p(z \mid \mathbf{x}; \theta))
\end{aligned}
$$</p>
<ol start="14">
<li><code>Variational Inference</code>를 하면 p와 q의 공동의 조합으로 <code>ELBO</code>를 최적화를 할 것이다. 일단 위 수식을 살펴보면 $\log p(\mathbf{x}; \theta) $ 는 <code>ELBO</code>와 <code>KL-Divergence</code>의 합친 것으로 확인 할 수 있고 (<code>4번 수식 참고</code>) 따라서 $\theta$ 와 $\phi$ 으로 해당 표현식을 최적화 하는 것을 확인할 수 있다.</li>
</ol>
<br>
<ol start="15">
<li>지금까지는 <strong>단일 데이터셋 x에 대해서만 수식을 설명</strong>했다. 이제 모든 데이터셋 ($\mathcal{D}$)에 적용시켜 볼 것이다. 수식은 아래와 같다.
<ul>
<li>수식을 확인하면 기존 $\log p$ 에 대하여 $\phi$ 를 사용하여 <code>ELBO</code>를 지정한 것을 확인할 수 있다.</li>
</ul>
</li>
</ol>
<br>
<p>$$\ell(\theta; \mathcal{D}) = \sum_{x^i \in \mathcal{D}} \log p(x^i; \theta) \geq \sum_{x^i \in \mathcal{D}} \mathcal{L}(x^i; \theta, \phi^i)$$</p>
<p>$$\max_{\theta} \ \ell(\theta; \mathcal{D}) \ \geq \ \max_{\theta, \phi^1, \cdots, \phi^M} \ \sum_{x^i \in \mathcal{D}} \mathcal{L}(x^i; \theta, \phi^i)$$</p>
<ol start="16">
<li>이때 생각해야할 점이 있다. 전체 데이터셋이기 때문에, 각 데이터 포인트 ($x^i$) 마다 posterior($\log p$)가 <strong>다른 분포</strong>로 나타나야한다. 그렇기 때문에 식을 자세히 확인하면 $\phi^i$ 로 나타나있는 것을 확인할 수 있다.
<ul>
<li>$x^i$ 에 대해 가장 posterior에 근접한 elbo를 찾은 다음, 이 파라미터들을 공동으로 최적화한다.</li>
<li>$\theta$ 가 <strong>모든 데이터 포인트에서 공통적이더라도</strong>, 추론하는 잠재 변수의 값은 달라야한다.
<ul>
<li>데이터 포인트 $x^i$ 마다 잠재 변수는 다를 것이기 때문이다.</li>
<li>그럼 최적의 잠재 변수 분포 $q(z|x^i ; \phi^{i,*})$  가 나오면 $\theta$ 는 공통된 decoder이기 때문에, <strong>어떤 z에 대해서든지 x를 생성해낼 수 있어야 한다.</strong></li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="stochastic-variational-inference-svi">Stochastic Variational Inference (SVI)</h2>
<ol start="17">
<li>그렇다면 이 $\mathcal{L}(\mathbf{x}^i; \theta, \phi^i)$ (<code>ELBO</code>)식을 이제 풀어볼 시간이 왔다.</li>
</ol>
<br>
<ol start="18">
<li>해당 목적식을 훈련때 최적화 하기 위해서, <strong>우리가 배운 방법 중 하나</strong>는 목적 함수(<code>ELBO</code>)에 대해 <code>gradient descent</code>을 하는 것이다. (참고: <a href="https://goodyoung.github.io/posts/cs236/lecture4/" target="_blank" rel="noopener noreffer ">lecture 4 17-19</a>)</li>
</ol>
<br>
<ol start="19">
<li>그렇다면 <code>gradient descent</code>의 순서를 보자.
<ul>
<li>
<p>$\theta,\phi^1, \phi^2, \cdots, \phi^M$: 랜덤 초기화</p>
</li>
<li>
<p>$\mathbf{x}^i \sim \mathcal{D}$ 에서 데이터 포인트 무작위 선택</p>
</li>
<li>
<p>$\mathcal{L}(\mathbf{x}^i; \theta, \phi^i)$ 식을 학습해 $\phi^i$ 를 $\phi^{i,*}$ 으로 <strong>최적화</strong> (이때 $\theta$ 는 고정):</p>
<ul>
<li>$\phi^i \leftarrow \phi^i + \eta \nabla_{\phi^i} \mathcal{L}(\mathbf{x}^i; \theta, \phi^i)$ 으로 gradient update</li>
<li>위 과정을 반복하여 $\phi^{i,*} \approx \arg\max_{\phi} \mathcal{L}(\mathbf{x}^i; \theta, \phi)$ 로 수렴</li>
</ul>
</li>
<li>
<p>$\phi^{i,*}$ 를 가지고  $\theta$ 에 대해 최적화 (실제 decoder 최적화):</p>
<ul>
<li>$\nabla_\theta \mathcal{L}(\mathbf{x}^i; \theta, \phi^{i,})$ 으로 기울기 계산</li>
<li>파라미터 업데이트: $\theta_{t+1} = \theta_t + \alpha_t \nabla_\theta \mathcal{L}(\mathbf{x}^i; \theta, \phi^{i,})$</li>
<li>위 과정을 $t \to T$ 까지 반복하여 θ의 최적값에 수렴</li>
</ul>
</li>
</ul>
</li>
</ol>
<br>
<ol start="20">
<li>$\phi$ 를 먼저 업데이트 하고 그다음 $\theta$ 에 대해서 업데이트를 한다. 그럼 이 <strong>기울기들을</strong> 어떻게 계산하는지 보기 위하여 목적 함수 ($\mathcal{L}(x^i; \theta, \phi^i)$) 를 조금 더 확장해보자.
<ul>
<li>하지만 파라미터를 <strong>공동으로 최적화</strong> 하기 때문에, 만약 $\phi$의 최적화 방향이 안좋다면 <code>non-convex</code>하기 때문에 해당 <code>목적 함수</code>가 <strong>매우 나쁜 local minimum에</strong> 갇힐 위험은 있다.</li>
</ul>
</li>
</ol>
<br>
<p>$$
\begin{aligned}
\mathcal{L}(x^i; \theta, \phi^i)
&amp;= \sum_{z} q(z; \phi^i) \log p(z, x^i; \theta) + H(q(z; \phi^i)) \\
&amp;= \mathbb{E_{q(z; \phi^i)}} \left[ \log p(z, x^i; \theta) - \log q(z; \phi^i) \right]
\end{aligned}
$$</p>
<ul>
<li><code>Entropy 식(H)</code>을 풀고, $\sum$ 과 $q(z;\phi^i)$ 를 <code>Expectation</code>으로 묶으면 해당 식이 된다.</li>
</ul>
<br>
<ol start="21">
<li>위 식을 보면 기울기를 계산하기 위하여 기대값과 기울기를 계산하는데 사용할 수 있는 표현식이 없다. 그렇기 때문에 다시 <code>Monte Carlo sampling</code>에 의존해야한다. 위 기대값을 <code>Monte Carlo</code>를 사용하면 $q(\mathbf{z}; \phi)$ 분포에서 $\mathbf{z}^1, \dots, \mathbf{z}^K$ 로 sampling을 하여 식을 <code>closed-form</code>으로 변경할 수 있다.</li>
</ol>
<ul>
<li>K의 값이 증가할수록 값이 기대값에 가까워진다. 하지만 실제 VAE는 K의 값을 1로 선택을 했다.</li>
</ul>
<br>
<p>$$\mathbb{E}_{q(\mathbf{z}; \phi)}\left[ \log p(\mathbf{z}, \mathbf{x}; \theta) - \log q(\mathbf{z}; \phi) \right]
\approx \frac{1}{K} \sum_k \left( \log p(\mathbf{z}^k, \mathbf{x}; \theta) - \log q(\mathbf{z}^k; \phi) \right)$$</p>
<ul>
<li>$\log q$ 에서 q의 확률을 평가하기 때문에 효율적으로 평가해야하는 모델이어야 한다. 따라서, q의 분포는 단순해야하는 가정이 있어야한다.</li>
</ul>
<br>
<ol start="22">
<li>자, 이제 <code>gradient descent</code> 순서(19번)에서 2개의 gradient($\theta$, $\phi$)를 계산해보자. 먼저 $\theta$ 에 대해서 gradient를 해보면, <strong>이미 다 나온 값</strong>들이기 때문에 <code>Monte Carlo</code>를 이용하여 계산하기 쉽다. 이때, 이미 다 나온값의 의미에서 $\phi$ 도 <strong>이미 고정된 분포에서 sampling을 하기 때문에</strong> 우리가 알고있는 neural network의 gradient descent라고 생각하면 된다. 따라서 $\theta$ 의 식은 아래와 같다.</li>
</ol>
<br>
<p>$$
\nabla_\theta \mathbb{E_{q(z; \phi)}} \left[ \log p(z, x; \theta) - \log q(z; \phi) \right]
= \mathbb{E_{q(z; \phi)}} \left[ \nabla_\theta \log p(z, x; \theta) \right]
\approx \frac{1}{K} \sum_k \nabla_\theta \log p(z^k, x; \theta)$$</p>
<ul>
<li>$\theta$ 에 대해서 기울기를 구하기 때문에 $\phi$ 는 미분하면 사라진다.</li>
</ul>
<br>
<ol start="23">
<li>하지만 $\phi$ 에 대해서 gradient를 계산해보려고 하면 $\phi^i$ 에 따라 달라지는 분포에서 표본을 추출하기 때문에 <strong>기울기를 구하는데 어려움이 있다.</strong>
<ul>
<li>
<p>$\theta$에 의존하는 분포에서 표본을 <strong>추출하지 않기 때문에</strong> $\theta$ 의 gradient는 구하기 쉽다.</p>
</li>
<li>
<p>하지만, $\phi$를 변경하면 sampling 절차가 $\phi$에 따라서 <strong>어떻게 변할지 이해해야해서 어렵다.</strong></p>
</li>
<li>
<p>$\phi$ 에 대해서 gradient 계산이 어렵다는 이해를 돕기 위해 <code>SVI</code>의 원형의 <code>pseudo code</code>가 있다.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">theta</span> <span class="n">optimization</span>
</span></span><span class="line"><span class="cl">      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">          <span class="n">phi</span> <span class="n">optimization</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">## Total Optimization Steps : N x M</span>
</span></span></code></pre></div></li>
<li>
<p>이 예시는 $\phi$를 최적화 하기 위해 매번 최적의 $\phi^{i,*}$ 를 구해야하는 복잡함을 단번에 이해할 수 있을 것이다.</p>
</li>
<li>
<p>하지만 왜 그럼 $\theta$ 에 대해서는 $\theta^{i,*}$ 을 구하지 않는걸까?라는 의문은 <code>16번</code>을 다시 돌아가면 해결이 된다.</p>
</li>
</ul>
</li>
</ol>
<br>
<ol start="24">
<li>따라서, VAE에 <code>SVI</code>를 적용시킬 때 2가지 문제가 있는 것이다. 첫번째는 $\phi$ 의 gradient를 계산할 때 $\phi$ 에서 샘플링을 하기 때문에 gradient 계산이 불안정하다는 점이고, 두 번째는 $\phi$ 계산이 M 번 수행되어야 된다는 점이다. 이 두 문제를 해결하기 위하여 각각 <code>Reparameterization Trick</code>과 <code>Amortized Inference</code> 방법으로 해결할 수 있다.</li>
</ol>
<hr>
<h2 id="reparameterization-trick">Reparameterization Trick</h2>
<ol start="25">
<li>먼저 <code>Reparameterization Trick</code>에 대한 개념을 살펴보고, 우리의 <code>VAE 식 ELBO</code>에 적용시켜 보겠다. 그리고 <code>Reparameterization Trick</code>을 사용하기 위한 제약사항이 있는데, 바로 잠재 변수 z가 <strong>연속</strong>일때만 작동한다는 점이다.</li>
</ol>
<br>
<p>$$\mathbb{E_{q(z; \phi)}} \left[ r(\mathbf{z}) \right] = \int q(\mathbf{z}; \phi) , r(\mathbf{z}) , d\mathbf{z}$$</p>
<ol start="26">
<li>그렇기 때문에 위 식을 보면 $\sum$ 이 아니라 <strong>적분으로 계산이 된다.</strong> 이제, 중요한 것은 $\phi$ 의 gradient 를 구할 때, 해당 식(ELBO)이 본질적으로 <strong>가능한 한 커지도록</strong> $\phi$ <strong>를 변경하는 방법을 알아내는 것</strong> 이기 때문에, 기대값 안의 식들을 $r$ 로 대체했다.
<ul>
<li>이는 <code>강화학습</code>하고도 연관을 지을 수 있는데, z가 행동이라면 이 행동을 선택하는데 확률적인 정책(q)가 있어서 다른 행동(z)은 다른 정책(q)을 받을 수 있다.</li>
<li>그래서 위 식을 다시 해석하면, <code>최대한 높은 보상(r or 기대값 전체)</code>을 얻으려면 확률적으로 어떤 행동(z)을 선택해야 할까요? 라고 볼 수 있다.</li>
</ul>
</li>
</ol>
<br>
<ol start="27">
<li>그리고 q함수를 간단한 가우시안 분포의 성격을 띈다면 $q(\mathbf{z}; \phi) = \mathcal{N}(\mu, \sigma^2I)$ 일 때 $\phi = (\mu, \sigma)$ 이다. q함수의 샘플링의 방법은 아래 2가지 방법이 될 수 있다.
<ul>
<li><code>직접 샘플링</code>: $\mathbf{z} \sim q(\mathbf{z}; \phi)$</li>
<li><code>Reparameterization Trick</code>:  $\boldsymbol{\epsilon} \sim \mathcal{N}(0, I), \quad \mathbf{z} = \mu + \sigma \odot \epsilon = g(\epsilon;\phi)$
<ul>
<li><code>Reparameterization Trick</code>을 사용하게 되면 $\epsilon$ 의 분포가 고정이 되어 분산이 튀는 현상을 방지할 수 있게 된다.</li>
</ul>
</li>
</ul>
</li>
</ol>
<br>
<ol start="28">
<li>따라서 <code>Reparameterization Trick</code> 을 사용하게 되면 z를 결정론적 수식으로 변환을 할 수 있게 된다. 샘플링의 두가지 방법으로 인하여 기대값 계산 또한 두가지 방법이 될 수 있다.</li>
</ol>
<br>
<p>$$\mathbb{E_{z \sim q(z; \phi)}} [r(z)] = \int q(z; \phi) r(z), dz = \mathbb{E_{\epsilon \sim \mathcal{N}(0, I)}} [r(g(\epsilon; \phi))]$$</p>
<ol start="29">
<li>해당 수식을 보면 q에서 샘플링하여 얻은 z를 사용하여 r에서 평가하는 방법과(2번째 항)$\epsilon$ 에서 샘플링 을 한 다음, g함수로 <strong>변환을</strong> 하고 r의 기대값을 얻는 방법(3번째 항)이 있다.</li>
</ol>
<br>
<ol start="30">
<li>이제 <code>3번째 항</code>이 <code>reparameterization trick</code>으로 인하여 <strong>결정론적으로 변했기 때문에</strong>, $\phi$ 의 gradient를 조금 변경했을 때 샘플이 어떻게 변하는지 알 수 있게 도;었다.. 그렇기 때문에 gradient를 <strong>내부에 넣어서 계산이 가능해진다</strong>. 또한 위에서 22번과 마찬가지로 <code>Monte Carlo</code>를 다시 사용할 수 있게 되었다.</li>
</ol>
<br>
<p>$$\nabla_{\phi} \mathbb{E_{q(z; \phi)}} [r(z)]
= \nabla_{\phi} \mathbb{E_{\epsilon}} [r(g(\epsilon; \phi))]
= \mathbb{E_{\epsilon}} [\nabla_{\phi} r(g(\epsilon; \phi))]$$</p>
<p>$$\mathbb{E_{\epsilon}} [\nabla_{\phi} r(g(\epsilon; \phi))]
\approx \frac{1}{K} \sum_k \nabla_{\phi} r(g(\epsilon^k; \phi))
\quad \text{where } \epsilon^1, \dots, \epsilon^K \sim \mathcal{N}(0, I)$$</p>
<ol start="31">
<li>이제 <code>reparameterization trick</code> 방법을 <code>VAE ELBO</code>에 적용시킬려고 보니, 단순히 $r(z)$가 아닌 $r(z, \phi)$ 인것을 확인할 수 있다. 하지만 이는 큰 문제가 되지 않는다. 아래의 식에서 확인해보자.</li>
</ol>
<hr>
<h2 id="amortized-inference">Amortized Inference</h2>
<ol start="32">
<li>이제, <code>VAE ELBO</code>의 gradient를 계산하는 방법을 배웠다. 하지만 아직도 문제가 있다. 바로 데이터 포인트($x^i$)당 variational parameter($\phi^i$) 가 있는 것은 M번의 수행이 이루어 져야한다는 것이고, 이는 <strong>계산 비용이 많이 든다고 생각할 수 있다.</strong></li>
</ol>
<br>
<ol start="33">
<li>이 계산 비용을 최적화 하기 위하여, 우린 모든 $\phi$ 에 대해 <strong>개별적으로 최적화하지 않을 것이다.</strong> 대신에, 우리는 또다른 신경망이 될 단일 매개변수 세트($f_\lambda$, VAE의 encoder가 된다.)를 정의한다. 이 $f_\lambda$ 는 좋은 <code>variational parameter</code>를 추측하려고 시도할 것이다.
<ul>
<li>$x^i$ 에 걸맞는 $\phi^{i,*}$ 를 찾는 역할이라고 생각하면 될 것 같다.</li>
</ul>
</li>
</ol>
<br>
<p>$$ q_{\lambda}(z \mid x^i) \equiv q(z \mid x^i; \phi^i = f_{\lambda}(x^i))$$</p>
<ul>
<li>$q(z|x^i ; \phi^{i,*})$ 기존 q의 함수에서 $\phi$ 를 inference하는 $f_\lambda$ 가 나온 것을 확인할 수 있다.</li>
</ul>
<ol start="34">
<li><code>Amortized Inference</code>를 사용하면 이제 매개변수의 수가 고정되어 있기 때문에, 확장성이 훨씬 뛰어나지게 된다. 또한 <code>훈련 관점</code>에서 생각해보면 약간 헷갈릴수도 있는데, <code>Amortized Inference</code>를 사용하면 <code>Encoder</code>와 <code>Decoder</code>가 <code>ELBO</code>를 통해서 <strong>공동으로 최적화 되기 때문에</strong> 학습 파라미터에서 $\phi$ 는 없어지고, $\lambda, \theta$ 만 남게 된다.</li>
</ol>
<br>
<ol start="35">
<li><code>VAE</code>에서 notation을 $q(z; f_\lambda(x^i))$ 이 $q_\phi(z|x)$ 로 표기된다. 따라서 $q_\phi(z|x)$ 을 사용하여 <code>ELBO</code>를 다시 표기해보면 아래와 같다. 기존 <code>ELBO</code> 식은 <code>20번에</code> 있으니 비교해서 보면 좋을 것 같다.</li>
</ol>
<br>
<p>$$
\begin{aligned}
\mathcal{L}(\mathbf{x}; \theta, \phi) &amp;= \sum_{z} q_{\phi}(z \mid \mathbf{x}) \log p(z, \mathbf{x}; \theta) + H(q_{\phi}(z \mid \mathbf{x})) \\
&amp;= \mathbb{E_{q_{\phi}(z \mid \mathbf{x})}} \left[ \log p(z, \mathbf{x}; \theta) - \log q_{\phi}(z \mid \mathbf{x}) \right]
\end{aligned}
$$</p>
<ul>
<li>반복해서 말하지만 $q_\phi$ 는 x를 입력으로 받아서 variational posterior 를(x에 맞는 $\phi$ 를 찾는 역할) 만드는 역할을 한다.</li>
</ul>
<ol start="36">
<li><code>Amoritized Inference</code>를 사용하여 <code>gradient descent</code>의 순서를 살펴보자.
<ul>
<li>
<p>$\theta^{(0)},\ \lambda^{(0)}\ \text{랜덤 초기화}$</p>
</li>
<li>
<p>$x^i \sim \mathcal{D}$</p>
<ul>
<li>전체 데이터셋 $\mathcal{D}$에서 무작위로 하나의 데이터 포인트 $x^i$를 샘플링</li>
</ul>
</li>
<li>
<p>$\nabla_\theta \mathcal{L}(x^i; \theta, \lambda),\quad \nabla_\lambda \mathcal{L}(x^i; \theta, \lambda)$</p>
<ul>
<li>$\phi^i = f_\lambda(x^i)$를 통해 variational 분포 $q_\phi(z|x^i)$를 정의하고, <code>reparameterization trick</code>을 활용해 $\theta, \lambda$ 각각에 대한 gradient를 계산</li>
</ul>
</li>
<li>
<p>$\theta \leftarrow \theta + \alpha \nabla_\theta \mathcal{L}, \quad \lambda \leftarrow \lambda + \alpha \nabla_\lambda \mathcal{L}$</p>
<ul>
<li>optimizer (예: Adam)를 사용하여 $\theta$와 $\lambda$를 업데이트</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="autoencoder-perspective">Autoencoder Perspective</h2>
<div style="text-align:center;">
<img src="/images/cs236/lecture6/vae-2.png" height="50%" width="50%"> </div>
<ol start="37">
<li>Encoder와 Decoder의 구조가 <code>Autoencoder(AE)</code>와 닮았고, $q_\phi$ 라는 <strong>variational posterior</strong> 가 있기 때문에, <code>Variational AutoEncoder (VAE)</code>가 되는 것이다.</li>
</ol>
<br>
<ol start="38">
<li>지금까지는 <code>ELBO</code>식을 전개하며 gradient를 구할 수 있게 하고, 그것을 이용하여 <code>ELBO</code>를 최대화 할 수 있다고 했다. 하지만, 이 식이 <code>AE</code> 관점에서 어떤 특성을 가지고 있는지에 대해서 구체적으로 설명하지 않았다. <code>AE</code> 관점에서 <code>ELBO</code>식을 파헤쳐보려고 한다. 일단 <code>ELBO</code> 식을 약간 조작해보면 아래와 같다.</li>
</ol>
<br>
<p>$$
\begin{aligned}
\mathcal{L}(\mathbf{x}; \theta, \phi)
&amp;= \mathbb{E_{q_\phi(z \mid \mathbf{x})}} \left[ \log p(\mathbf{z}, \mathbf{x}; \theta) - \log q_\phi(z \mid \mathbf{x}) \right] \\
&amp;= \mathbb{E_{q_\phi(z \mid \mathbf{x})}} \left[ \log p(\mathbf{z}, \mathbf{x}; \theta) - \log p(z) + \log p(z) - \log q_\phi(z \mid \mathbf{x}) \right] \\
&amp;= \mathbb{E_{q_\phi(z \mid \mathbf{x})}} \left[ \log p(\mathbf{x} \mid z; \theta) \right] - D_{\mathrm{KL}}\left( q_\phi(z \mid \mathbf{x}) | p(z) \right)
\end{aligned}
$$</p>
<ul>
<li>KL 식은 아래와 같기 때문에 KL로 묶이는 것이다.
<ul>
<li>$D_{\mathrm{KL}}\left( q_\phi(z \mid \mathbf{x}) | p(z) \right)
= \sum_{q_\phi(z \mid \mathbf{x})} q_\phi(z \mid \mathbf{x}) \log \frac{q_\phi(z \mid \mathbf{x})}{p(z)}
= \mathbb{E_{q_\phi(z \mid \mathbf{x})}} \left[ \log q_\phi(z \mid \mathbf{x}) - \log p(z) \right]$</li>
</ul>
</li>
</ul>
<p>$$\mathbb{E_{q_\phi(z \mid \mathbf{x})}} \left[ \log p(\mathbf{x} \mid z; \theta) \right]$$</p>
<ol start="39">
<li>우리는 훈련 시 이 <code>ELBO</code>를 <strong>최대화하는 것을 목표</strong>로 한다. 일단 <code>세번째 줄의 첫번째 항</code>만 가져와서 봐보자. 이 항을 계산하기 위해서 <strong>기대값이기</strong> 때문에, <code>Monte Carlo</code> 를 사용할 수 있다. $q_\phi(z|x)$ 에서 샘플을 추출하고 그것을 decoder(p)에 넣어 확률이 나오는 것으로 식을 해석할 수 있다.
<ul>
<li>앞서 우리는 위에서 $q_\phi(z|x)$ 는 <code>variational posterior</code>를 추론하는 <code>neural network</code>라고 배웠다.</li>
<li>그렇다면 encoder는 이미지(x)를 보고 <strong>이미지에 맞는</strong> latent variable z의 분포, 즉 평군과 분산의 값이 나오고 이를 샘플링하여 특정 z의 값을 얻는 것이다.
<ul>
<li>만약 <strong>훈련 시</strong> $q_\phi(z|x)$ 이 <code>가우시안 분포</code>를 띈다면, <code>인코더</code>를 통해 이미지(x)를 맞춰서 얻은 결과에 따라 정의되는 평균과 분산을 갖는 <code>가우시안 분포</code>가 나올 것이다. 그럼 이 분포로 샘플링을 하여 $\hat{z}$ 를 얻는다.</li>
</ul>
</li>
<li><strong>훈련 시</strong> 우린 이 $\hat{z}$를 다시 <code>neural network</code>인 decoder에 넣으면 원래 이미지 x를 얼마나 잘 재구성할 수 있는지에 대한 <code>재구성 분포</code>를 얻고 $\hat{x}$ 를 얻는다.</li>
<li>이 항을 <code>Reconstruction Term</code>으로 불린다. 이 항만으로도 약간의 <code>확률적 AE</code> 기능을 한다.</li>
<li><a href="https://goodyoung.github.io/posts/paper/vae/" target="_blank" rel="noopener noreffer ">VAE Paper Review 31번째 줄</a> 을 보면 식 전개하는 과정을 참고할 수 있다. 추가로 해당 항이 분포에 따라서 <code>Cross Entropy</code>, <code>L2 Loss</code>가 된다는 것을 알 수 있다.</li>
</ul>
</li>
</ol>
<br>
<p>$$-D_{\mathrm{KL}}\left( q_\phi(z \mid \mathbf{x}) | p(z) \right)$$</p>
<ol start="40">
<li><code>세번째 줄의 두번째 항</code>을 보면 encoder에서 나온 $\hat{z}$ 가 $p(z)$ 와 유사해지게 한다. 이는 이미지를 잘 재구성할 뿐 아니라 재구성에서 사용하는 latent variable z의 분포도 우리가 사전에 정의한 분포($p(z)$)와 유사해져야 한다는 것이다.
<ul>
<li><code>첫번째 항</code>만으로는 <strong>새로운 데이터 포인트에서 생성할 방법이 없다.</strong> 첫번째 항만 사용한다면, 그저 일반화가 잘되기를 빌어야한다.</li>
<li>잠재 변수가 특정한 모양, 분포를 갖게 정규화 해주는 역할을 하기 때문에도 <code>Variational AE</code>라고 불리는 이유이다.</li>
<li>이 항을 <code>Regularization Term</code>으로 불린다.</li>
<li><a href="https://goodyoung.github.io/posts/paper/vae/" target="_blank" rel="noopener noreffer ">VAE Paper Review 31번째 줄</a> 을 보면 식 전개하는 과정을 참고할 수 있다.</li>
</ul>
</li>
</ol>
<br>
<p>$$p(x) = \sum_z p(z)p(x|z)$$</p>
<ol start="41">
<li>결국 <code>첫번째 항</code>은 p(x|z) 가 잘 훈련되기 위한 항이고, <code>두번째 항</code>은 p(z)가 잘 훈련되기 위한 항이다. 따라서 훈련이 다 끝나고, 생성을 할 땐 p(z)는 미리 알기때문에 $z \sim p(z)$ 으로 추출하고 그것을 $p_\theta(x|z)$ 에 넣으면 x가 <strong>생성이 된다.</strong>
<ul>
<li>결국 encoder는 decoder를 <strong>훈련시키기 위한 하나의 수단</strong>이고, <code>생성의 관점</code>에서는 decoder만으로 <strong>새로운 x를 만들 수 있게 되는 것이다.</strong></li>
</ul>
</li>
</ol>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://deepgenerativemodels.github.io/" target="_blank" rel="noopener noreffer ">https://deepgenerativemodels.github.io/</a></li>
<li><a href="https://www.youtube.com/watch?v=tRArbBf-AbI&amp;list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&amp;index=3&amp;t=4s" target="_blank" rel="noopener noreffer ">https://www.youtube.com/watch?v=tRArbBf-AbI&list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&index=3&t=4s</a></li>
<li><a href="https://wikidocs.net/228835" target="_blank" rel="noopener noreffer ">https://wikidocs.net/228835</a></li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2025-07-26</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://goodyoung.github.io/posts/cs236/lecture6/" data-title="[CS236] 6. Latent Variable Models-2" data-hashtags="Latent Variable Models,VAE,CS236"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://goodyoung.github.io/posts/cs236/lecture6/" data-hashtag="Latent Variable Models"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://goodyoung.github.io/posts/cs236/lecture6/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://goodyoung.github.io/posts/cs236/lecture6/" data-title="[CS236] 6. Latent Variable Models-2"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://goodyoung.github.io/posts/cs236/lecture6/" data-title="[CS236] 6. Latent Variable Models-2"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://goodyoung.github.io/posts/cs236/lecture6/" data-title="[CS236] 6. Latent Variable Models-2"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://goodyoung.github.io/posts/cs236/lecture6/" data-title="[CS236] 6. Latent Variable Models-2" data-description=""><i class="fab fa-blogger fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/latent-variable-models/">Latent Variable Models</a>,&nbsp;<a href="/tags/vae/">VAE</a>,&nbsp;<a href="/tags/cs236/">CS236</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/cs236/lecture5/" class="prev" rel="prev" title="[CS236] 5. Latent Variable Models-1"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[CS236] 5. Latent Variable Models-1</a>
            <a href="/posts/cs236/lecture7/" class="next" rel="next" title="[CS236] 7. Normalizing Flows - 1">[CS236] 7. Normalizing Flows - 1<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
  
</footer>
</div>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"goodylung/blog-comment"}},"lightgallery":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-86432198-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body>
</html>
