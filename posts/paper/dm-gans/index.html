<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs) - Good Young</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)" />
<meta property="og:description" content="개요 GAN 대비 Diffusion Model(DM)의 이미지 생성 성능을 비교하며, DM이 GAN을 능가하는 이유를 분석한 Diffusion Models Beat GANs 논문을 리뷰할 것이다. Introduction 요즘의 생성 모델은 많이 발전해오고 있다. 하지만 그 중에도 발전 가능성이 아직 많다. 생성 모델이 더욱 발전 한다면, 사용할 수 있는 분야가 셀 수 없이 많다. GAN은 여러 평가 지표 (FID, Inception Score, Precision, &hellip; 등)에 의하여 image generation에서 SOTA를 달성하고 있다. 하지만 이 평가 지표는 다양성을 완전히 포착하지 않고, likelihood-based model보다 더 다양성을 포착하지 않는다. 또한, GAN은 최적의 하이퍼 파라미터와 정규화를 하지 않으면 모델이 붕괴하기 때문에 훈련이 어렵다. 이러한 GAN의 단점 때문에 다른 domain에 적용하기에도 어렵고, 확장시키기도 어려워졌다. 그 결과 likelihood-based model이 GAN의 sampling image quality와 비슷하게 발전해왔다. likelihood-based model도 결국 단점이 있었는데, sampling 시 GAN보다 매우 느리고 sample quality 또한 기대에 미치진 못한다. Likelihood-based model의 한 종류인 Diffusion model이 등장하여 확장성도 있고, 높은 품질을 만들어내는 성능을 보였주었다. CIFAR-10에서 SOTA를 달성했지만 다른 어려운 dataset(LSUN, ImageNet)에 대해서는 GAN에 밀려있었다. 논문 저자들이 Improved Denoising Diffusion Probabilistic Models에서 diffusion model의 신뢰성을 증가시키는 연구를 했지만 FID가 GAN에 비하여 경쟁력 있지는 않았었다. 본 논문에선 GAN과 Diffusion model이 차이가 나는 두 가지 요인에서 비롯된다고 가정한다. 최근 GAN 연구에서 사용된 모델 아키텍처는 광범위하게 탐색되고 최적화되었다. GAN은 다양성(diversity)과 정확성(fidelity) 사이에서 trade-off의 균형을 조절한다. 따라서 GAN은 높은 품질의 샘플을 생성하는 대신 전체 데이터 분포를 완전히 포괄하지는 못한다. GAN은 Generator, Discriminator로 나뉘어져 있으므로 둘 간 균형을 조정한다. 본 논문에선 이 두 가지의 요인을 Diffusion model에도 적용하고자 한다. 먼저 모델의 아키텍쳐를 개선하고, 이후 다양성과 정확성 간의 trade-off의 균형을 조절 할 수 있는 기법을 개발한다. 이 결과 본 논문에서 제안한 diffusion model이 새로운 SOTA를 달성하며, GAN을 이기게 되었다. Background 이번 단락에서는 Diffusion model 중 DDPM에 대한 간단한 배경을 설명하고 있다. Diffusion model에 대한 자세한 설명은 해당 링크에서 보면 될 것 같다. DDPM에서의 목표는 조금 더 덜 노이즈가 포함된 $x_\text{t-1}$ 를 $x_t$에서 생성하는 과정을 학습하게 된다. DDPM에서 학습하기 위한 loss로 실제 변분 하한(Variational Lower Bound) $L_\text{vlb}$를 단순화한 $L_\text{simple}$이 성능이 좋음을 관찰하였다. 이런 훈련 절차와 샘플링 절차는 denoising score matching model과 동일하다고 한다. 다음으로, 조금 더 나은 diffusion model을 설명하게 되는데 기존 DDPM에서는 reverse process에서의 분산 $\Sigma_\theta(x_t, t)$ 을 고정된 값으로 설정하였는데, 이런 고정된 분산이 샘플링 단계 수가 적을 때 성능이 낮아질 수 있다. 따라서 $\Sigma_\theta(x_t, t)$ 를 파라미터화 하여 해결하려고 했고, 훈련 loss 또한 $L_\text{vlb}$ 과 $L_\text{simple}$ 를 함께 사용하는 hybrid objective로 해결한다. 본 논문에서도 해당 objecive와 parameterization을 사용한다. 또한 DDIM의 Non-Markovian 과정으로 인한 샘플링 스텝을 줄이는 방법 또한 본 논문에서 사용한다. 마지막으로 샘플 품질을 평가하는 metrics에 관한 설명으로 이어진다. Metrics 중 Inception Score(IS)는 ImageNet 클래스 분포를 얼마나 잘 학습했는지를 측정하는 메트릭이다. 개별 샘플이 특정 클래스의 예제를 얼마나 그럴듯하게 평가하면서도, 모델이 전체 dataset 클래스 분포를 잘 반영했는지 측정한다. 이런 IS도 한계점이 있는데, 아래는 IS의 한계점을 설명한 것이다. 모든 클래스에 대한 전체 분포를 얼마나 잘 커버하는지 평가하지 못한다. 데이터셋의 일부를 단순히 암기한 모델도 높은 IS 점수를 가질 수 있다. Fréchet Inception Distance (FID)는 IS보다 더 다양성을 잘 평가할 수 있는 방법이다. Inception-V3 모델의 latent space에서 두 이미지 분포 간 거리를 측정하여 두 이미지 분포 간의 symmetric measure of distance를 측정하게 된다. sFID라는 변형 버전은 기존 FID보다 공간적 특성을 고려하여 더 정교한 평가가 가능하다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://goodyoung.github.io/posts/paper/dm-gans/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-02-27T16:42:40+09:00" />
<meta property="article:modified_time" content="2025-02-27T16:42:40+09:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)"/>
<meta name="twitter:description" content="개요 GAN 대비 Diffusion Model(DM)의 이미지 생성 성능을 비교하며, DM이 GAN을 능가하는 이유를 분석한 Diffusion Models Beat GANs 논문을 리뷰할 것이다. Introduction 요즘의 생성 모델은 많이 발전해오고 있다. 하지만 그 중에도 발전 가능성이 아직 많다. 생성 모델이 더욱 발전 한다면, 사용할 수 있는 분야가 셀 수 없이 많다. GAN은 여러 평가 지표 (FID, Inception Score, Precision, &hellip; 등)에 의하여 image generation에서 SOTA를 달성하고 있다. 하지만 이 평가 지표는 다양성을 완전히 포착하지 않고, likelihood-based model보다 더 다양성을 포착하지 않는다. 또한, GAN은 최적의 하이퍼 파라미터와 정규화를 하지 않으면 모델이 붕괴하기 때문에 훈련이 어렵다. 이러한 GAN의 단점 때문에 다른 domain에 적용하기에도 어렵고, 확장시키기도 어려워졌다. 그 결과 likelihood-based model이 GAN의 sampling image quality와 비슷하게 발전해왔다. likelihood-based model도 결국 단점이 있었는데, sampling 시 GAN보다 매우 느리고 sample quality 또한 기대에 미치진 못한다. Likelihood-based model의 한 종류인 Diffusion model이 등장하여 확장성도 있고, 높은 품질을 만들어내는 성능을 보였주었다. CIFAR-10에서 SOTA를 달성했지만 다른 어려운 dataset(LSUN, ImageNet)에 대해서는 GAN에 밀려있었다. 논문 저자들이 Improved Denoising Diffusion Probabilistic Models에서 diffusion model의 신뢰성을 증가시키는 연구를 했지만 FID가 GAN에 비하여 경쟁력 있지는 않았었다. 본 논문에선 GAN과 Diffusion model이 차이가 나는 두 가지 요인에서 비롯된다고 가정한다. 최근 GAN 연구에서 사용된 모델 아키텍처는 광범위하게 탐색되고 최적화되었다. GAN은 다양성(diversity)과 정확성(fidelity) 사이에서 trade-off의 균형을 조절한다. 따라서 GAN은 높은 품질의 샘플을 생성하는 대신 전체 데이터 분포를 완전히 포괄하지는 못한다. GAN은 Generator, Discriminator로 나뉘어져 있으므로 둘 간 균형을 조정한다. 본 논문에선 이 두 가지의 요인을 Diffusion model에도 적용하고자 한다. 먼저 모델의 아키텍쳐를 개선하고, 이후 다양성과 정확성 간의 trade-off의 균형을 조절 할 수 있는 기법을 개발한다. 이 결과 본 논문에서 제안한 diffusion model이 새로운 SOTA를 달성하며, GAN을 이기게 되었다. Background 이번 단락에서는 Diffusion model 중 DDPM에 대한 간단한 배경을 설명하고 있다. Diffusion model에 대한 자세한 설명은 해당 링크에서 보면 될 것 같다. DDPM에서의 목표는 조금 더 덜 노이즈가 포함된 $x_\text{t-1}$ 를 $x_t$에서 생성하는 과정을 학습하게 된다. DDPM에서 학습하기 위한 loss로 실제 변분 하한(Variational Lower Bound) $L_\text{vlb}$를 단순화한 $L_\text{simple}$이 성능이 좋음을 관찰하였다. 이런 훈련 절차와 샘플링 절차는 denoising score matching model과 동일하다고 한다. 다음으로, 조금 더 나은 diffusion model을 설명하게 되는데 기존 DDPM에서는 reverse process에서의 분산 $\Sigma_\theta(x_t, t)$ 을 고정된 값으로 설정하였는데, 이런 고정된 분산이 샘플링 단계 수가 적을 때 성능이 낮아질 수 있다. 따라서 $\Sigma_\theta(x_t, t)$ 를 파라미터화 하여 해결하려고 했고, 훈련 loss 또한 $L_\text{vlb}$ 과 $L_\text{simple}$ 를 함께 사용하는 hybrid objective로 해결한다. 본 논문에서도 해당 objecive와 parameterization을 사용한다. 또한 DDIM의 Non-Markovian 과정으로 인한 샘플링 스텝을 줄이는 방법 또한 본 논문에서 사용한다. 마지막으로 샘플 품질을 평가하는 metrics에 관한 설명으로 이어진다. Metrics 중 Inception Score(IS)는 ImageNet 클래스 분포를 얼마나 잘 학습했는지를 측정하는 메트릭이다. 개별 샘플이 특정 클래스의 예제를 얼마나 그럴듯하게 평가하면서도, 모델이 전체 dataset 클래스 분포를 잘 반영했는지 측정한다. 이런 IS도 한계점이 있는데, 아래는 IS의 한계점을 설명한 것이다. 모든 클래스에 대한 전체 분포를 얼마나 잘 커버하는지 평가하지 못한다. 데이터셋의 일부를 단순히 암기한 모델도 높은 IS 점수를 가질 수 있다. Fréchet Inception Distance (FID)는 IS보다 더 다양성을 잘 평가할 수 있는 방법이다. Inception-V3 모델의 latent space에서 두 이미지 분포 간 거리를 측정하여 두 이미지 분포 간의 symmetric measure of distance를 측정하게 된다. sFID라는 변형 버전은 기존 FID보다 공간적 특성을 고려하여 더 정교한 평가가 가능하다."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://goodyoung.github.io/posts/paper/dm-gans/" /><link rel="prev" href="https://goodyoung.github.io/posts/paper/ldm/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/goodyoung.github.io\/posts\/paper\/dm-gans\/"
        },"genre": "posts","keywords": "논문 리뷰, computer vision, Diffusion, DM-GANs, Classifier Guidance","wordcount":  942 ,
        "url": "https:\/\/goodyoung.github.io\/posts\/paper\/dm-gans\/","datePublished": "2025-02-27T16:42:40+09:00","dateModified": "2025-02-27T16:42:40+09:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "GoodYoung"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Good Young">GoodYoung Dev Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Good Young">GoodYoung Dev Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://goodyoung.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>GoodYoung</a></span>&nbsp;<span class="post-category">included in <a href="/categories/paper-review/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Paper Review</a>&nbsp;<a href="/categories/dl/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>DL</a>&nbsp;<a href="/categories/diffusion/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Diffusion</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2025-02-27">2025-02-27</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;942 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#background">Background</a></li>
    <li><a href="#architecture-improvements">Architecture Improvements</a>
      <ul>
        <li><a href="#adaptive-group-normalizationadagn">Adaptive Group Normalization(AdaGN)</a></li>
      </ul>
    </li>
    <li><a href="#classifier-guidance">Classifier Guidance</a>
      <ul>
        <li><a href="#conditional-reverse-noising-process">Conditional Reverse Noising Process</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- image format
<div style="text-align:center;">
<img src="/images/cs231n/lecture4/back-1.png" height="100%" width="80%"> </div>
 -->
<h2 id="개요">개요</h2>
<ol start="0">
<li><code>GAN</code> 대비 <code>Diffusion Model(DM)</code>의 이미지 생성 성능을 비교하며, <code>DM</code>이 <code>GAN</code>을 능가하는 이유를 분석한 <code>Diffusion Models Beat GANs</code> 논문을 리뷰할 것이다.</li>
</ol>
<hr>
<h2 id="introduction">Introduction</h2>
<ol>
<li>요즘의 <code>생성 모델</code>은 많이 발전해오고 있다. 하지만 그 중에도 <strong>발전 가능성이 아직 많다.</strong></li>
</ol>
<br>
<ol start="2">
<li><code>생성 모델</code>이 더욱 발전 한다면, 사용할 수 있는 분야가 셀 수 없이 많다.</li>
</ol>
<br>
<ol start="3">
<li><code>GAN</code>은 여러 평가 지표 (FID, Inception Score, Precision, &hellip; 등)에 의하여 <code>image generation</code>에서 <code>SOTA</code>를 달성하고 있다.</li>
</ol>
<br>
<ol start="4">
<li>하지만 이 평가 지표는 다양성을 완전히 포착하지 않고, <code>likelihood-based model</code>보다 더 다양성을 포착하지 않는다.</li>
</ol>
<br>
<ol start="5">
<li>또한, <code>GAN</code>은 최적의 <code>하이퍼 파라미터</code>와 <code>정규화</code>를 하지 않으면 <strong>모델이 붕괴하기 때문에 훈련이 어렵다.</strong></li>
</ol>
<br>
<ol start="6">
<li>이러한 <code>GAN</code>의 단점 때문에 다른 domain에 적용하기에도 어렵고, 확장시키기도 어려워졌다. 그 결과 <code>likelihood-based model</code>이 <code>GAN</code>의 <code>sampling image quality</code>와 비슷하게 발전해왔다.</li>
</ol>
<br>
<ol start="7">
<li><code>likelihood-based model</code>도 결국 <strong>단점</strong>이 있었는데, sampling 시 <code>GAN</code>보다 매우 느리고 <code>sample quality</code> 또한 <strong>기대에 미치진 못한다.</strong></li>
</ol>
<br>
<ol start="8">
<li><code>Likelihood-based model</code>의 한 종류인 <code>Diffusion model</code>이 등장하여 확장성도 있고, 높은 품질을 만들어내는 성능을 보였주었다.</li>
</ol>
<br>
<ol start="9">
<li><code>CIFAR-10</code>에서 <code>SOTA</code>를 달성했지만 다른 어려운 dataset(<code>LSUN</code>, <code>ImageNet</code>)에 대해서는 <code>GAN</code>에 밀려있었다.</li>
</ol>
<ul>
<li>논문 저자들이 <code>Improved Denoising Diffusion Probabilistic Models</code>에서 <code>diffusion model</code>의 신뢰성을 증가시키는 연구를 했지만 <code>FID</code>가 <code>GAN</code>에 비하여 <strong>경쟁력 있지는 않았었다.</strong></li>
</ul>
<br>
<ol start="10">
<li><code>본 논문</code>에선 <code>GAN</code>과 <code>Diffusion model</code>이 차이가 나는 <code>두 가지 요인</code>에서 비롯된다고 가정한다.</li>
</ol>
<ul>
<li>최근 <code>GAN</code> 연구에서 사용된 모델 아키텍처는 <strong>광범위하게 탐색되고 최적화</strong>되었다.</li>
<li><code>GAN</code>은 <code>다양성(diversity)</code>과 <code>정확성(fidelity)</code> 사이에서 trade-off의 균형을 조절한다. 따라서 <code>GAN</code>은 높은 품질의 샘플을 생성하는 대신 전체 데이터 분포를 완전히 포괄하지는 못한다.
<ul>
<li><code>GAN</code>은 <code>Generator</code>, <code>Discriminator</code>로 나뉘어져 있으므로 둘 간 균형을 조정한다.</li>
</ul>
</li>
</ul>
<br>
<ol start="11">
<li><code>본 논문</code>에선 이 두 가지의 요인을 <code>Diffusion model</code>에도 적용하고자 한다.</li>
</ol>
<ul>
<li>먼저 <strong>모델의 아키텍쳐를 개선</strong>하고, 이후 <code>다양성</code>과 <code>정확성</code> 간의 trade-off의 균형을 조절 할 수 있는 기법을 개발한다.</li>
</ul>
<br>
<ol start="12">
<li>이 결과 본 논문에서 제안한 <code>diffusion model</code>이 새로운 <code>SOTA</code>를 달성하며, <code>GAN</code>을 이기게 되었다.</li>
</ol>
<hr>
<h2 id="background">Background</h2>
<ol start="13">
<li>이번 단락에서는 <code>Diffusion model</code> 중 <code>DDPM</code>에 대한 <strong>간단한 배경</strong>을 설명하고 있다. Diffusion model에 대한 자세한 설명은 <a href="https://goodyoung.github.io/posts/paper/ddpm/" target="_blank" rel="noopener noreffer ">해당 링크</a>에서 보면 될 것 같다.</li>
</ol>
<br>
<ol start="14">
<li><code>DDPM</code>에서의 목표는 조금 더 덜 노이즈가 포함된 $x_\text{t-1}$ 를 $x_t$에서 <strong>생성하는 과정을 학습하게 된다.</strong></li>
</ol>
<br>
<ol start="15">
<li><code>DDPM</code>에서 학습하기 위한 loss로 실제 변분 하한(Variational Lower Bound) $L_\text{vlb}$를 단순화한 $L_\text{simple}$이 성능이 좋음을 관찰하였다.</li>
</ol>
<br>
<ol start="16">
<li>이런 훈련 절차와 샘플링 절차는 denoising score matching model과 동일하다고 한다.</li>
</ol>
<br>
<ol start="17">
<li>다음으로, 조금 더 나은 <code>diffusion model</code>을 설명하게 되는데 기존 <code>DDPM</code>에서는 <code>reverse process</code>에서의 분산 $\Sigma_\theta(x_t, t)$ 을 <strong>고정된 값</strong>으로 설정하였는데, 이런 <code>고정된 분산</code>이 샘플링 단계 수가 적을 때 <strong>성능이 낮아질 수 있다.</strong></li>
</ol>
<br>
<ol start="18">
<li>따라서 $\Sigma_\theta(x_t, t)$ 를 파라미터화 하여 해결하려고 했고, 훈련 loss 또한 $L_\text{vlb}$ 과 $L_\text{simple}$ 를 함께 사용하는 <code>hybrid objective</code>로 해결한다.</li>
</ol>
<ul>
<li><code>본 논문</code>에서도 <code>해당 objecive</code>와 <code>parameterization</code>을 사용한다.</li>
</ul>
<br>
<ol start="19">
<li>또한 <code>DDIM</code>의 <code>Non-Markovian</code> 과정으로 인한 <code>샘플링 스텝</code>을 줄이는 방법 또한 <code>본 논문</code>에서 사용한다.</li>
</ol>
<br>
<ol start="20">
<li>마지막으로 샘플 품질을 평가하는 <code>metrics</code>에 관한 설명으로 이어진다. <code>Metrics</code> 중 <code>Inception Score(IS)</code>는 <code>ImageNet 클래스 분포</code>를 얼마나 잘 학습했는지를 측정하는 메트릭이다.</li>
</ol>
<br>
<ol start="21">
<li><code>개별 샘플</code>이 특정 클래스의 예제를 얼마나 그럴듯하게 평가하면서도, 모델이 <code>전체 dataset 클래스 분포</code>를 잘 반영했는지 측정한다. 이런 <code>IS</code>도 한계점이 있는데, 아래는 <code>IS</code>의 한계점을 설명한 것이다.</li>
</ol>
<ul>
<li>모든 클래스에 대한 <code>전체 분포</code>를 얼마나 잘 커버하는지 평가하지 못한다.</li>
<li>데이터셋의 일부를 단순히 <code>암기한 모델</code>도 <strong>높은 IS 점수</strong>를 가질 수 있다.</li>
</ul>
<br>
<ol start="22">
<li><code>Fréchet Inception Distance (FID)</code>는 <code>IS</code>보다 더 다양성을 잘 평가할 수 있는 방법이다. <code>Inception-V3 모델</code>의 <code>latent space</code>에서 <strong>두 이미지 분포 간 거리를 측정</strong>하여 두 이미지 분포 간의 <code>symmetric measure of distance</code>를 측정하게 된다.</li>
</ol>
<ul>
<li><code>sFID</code>라는 변형 버전은 기존 <code>FID</code>보다 <code>공간적 특성</code>을 고려하여 더 정교한 평가가 가능하다.</li>
</ul>
<br>
<ol start="23">
<li>마지막 평가 방법인 <code>개선된 precision &amp; recall 기반 metrics</code>가 있다.</li>
</ol>
<br>
<ol start="24">
<li><code>본 논문</code>은 <code>FID</code>를 기본 평가 지표로 사용하고 <em>일관된 평가</em>를 위해 <code>동일한 공개 샘플, 코드베이스</code>를 사용하여 평가를 진행한다.</li>
</ol>
<hr>
<h2 id="architecture-improvements">Architecture Improvements</h2>
<div style="text-align:center;">
<img src="/images/paper/dm-gans/model-1.png" height="70%" width="70%"> </div>
<ol start="25">
<li><code>Introduction 11번 글</code>에서 설명했듯이 <code>모델의 아키텍쳐</code>를 <code>개선한 방법론</code>을 먼저 설명을 할 것이다. 그 후 <code>다양성</code>과 <code>정확성</code>을 조절한 <code>Classifier Guidance</code>를 설명할 것이다.</li>
</ol>
<br>
<ol start="26">
<li><code>모델의 아키텍쳐</code>를 개선하기 위하여 <code>모델 구조</code>에 대하여 <code>ablation study</code>를 진행하였다. <code>DDPM</code>에서는 <code>UNet</code>을 사용하였고 해당 구조는 다음과 같은 구성을 가진다. 모든 <code>실험</code>은 <code>동일한</code> 데이터 셋에서 진행했다.</li>
</ol>
<ul>
<li><code>Residual layers</code>와 <code>다운샘플링 &amp; 업샘플링 convolutions</code>을 거쳐 피처를 <strong>압축 및 복원</strong></li>
<li><code>Skip connections</code>을 사용하여 같은 공간 크기(spatial size)를 갖는 레이어 간 정보를 직접 전달</li>
<li><code>16×16</code>에서 <code>단일 헤드</code>를 사용하는 <code>글로벌 어텐션(Global Attention) 레이어</code> 추가</li>
<li><code>각 Residual block</code>에 <code>timestep embedding</code> 투영(projection)</li>
</ul>
<br>
<ol start="27">
<li><code>본 논문</code>에서는 다음의 구성을 추가하여 모델 구조를 변형하여 실험한다.</li>
</ol>
<ul>
<li><code>깊이 vs. 너비</code> 조정 → 모델 크기를 유지하면서 깊이를 늘릴지, 너비를 늘릴지 실험
<ul>
<li>깊이를 증가시키면 <strong>성능이 향상되지만</strong>, 학습 시간이 <strong>길어지는 단점이 발생</strong></li>
<li>이후 실험에서 깊이를 증가시키는 실험을 사용하지 않기로 결정함</li>
</ul>
</li>
<li><code>attention head 수 증가</code> → 더 많은 <code>attention head</code>가 성능 향상에 기여하는지 실험
<ul>
<li><code>고정된 attention head 수</code> vs <code>고정된 채널 수</code>를 비교 실험을 하였다.
<ul>
<li>attention를 <strong>늘리거나</strong> head당 채널 수를 <strong>줄이는 것</strong>이 <code>FID 향상</code></li>
</ul>
</li>
</ul>
</li>
<li><code>attention 범위 확장</code> → 기존 16×16에서만 적용하던 <code>attention</code>을 <code>32×32</code>, <code>16×16</code>, <code>8×8</code>에도 적용</li>
<li><code>BigGAN residual block 활용</code> → 업샘플링 및 다운샘플링 과정에서 <code>BigGAN</code>의 <code>residual block</code> 사용</li>
<li><code>Residual connection rescaling</code> → 안정성을 위해 residual connection을 √(1/2)로 조정</li>
</ul>
<br>
<ol start="28">
<li>결론적으로 이러한 실험 사항들이 서로 결합될 때 <code>더 큰 성능 향상</code>을 보였다.</li>
</ol>
<h3 id="adaptive-group-normalizationadagn">Adaptive Group Normalization(AdaGN)</h3>
<ol start="29">
<li><code>AdaGN</code>은 <code>Group Normalization</code> 후에 <code>timestep</code> 및 <code>class embedding</code>을 <code>residual block</code>에 적용하는 방식이다.</li>
</ol>
<br>
<p>$$\text{AdaGN}(h,y) =y_s\text{GroupNorm}(h) + y_b$$</p>
<ul>
<li>$h$: 첫 번째 <code>convolution</code> 이후의 <code>residual block</code>의 <code>중간 활성값(intermediate activations)</code></li>
<li>$y = [y_s, y_b]$: <code>timestep 및 class embedding</code>을 <code>선형 변환</code>하여 생성된 벡터</li>
</ul>
<ol start="30">
<li>이로 인하여 <code>각 residual block</code>에 <code>timestep</code>과 <code>클래스 정보</code>를 반영할 수 있음</li>
</ol>
<br>
<ol start="31">
<li>초기에 <code>AdaGN</code>을 적용한 <code>diffusion model</code>에서 성능 향상을 하여, 기본 값으로 사용을 한다.</li>
</ol>
<br>
<ol start="32">
<li>그래서 <code>모든 비교 실험</code>을 거쳐 <code>최종 모델 아키텍쳐</code>는 다음과 같다.</li>
</ol>
<ul>
<li>각 해상도당 <code>residual block</code> 2개</li>
<li>64채널 per head의 <code>다중 어텐션 구조</code></li>
<li>해상도 <code>32×32</code>, <code>16×16</code>, <code>8×8</code>에서 어텐션 적용</li>
<li><code>BigGAN residual blocks</code>을 업/다운샘플링에 사용</li>
<li><code>AdaGN</code> 적용</li>
</ul>
<hr>
<h2 id="classifier-guidance">Classifier Guidance</h2>
<ol start="33">
<li><code>conditional gan</code>은 잘 설계된 아키텍쳐뿐 아니라 <code>class labels</code>을 활용한다. <code>class 정보</code>가 생성 모델의 <strong>중요한 역할을 한다.</strong></li>
</ol>
<ul>
<li><code>GAN</code>에서는 <code>discriminator</code>를 통하여 <code>class 정보</code>를 반영한다.</li>
</ul>
<br>
<ol start="34">
<li>따라서 <code>conditional diffusion</code>도 연구해볼만한 가치가 있다.</li>
</ol>
<br>
<ol start="35">
<li>이미 <code>AdaGN</code>에서 <code>class 정보</code>를 <strong>포함하는 방법</strong>을 사용했는데, 이 방법 말고 <code>본 논문</code>은 <code>classifier</code> ($p(y|x)$)를 활용하여 <code>diffusion</code>의 <strong>성능을 향상</strong>시키는 것을 보여준다.</li>
</ol>
<br>
<ol start="36">
<li><code>이전 연구</code>에서는 <code>pretrained diffusion model</code>이 <code>classifier</code>의 <strong>gradient를 활용</strong>하여 조건부 생성이 가능함을 보였다.</li>
</ol>
<br>
<ol start="37">
<li>따라서 <code>본 논문</code>은 <code>noisy</code>한 $x_t$를 기반으로 분류기 $p_\phi(y|x_t,t)$를 학습시키고, 그 <strong>gradient를 활용</strong> ($\nabla_{x_t}logp_\phi(y|x_t,t)$)하여 <code>diffusion sampling process</code>를 <code>특정 클래스</code> $y$로 유도되도록 할 것이다.</li>
</ol>
<br>
<ol start="38">
<li>앞으로 <code>분류기 조건부 샘플링 방법</code>에 대해 <code>두 가지</code>를 검토 한 후 샘플 품질 개선에 대해서 사용하는 방법을 설명 할 것이다.</li>
</ol>
<h3 id="conditional-reverse-noising-process">Conditional Reverse Noising Process</h3>
<ol start="39">
<li>continue</li>
</ol>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2025-02-27</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://goodyoung.github.io/posts/paper/dm-gans/" data-title="[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)" data-hashtags="논문 리뷰,computer vision,Diffusion,DM-GANs,Classifier Guidance"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://goodyoung.github.io/posts/paper/dm-gans/" data-hashtag="논문 리뷰"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://goodyoung.github.io/posts/paper/dm-gans/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://goodyoung.github.io/posts/paper/dm-gans/" data-title="[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://goodyoung.github.io/posts/paper/dm-gans/" data-title="[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://goodyoung.github.io/posts/paper/dm-gans/" data-title="[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://goodyoung.github.io/posts/paper/dm-gans/" data-title="[Paper Review]Diffusion Models Beat GANs on Image Synthesis(DM-GANs)" data-description=""><i class="fab fa-blogger fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/">논문 리뷰</a>,&nbsp;<a href="/tags/computer-vision/">computer vision</a>,&nbsp;<a href="/tags/diffusion/">Diffusion</a>,&nbsp;<a href="/tags/dm-gans/">DM-GANs</a>,&nbsp;<a href="/tags/classifier-guidance/">Classifier Guidance</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/paper/ldm/" class="prev" rel="prev" title="[Paper Review]High-Resolution Image Synthesis with Latent Diffusion Models(LDM)"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[Paper Review]High-Resolution Image Synthesis with Latent Diffusion Models(LDM)</a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
  
</footer>
</div>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"goodylung/blog-comment"}},"lightgallery":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-86432198-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body>
</html>
