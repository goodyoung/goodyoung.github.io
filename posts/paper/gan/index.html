<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[Paper Review]Generative Adversarial Nets(GAN) - Good Young</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="[Paper Review]Generative Adversarial Nets(GAN)" />
<meta property="og:description" content="개요 VAE논문 다음으로 Generative분야에서 기초가 되는 논문인 GAN에 관한 리뷰를 할 것이다. Introduction 다양한 data환경에서 확률 분포를 잘 표현할 수 있는 풍부하고 계층적인 모델을 발견하는 것이 딥러닝의 잠재력이다. 딥러닝의 두드러진 성공 사례는 풍부한 감각 input을 class label로 매핑하는 판별 모델이다. 이런 성공은 backpropagation과 dropout의 algorithm, gradient를 가진 조각별 선형적 유닛들(ReLU)에 기반을 두고 있다. 그동안 Deep generative model은 큰 영향을 끼치진 못했다. Likelihood에 대한 추정과 관련된 전략에서 발생하는 계산을 근사화하는 것이 어렵고, 조각별 선형적 유닛들을 활용하여 generative에서 활용하는 것도 어렵기 때문이다. 따라서 본 논문은 이런 어려움들을 피할 수 있는 추정 절차를 제안한다. 제안된 adversarial nets은 generative model은 discriminative model과 맞서게 된다. Discriminative model은 model 분포에서 나온 것인지 data 분포에서 나온 것인지 구분하는 방법을 학습한다. Generative model은 위조자와 비슷하게 생각할 수 있다. 이는 fake 지폐를 만들어 경찰의 탐지 없이 사용하려고 한다. 반면 discriminative model은 경찰에 비유할 수 있다. 이런 fake 지폐를 탐지하려고 한다. 이런 상황 속에서 두개의 model이 자신들의 방법을 개선하려고 한다. 결국 위조지폐가 진짜 지폐와 구별되지 않게 되게 된다. 이 framework는 다양한 모델과 최적화 방법에 대해서 특정한 training algorithm을 도출할 수 있다. Generative 모델이 MLP을 통해 random noise를 통과시켜 sample을 생성하는 특수한 경우를 탐구합니다. 이런 특수한 경우를 적대적 신경망(Adversarial Nets)이라고 부른다. Generative, discriminative model 둘 다 backpropagation을 통하여 업데이트를 하며 generative model을 통하여 sampling을 할 땐 forward만 수행한다. Adversarial nets 이젠 Adversarial nets에 대한 설명을 할 것 이다. Adversarial modeling framework는 both multilayer perceptron 일 때 곧바로 적용할 수 있다. Data x에 $p_g$ 분포를 배우기 위하여 사전에 noise 변수 $p_z(z)$를 선언한다. 그 후 $G(z;\theta_g)$의 data space에 매핑을 하게 된다. 이 때 $G$는 파라미터 $\theta_g$를 지닌 미분 가능한 함수이다. 또한 두번째 multilayer perceptron이고 output이 하나의 scalar가 나오는 $D(x;\theta_d)$가 있게 된다. 이때 $D(x)$는 $p_g$분포와는 다른 $x$로부터 나왔을 확률을 representation한다. 이때 나온 output(single scalar)이 1: real ~ 0: fake일 확률을 나타낸다. 본 논문에서 나오는 훈련은 $D$는 훈련 샘플과 $G$에서 나온 샘플 (fake image) 모두에 대해 올바른 label(real or fake)을 할당하는 확률을 최대화하도록 훈련이 된다. 또 동시에 $G$를 $log(1-D(G(z))$ 를 사용하여 최소화 하는 방식으로 훈련을 하게 된다. 위의 내용을 총 정리한 $V(G,D)$ 의 목적 함수(Object Function)를 나타내면 아래의 식이다. $$\min_G \max_D V(D, G) = E_{x \sim p_{\text{data}}(x)} [\log D(x)] &#43; E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$$
위의 Adversarial net을 나타내는 목적 함수를 좀 더 살펴 보도록 할 것 이다. $\min_G \max_D V(D, G)$ 의 부분을 먼저 살펴보자면 $V(D, G)$ 식에서 $G$ 는 낮추고자 하고 $D$ 는 높이고자 하는 것을 알 수 있다. $D$의 목표는 진짜 데이터에 대해 높은 확률을 부여하고 가짜 데이터에 대해 낮은 값을 부여하도록 하는 역할이기 때문에 최대화를 목표로 한다. $G$의 목표는 생성된 데이터가 $D$에게 진짜 데이터 처럼 보이게 하는 역할이기 때문에 최소화를 목표로 한다. $E_{x \sim p_{\text{data}}(x)} [\log D(x)]$ 은 원본 데이터 $p_\text{data}(x)$에서 한개의 데이터인 $x$를 sampling을 하여 그 $x$를 $D$에 넣은 값에 $log$를 취한 값의 기대값을 나타낸다. 따라서 앞서 13번을 보면 사전에 noise 변수인 $p_z(z)$ 를 선언한다고 나와 있다. 따라서 $E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$ 의 식은 하나의 noise 분포 $p_z(z)$ 에서 한 값을 sampling하여 그 $x$ 를 생성자 $G$ 에 넣고 가짜 이미지를 만든 다음에 $D$에 넣고 $1-D$의 형태로 만든 값에 $log$를 취한 값의 기대값을 나타낸다. 그래서 이런 두 항을 $D$의 관점에서 봤을 때 maximize하기 때문에 원본 데이터(x)에 대해서는 real(1)을 찾을 수 있도록 하고 반면에 가짜 이미지(z)가 들어왔을 때는 그 이미지가 fake(0)인지 분류할 수 있게 가능하게 한다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://goodyoung.github.io/posts/paper/gan/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-09-02T14:52:43+09:00" />
<meta property="article:modified_time" content="2024-09-02T14:52:43+09:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[Paper Review]Generative Adversarial Nets(GAN)"/>
<meta name="twitter:description" content="개요 VAE논문 다음으로 Generative분야에서 기초가 되는 논문인 GAN에 관한 리뷰를 할 것이다. Introduction 다양한 data환경에서 확률 분포를 잘 표현할 수 있는 풍부하고 계층적인 모델을 발견하는 것이 딥러닝의 잠재력이다. 딥러닝의 두드러진 성공 사례는 풍부한 감각 input을 class label로 매핑하는 판별 모델이다. 이런 성공은 backpropagation과 dropout의 algorithm, gradient를 가진 조각별 선형적 유닛들(ReLU)에 기반을 두고 있다. 그동안 Deep generative model은 큰 영향을 끼치진 못했다. Likelihood에 대한 추정과 관련된 전략에서 발생하는 계산을 근사화하는 것이 어렵고, 조각별 선형적 유닛들을 활용하여 generative에서 활용하는 것도 어렵기 때문이다. 따라서 본 논문은 이런 어려움들을 피할 수 있는 추정 절차를 제안한다. 제안된 adversarial nets은 generative model은 discriminative model과 맞서게 된다. Discriminative model은 model 분포에서 나온 것인지 data 분포에서 나온 것인지 구분하는 방법을 학습한다. Generative model은 위조자와 비슷하게 생각할 수 있다. 이는 fake 지폐를 만들어 경찰의 탐지 없이 사용하려고 한다. 반면 discriminative model은 경찰에 비유할 수 있다. 이런 fake 지폐를 탐지하려고 한다. 이런 상황 속에서 두개의 model이 자신들의 방법을 개선하려고 한다. 결국 위조지폐가 진짜 지폐와 구별되지 않게 되게 된다. 이 framework는 다양한 모델과 최적화 방법에 대해서 특정한 training algorithm을 도출할 수 있다. Generative 모델이 MLP을 통해 random noise를 통과시켜 sample을 생성하는 특수한 경우를 탐구합니다. 이런 특수한 경우를 적대적 신경망(Adversarial Nets)이라고 부른다. Generative, discriminative model 둘 다 backpropagation을 통하여 업데이트를 하며 generative model을 통하여 sampling을 할 땐 forward만 수행한다. Adversarial nets 이젠 Adversarial nets에 대한 설명을 할 것 이다. Adversarial modeling framework는 both multilayer perceptron 일 때 곧바로 적용할 수 있다. Data x에 $p_g$ 분포를 배우기 위하여 사전에 noise 변수 $p_z(z)$를 선언한다. 그 후 $G(z;\theta_g)$의 data space에 매핑을 하게 된다. 이 때 $G$는 파라미터 $\theta_g$를 지닌 미분 가능한 함수이다. 또한 두번째 multilayer perceptron이고 output이 하나의 scalar가 나오는 $D(x;\theta_d)$가 있게 된다. 이때 $D(x)$는 $p_g$분포와는 다른 $x$로부터 나왔을 확률을 representation한다. 이때 나온 output(single scalar)이 1: real ~ 0: fake일 확률을 나타낸다. 본 논문에서 나오는 훈련은 $D$는 훈련 샘플과 $G$에서 나온 샘플 (fake image) 모두에 대해 올바른 label(real or fake)을 할당하는 확률을 최대화하도록 훈련이 된다. 또 동시에 $G$를 $log(1-D(G(z))$ 를 사용하여 최소화 하는 방식으로 훈련을 하게 된다. 위의 내용을 총 정리한 $V(G,D)$ 의 목적 함수(Object Function)를 나타내면 아래의 식이다. $$\min_G \max_D V(D, G) = E_{x \sim p_{\text{data}}(x)} [\log D(x)] &#43; E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$$
위의 Adversarial net을 나타내는 목적 함수를 좀 더 살펴 보도록 할 것 이다. $\min_G \max_D V(D, G)$ 의 부분을 먼저 살펴보자면 $V(D, G)$ 식에서 $G$ 는 낮추고자 하고 $D$ 는 높이고자 하는 것을 알 수 있다. $D$의 목표는 진짜 데이터에 대해 높은 확률을 부여하고 가짜 데이터에 대해 낮은 값을 부여하도록 하는 역할이기 때문에 최대화를 목표로 한다. $G$의 목표는 생성된 데이터가 $D$에게 진짜 데이터 처럼 보이게 하는 역할이기 때문에 최소화를 목표로 한다. $E_{x \sim p_{\text{data}}(x)} [\log D(x)]$ 은 원본 데이터 $p_\text{data}(x)$에서 한개의 데이터인 $x$를 sampling을 하여 그 $x$를 $D$에 넣은 값에 $log$를 취한 값의 기대값을 나타낸다. 따라서 앞서 13번을 보면 사전에 noise 변수인 $p_z(z)$ 를 선언한다고 나와 있다. 따라서 $E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$ 의 식은 하나의 noise 분포 $p_z(z)$ 에서 한 값을 sampling하여 그 $x$ 를 생성자 $G$ 에 넣고 가짜 이미지를 만든 다음에 $D$에 넣고 $1-D$의 형태로 만든 값에 $log$를 취한 값의 기대값을 나타낸다. 그래서 이런 두 항을 $D$의 관점에서 봤을 때 maximize하기 때문에 원본 데이터(x)에 대해서는 real(1)을 찾을 수 있도록 하고 반면에 가짜 이미지(z)가 들어왔을 때는 그 이미지가 fake(0)인지 분류할 수 있게 가능하게 한다."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://goodyoung.github.io/posts/paper/gan/" /><link rel="prev" href="https://goodyoung.github.io/posts/paper/multimodal-survey/" /><link rel="next" href="https://goodyoung.github.io/posts/paper/dcgan/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[Paper Review]Generative Adversarial Nets(GAN)",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/goodyoung.github.io\/posts\/paper\/gan\/"
        },"genre": "posts","keywords": "GAN, 논문 리뷰, Generative","wordcount":  1283 ,
        "url": "https:\/\/goodyoung.github.io\/posts\/paper\/gan\/","datePublished": "2024-09-02T14:52:43+09:00","dateModified": "2024-09-02T14:52:43+09:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "GoodYoung"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Good Young">GoodYoung Dev Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Good Young">GoodYoung Dev Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[Paper Review]Generative Adversarial Nets(GAN)</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://goodyoung.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>GoodYoung</a></span>&nbsp;<span class="post-category">included in <a href="/categories/paper-review/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Paper Review</a>&nbsp;<a href="/categories/dl/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>DL</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2024-09-02">2024-09-02</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;1283 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;7 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#adversarial-nets">Adversarial nets</a></li>
    <li><a href="#theoretical-analysis-of-adversarial-nets">Theoretical analysis of adversarial nets</a></li>
    <li><a href="#global-optimality">Global Optimality</a></li>
    <li><a href="#experiment">Experiment</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- image format
<div style="text-align:center;">
<img src="/images/cs231n/lecture4/back-1.png" height="100%" width="80%"> </div>
 -->
<h2 id="개요">개요</h2>
<ol start="0">
<li><code>VAE</code>논문 다음으로 <code>Generative</code>분야에서 기초가 되는 논문인 <code>GAN</code>에 관한 리뷰를 할 것이다.</li>
</ol>
<hr>
<h2 id="introduction">Introduction</h2>
<ol>
<li>다양한 <code>data환경</code>에서 <code>확률 분포</code>를 잘 표현할 수 있는 풍부하고 <code>계층적인 모델</code>을 발견하는 것이 <code>딥러닝의 잠재력</code>이다.</li>
</ol>
<br>
<ol start="2">
<li><code>딥러닝</code>의 두드러진 성공 사례는 풍부한 <code>감각 input</code>을 <code>class label</code>로 매핑하는 판별 모델이다.</li>
</ol>
<ul>
<li>이런 성공은 <code>backpropagation</code>과 <code>dropout</code>의 algorithm, gradient를 가진 <code>조각별 선형적 유닛들(ReLU)</code>에 기반을 두고 있다.</li>
</ul>
<br>
<ol start="3">
<li>그동안 <code>Deep generative model</code>은 큰 영향을 끼치진 못했다. <code>Likelihood</code>에 대한 추정과 관련된 전략에서 발생하는 계산을 근사화하는 것이 어렵고, <code>조각별 선형적 유닛들</code>을 활용하여 <code>generative</code>에서 활용하는 것도 어렵기 때문이다.</li>
</ol>
<br>
<ol start="4">
<li>따라서 본 논문은 이런 <strong>어려움들을 피할 수 있는</strong> <code>추정 절차</code>를 제안한다.</li>
</ol>
<br>
<ol start="5">
<li>제안된 <code>adversarial nets</code>은 <code>generative model</code>은 <code>discriminative model</code>과 맞서게 된다.</li>
</ol>
<br>
<ol start="6">
<li><code>Discriminative model</code>은 <code>model 분포</code>에서 나온 것인지 <code>data 분포</code>에서 나온 것인지 구분하는 방법을 학습한다.</li>
</ol>
<br>
<ol start="7">
<li><code>Generative model</code>은 위조자와 비슷하게 생각할 수 있다. 이는 fake 지폐를 만들어 경찰의 탐지 없이 사용하려고 한다. 반면 <code>discriminative model</code>은 경찰에 비유할 수 있다. 이런 fake 지폐를 탐지하려고 한다.</li>
</ol>
<br>
<ol start="8">
<li>이런 상황 속에서 두개의 model이 자신들의 방법을 개선하려고 한다. <strong>결국 위조지폐가 진짜 지폐와 구별되지 않게 되게 된다.</strong></li>
</ol>
<br>
<ol start="9">
<li>이 framework는 다양한 모델과 최적화 방법에 대해서 <code>특정한 training algorithm</code>을 도출할 수 있다.</li>
</ol>
<br>
<ol start="10">
<li><code>Generative 모델</code>이 MLP을 통해 <code>random noise</code>를 통과시켜 sample을 생성하는 <strong>특수한 경우</strong>를 탐구합니다. 이런 <strong>특수한 경우</strong>를 <code>적대적 신경망(Adversarial Nets)</code>이라고 부른다.</li>
</ol>
<br>
<ol start="11">
<li><code>Generative, discriminative model</code> 둘 다 <code>backpropagation</code>을 통하여 업데이트를 하며 <code>generative model</code>을 통하여 sampling을 할 땐 <code>forward</code>만 수행한다.</li>
</ol>
<hr>
<h2 id="adversarial-nets">Adversarial nets</h2>
<div style="text-align:center;">
<img src="/images/paper/gan/overall.png" height="100%" width="80%"> </div>
<ol start="12">
<li>이젠 <code>Adversarial nets</code>에 대한 설명을 할 것 이다. <code>Adversarial modeling framework</code>는 <code>both multilayer perceptron</code> 일 때 곧바로 적용할 수 있다.</li>
</ol>
<br>
<ol start="13">
<li>Data x에 $p_g$ 분포를 배우기 위하여 사전에 <code>noise 변수</code> $p_z(z)$를 선언한다. 그 후 $G(z;\theta_g)$의 data space에 매핑을 하게 된다.</li>
</ol>
<ul>
<li>이 때 $G$는 파라미터 $\theta_g$를 지닌 미분 가능한 함수이다.</li>
</ul>
<br>
<ol start="14">
<li>또한 <code>두번째 multilayer perceptron</code>이고 output이 <code>하나의 scalar</code>가 나오는 $D(x;\theta_d)$가 있게 된다. 이때 $D(x)$는 $p_g$분포와는 다른 $x$로부터 나왔을 확률을 <code>representation</code>한다.</li>
</ol>
<ul>
<li>이때 나온 output(single scalar)이 <code>1: real ~ 0: fake</code>일 확률을 나타낸다.</li>
</ul>
<br>
<ol start="15">
<li>본 논문에서 나오는 <code>훈련</code>은 $D$는 <code>훈련 샘플</code>과 $G$<code>에서 나온 샘플 (fake image)</code> 모두에 대해 <code>올바른 label(real or fake)</code>을 할당하는 확률을 <strong>최대화하도록 훈련이 된다.</strong></li>
</ol>
<br>
<ol start="16">
<li>또 동시에 $G$를 $log(1-D(G(z))$ 를 사용하여 <strong>최소화 하는 방식으로 훈련을 하게 된다.</strong></li>
</ol>
<br>
<ol start="17">
<li>위의 내용을 총 정리한 $V(G,D)$ 의 <code>목적 함수(Object Function)</code>를 나타내면 아래의 식이다.</li>
</ol>
<p>$$\min_G \max_D V(D, G) = E_{x \sim p_{\text{data}}(x)} [\log D(x)] + E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$$</p>
<br>
<ol start="18">
<li>위의 <code>Adversarial net</code>을 나타내는 목적 함수를 좀 더 살펴 보도록 할 것 이다.</li>
</ol>
<br>
<ol start="19">
<li>$\min_G \max_D V(D, G)$ 의 부분을 먼저 살펴보자면 $V(D, G)$ 식에서 $G$ 는 낮추고자 하고 $D$ 는 높이고자 하는 것을 알 수 있다.</li>
</ol>
<ul>
<li>$D$의 목표는 <strong>진짜 데이터에 대해 높은 확률을 부여하고 가짜 데이터에 대해 낮은 값을 부여하도록 하는 역할이기 때문에 최대화를 목표로 한다.</strong></li>
<li>$G$의 목표는 <strong>생성된 데이터가 $D$에게 진짜 데이터 처럼 보이게 하는 역할이기 때문에 최소화를 목표로 한다.</strong></li>
</ul>
<br>
<ol start="20">
<li>$E_{x \sim p_{\text{data}}(x)} [\log D(x)]$ 은 원본 데이터 $p_\text{data}(x)$에서 한개의 데이터인 $x$를 sampling을 하여 그 $x$를 $D$에 넣은 값에 $log$를 취한 값의 기대값을 나타낸다.</li>
</ol>
<ul>
<li>따라서</li>
</ul>
<br>
<ol start="21">
<li>앞서 13번을 보면 사전에 <code>noise 변수</code>인 $p_z(z)$ 를 선언한다고 나와 있다.</li>
</ol>
<br>
<ol start="22">
<li>따라서 $E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$ 의 식은 하나의 <code>noise 분포</code> $p_z(z)$ 에서 한 값을 sampling하여 그 $x$ 를 생성자 $G$ 에 넣고 <code>가짜 이미지</code>를 만든 다음에 $D$에 넣고 $1-D$의 형태로 만든 값에 $log$를 취한 값의 기대값을 나타낸다.</li>
</ol>
<br>
<ol start="23">
<li>그래서 이런 두 항을 $D$의 관점에서 봤을 때 <code>maximize</code>하기 때문에 <code>원본 데이터(x)</code>에 대해서는 <code>real(1)</code>을 찾을 수 있도록 하고 반면에 <code>가짜 이미지(z)</code>가 들어왔을 때는 그 이미지가 <code>fake(0)</code>인지 <strong>분류할 수 있게 가능하게</strong> 한다.</li>
</ol>
<br>
<ol start="24">
<li>생성자 $G$는 이 $E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$ 항을 <code>minimize</code>하기 때문에 다음과 같이 해석을 할 수 있게 된다.</li>
</ol>
<br>
<ol start="25">
<li><code>noise 분포</code>에서 뽑은 가짜 이미지가 판별자에 의해서 진짜(1)라고 내뱉을 수 있도록 학습을 하는 것이다.</li>
</ol>
<ul>
<li>$G$가 <strong>그럴싸한 이미지</strong>를 만들 수 있도록 학습을 하는 것이다.</li>
</ul>
<hr>
<h2 id="theoretical-analysis-of-adversarial-nets">Theoretical analysis of adversarial nets</h2>
<div style="text-align:center;">
<img src="/images/paper/gan/fig-1.png" height="100%" width="80%"> </div>
<ol start="26">
<li>다음은 <code>Adversarial net</code>의 이론적 분석을 제시한다. <code>Non-parametric limit인 상황</code>에서 이 <code>Net</code>의 <code>훈련 기준</code>은 $G$와 $D$가 충분하게 있을 때 data를 <code>generating</code>하는 기능을 하게 된다.</li>
</ol>
<ul>
<li>이때 나온 <code>Non-parametric</code>상황은 <strong>특정한 매개변수 수에 제한되지 않는다는 것을 의미</strong>하게 된다.
<ul>
<li>즉, 임의의 복잡한 함수도 근사할 수 있는 <strong>충분한 유연성</strong>을 가진 경우를 의미한다.</li>
</ul>
</li>
</ul>
<br>
<ol start="27">
<li>$D$를 최적화 하는 단계를 k번 반복하고, $G$를 최적화하는 단게를 한 번 수행하게 된다.</li>
</ol>
<ul>
<li>$G$가 충분히 천천히 변하는 동안 $D$가 <strong>optimal한 solution</strong>을 지니도록 한다.</li>
</ul>
<br>
<ol start="28">
<li>위 그림은 해당 학습 과정에 데이터 분포를 그림으로 표현한 것이다. <code>파란색 점선</code> : discriminative distribution(데이터 구분), <code>검은색 점선</code> : data generating distribution $p_x$(실제 데이터), <code>녹색 실선</code> : generative distribution $p_g$(생성한 데이터)이다.</li>
</ol>
<ul>
<li>또한 밑에 수평선 $z$는 $z$가 <code>샘플되는 영역(domain)</code>을 나타낸다.</li>
<li>이때 <code>z-&gt;x</code>로 향하는 <strong>화살표들은</strong> <code>mapping x = G(z)</code>가 <code>non-uniform</code>한 분포 <code>p_g</code>를 <code>transformed samples</code>로 변경하게 된다.</li>
</ul>
<br>
<ol start="29">
<li><code>각 단계</code>에 대한 설명을 할 것이다. <code>a</code>: 학습 초기 단계이다. 그림을 보면 <code>discriminative distribution</code>이 <strong>부분적으로</strong> 정확한 classifier인 상태이다.</li>
</ol>
<br>
<ol start="30">
<li><code>b</code>: $D$가 $D*(x) = p_data(x)/((p_data(x) + p_g(x))$로 <strong>수렴하여</strong> <code>실제 데이터</code>와 <code>생성된 가짜 데이터</code>를 구분할 수 있게 학습이 된 상태이다.</li>
</ol>
<br>
<ol start="31">
<li><code>c</code>: $G$를 학습시킵니다. 이때 $D$의 <code>그래디언트</code>는 $G(z)$가 <code>실제 데이터</code>와 <code>같은 데이터</code>로 변형되게 변하는 상태를 볼 수 있다.</li>
</ol>
<br>
<ol start="32">
<li><code>d</code>: $G$와 $D$가 충분한 능력을 가질 때까지 <code>a~c</code>를 <strong>여러번 반복합니다.</strong> $G$는 $p_g = p_data$라고 할 정도로 데이터를 잘 생성하는 것을 확인할 수 있다. 또한 $D$는 <strong>두 데이터의 차이를 구분할 수 없게</strong> 되었다. <strong>즉, D(x) = 0.5입니다.</strong></li>
</ol>
<ul>
<li><code>0.5</code>인 이유는 훈련이 잘 되었을 때 $D$가 <strong>실제인지 가짜인지</strong> 50%의 확률로 추정하기 때문이다.</li>
</ul>
<br>
<div style="text-align:center;">
<img src="/images/paper/gan/algorithm.png" height="100%" width="80%"> </div>
<ol start="33">
<li><code>위 그림</code>은 <code>위의 단계들</code>을 <code>pseudo code</code>로 각 step을 나타낸 그림이다.</li>
</ol>
<br>
<ol start="34">
<li>결론적으로 <code>adversarial net</code>의 목적 함수들의 <code>최종 목표</code>를 정리하자면 $p_g -&gt; p_\text{data}$ 이다. <strong>생성자의 분포가 원본 학습데이터의 분포를 잘 따를 수</strong> 있도록 만드는 것이다.</li>
</ol>
<br>
<ol start="35">
<li>또한 $D(G(z)) -&gt; 1/2$이다. $D$가 더이상 <strong>가짜 데이터와 진짜 데이터를 구분할 수 없기 때문에</strong> $1/2$로 가게 되는 것이다.</li>
</ol>
<hr>
<h2 id="global-optimality">Global Optimality</h2>
<ol start="34">
<li>다음은 실제로 학습을 진행했을 때 $p_g -&gt; p_\text{data}$ 로 진행하는지에 대해서 증명을 할 것이다.</li>
</ol>
<ul>
<li>매 상황에서 $D$와 $G$가 어디서 <code>global optimal</code>을 가지는지에 대해서 나타낼 것이다.</li>
</ul>
<br>
<ol start="35">
<li>$G$가 고정되어 있을 때 $D$의 <code>optimal point</code>는 <code>아래 식</code>과 같다.</li>
</ol>
<p>$$D_G^*(x) = \frac{p_\text{data}(x)}{p_\text{data}(x) + p_g(x)}$$</p>
<br>
<ol start="36">
<li>이제 <code>위 식</code>이 어떻게 나왔는지에 대해서 증명을 할 것이다.</li>
</ol>
<br>
<ol start="37">
<li>$V(G,D)$를 변경을 하면 <code>아래 식</code>과 같아진다.
$$V(G, D) = E_{x \sim p_{\text{data}}(x)} [\log D(x)] + E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$$
$$= \int_x p_{\text{data}}(x) \log(D(x))dx + \int_z p_z(z) \log(1 - D(G(z)))dz \ (\therefore E[X] = \int_{-\infty}^{\infty} x f(x)dx
)$$</li>
</ol>
<br>
<ol start="38">
<li>그리고 식을 조금 더 정리를 하게 되면 <code>아래 식</code>과 같아진다.
$$= \int_x p_{\text{data}}(x) \log(D(x)) \dx + \int_x p_g(x) \log(1 - D(x))dx$$</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/paper/gan/optima.png" height="100%" width="80%"> </div>
<ol start="39">
<li>이때 $alog(y) + blog(1-y)$ 의 형태일 때 $\frac{a}{a+b}$ 에서 <code>global optima</code>를 가진다는 정리를 이용하게 되면 $D_G^*(x)$의 식이 나오게 되는 것이다.</li>
</ol>
<br>
<ol start="40">
<li>이제 $G$의 <code>global optima point</code>를 구하려고 한다.</li>
</ol>
<br>
<ol start="41">
<li>아래는 고정된 $G$에 대해서 $V$함수를 <strong>최대로 만드는</strong> $D$에 대한 함수 이다. 이는 <code>Global optima</code>를 가지는 $D$함수에 대한 $V$함수로 정의가 가능하다.
$$C(G) = max_D V(G, D) = E_{x \sim p_{\text{data}}(x)} [\log (D^*(x))]+ E_{z \sim p_z(z)} [\log(1 - D^*(G(z)))]$$
<ul>
<li>$D^*$로 $D$는 이미 <code>optima</code>하게 되어있는 것을 확인 할 수 있다.</li>
</ul>
</li>
</ol>
<br>
<ol start="42">
<li>위 식의 $D$를 풀어서 작성하면 아래 식과 같다.
$$= E_{x \sim p_{\text{data}}(x)} \left[ \log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)} \right] + E_{x \sim p_g(x)} \left[ \log \frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)} \right](\therefore D_G^*(x) = \frac{p_\text{data}(x)}{p_\text{data}(x) + p_g(x)})$$</li>
</ol>
<br>
<ol start="43">
<li><strong>식 변형을 위하여</strong> 식에 2를 곱하고 $log(4)$를 빼준다.
$$= E_{x \sim p_{\text{data}}(x)} \left[ \log \frac{2 \cdot p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)} \right] + E_{x \sim p_g(x)} \left[ \log \frac{2 \cdot p_g(x)}{p_{\text{data}}(x) + p_g(x)} \right]-log(4)$$</li>
</ol>
<br>
<ol start="44">
<li>이 식은 다시 <code>KL-divergence</code>로 변형할 수 있다.
$$= KL\left(p_{\text{data}} \bigg| \frac{p_{\text{data}}(x) + p_g(x)}{2} \right) + KL\left(p_g \bigg| \frac{p_{\text{data}}(x) + p_g(x)}{2} \right) - \log(4) (\therefore KL(p_{\text{data}} | p_g) = \int_{-\infty}^{\infty} p_{\text{data}}(x) \log \left( \frac{p_{\text{data}}(x)}{p_g(x)} \right) dx)$$</li>
</ol>
<br>
<ol start="45">
<li>이는 다시 $JSD$로 변환이 가능했다.</li>
</ol>
<ul>
<li><code>KL-divergence</code>는 <strong>두개의 분포가 수치적으로 얼마나 차이가 나는지</strong>에 대해서 일반적으로 사용할 수 있는 공식이다.</li>
<li><code>Jsd</code>는 <code>KL-divergence</code>는 <strong>distance matrix로 활용하기 어렵기 때문에</strong> <code>JSD방법론</code>을 사용하게 된다.
<ul>
<li>두개의 분포가 있을 때 <code>두 분포의 distance</code>를 구하는데 사용이 된다.</li>
</ul>
</li>
</ul>
<p>$$= 2 \cdot JSD(p_{\text{data}} | p_g) - \log(4)(\therefore JSD(p | q) = \frac{1}{2} KL\left(p \bigg| \frac{p + q}{2}\right) + \frac{1}{2} KL\left(q \bigg| \frac{p + q}{2}\right))$$</p>
<br>
<ol start="46">
<li><code>위 식</code>은 이 JSD 분포는 <strong>최솟값으로 0의 값을</strong> 가지게 된다. 따라서 최종적으로 최솟값으로 $-log(4)$로 얻는다.</li>
</ol>
<ul>
<li>그래서 이러한 최솟값을 얻을 수 있게 하는 것은 $p_data$와 $p_g$가 <strong>동일할 때를 의미한다.</strong></li>
</ul>
<br>
<ol start="47">
<li>따라서 <code>30번 라인</code>을 보면 $D$가 <strong>수렴을 한 후에</strong> $G$를 <strong>학습시켜</strong> $G$도 수렴하게 가중치 업데이트를 수행하게 되는 것을 알 수 있다.</li>
</ol>
<hr>
<h2 id="experiment">Experiment</h2>
<div style="text-align:center;">
<img src="/images/paper/gan/result-1.png" height="100%" width="80%"> </div>
<ol start="48">
<li><code>위의 훈련 결과</code>를 보면 노란색 박스가 훈련 중 가장 가까운 sample을 뽑은 것이다. 이를 보면 왼쪽과 확연히 다른 것을 확인 할 수 있는데 이는 모델이 훈련 시 <code>memorized</code><strong>하지 않았다는 것을 의미한다.</strong></li>
</ol>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=AVvlDmhHgC4" target="_blank" rel="noopener noreffer ">https://www.youtube.com/watch?v=AVvlDmhHgC4</a></li>
<li><a href="https://velog.io/@seo78200/Review-paperGenerative-Adversarial-Nets" target="_blank" rel="noopener noreffer ">https://velog.io/@seo78200/Review-paperGenerative-Adversarial-Nets</a></li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2024-09-02</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://goodyoung.github.io/posts/paper/gan/" data-title="[Paper Review]Generative Adversarial Nets(GAN)" data-hashtags="GAN,논문 리뷰,Generative"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://goodyoung.github.io/posts/paper/gan/" data-hashtag="GAN"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://goodyoung.github.io/posts/paper/gan/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://goodyoung.github.io/posts/paper/gan/" data-title="[Paper Review]Generative Adversarial Nets(GAN)"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://goodyoung.github.io/posts/paper/gan/" data-title="[Paper Review]Generative Adversarial Nets(GAN)"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://goodyoung.github.io/posts/paper/gan/" data-title="[Paper Review]Generative Adversarial Nets(GAN)"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://goodyoung.github.io/posts/paper/gan/" data-title="[Paper Review]Generative Adversarial Nets(GAN)" data-description=""><i class="fab fa-blogger fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/gan/">GAN</a>,&nbsp;<a href="/tags/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/">논문 리뷰</a>,&nbsp;<a href="/tags/generative/">Generative</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/paper/multimodal-survey/" class="prev" rel="prev" title="[Paper Review]Multimodal Machine Learning: A Survey and Taxonomy"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[Paper Review]Multimodal Machine Learning: A Survey and Taxonomy</a>
            <a href="/posts/paper/dcgan/" class="next" rel="next" title="[Paper Review]Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks(DCGAN)">[Paper Review]Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks(DCGAN)<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
  
</footer>
</div>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"goodylung/blog-comment"}},"lightgallery":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-86432198-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body>
</html>
