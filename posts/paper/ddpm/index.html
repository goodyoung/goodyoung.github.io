<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[Paper Review]Denoising Diffusion Probabilistic Models(DDPM) - Good Young</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)" />
<meta property="og:description" content="개요 Diffusion의 기초인 DDPM에 대한 논문을 리뷰할 것이다. Introduction 최근 몇 년간 다양한 생성 모델(deep generative models) 이 높은 품질의 샘플을 생성하는 성과를 보였다. 에너지 기반 모델(Energy-Based Models) 및 Score Matching 기법도 GAN과 비슷한 수준의 이미지 품질을 생성하는 연구가 등장했다. 이 논문은 Diffusion Probabilistic Models의 발전이다. Diffusion Probabilistic Models (DPMs, 2015): Markov chain을 기반으로 데이터를 점진적으로 샘플링하는 모델 Markov Chain이란? - 어떤 시간에 특정 state에 도달하든, 그 이전에 어떤 state를 거쳐왔든 다음 state로 갈 확률은 항상 같다는 성질이다. DPMs는 변분 추론을 활용해 샘플을 생성하기 위해 **확산 과정(diffusion process)을 반전(reverse)**시키는 방법을 학습한다. 변분 추론(variational inference) : 확률 모델에서 복잡한 후행 확률 분포(posterior distribution)를 근사하는 방법 중 하나이다. 정확한 posterior를 계산하는 것은 intractable하여 $p(z|x)$를 계산하는 것 대신 $q_\theta(z|x)$로 근사하는 방법이다. 즉, 변분 추론을 통해 모델의 역방향 과정의 확률 분포( $p(x_\text{t-1} | x_t)$ )를 근사하여, $p_\theta(x_\text{t-1} | x_t)$ 를 통하여 정방향 과정에서 추가된 노이즈를 제거하는 방법을 학습 DPMs은 정의하기 쉽고 학습이 효율적이지만, 지금까지 고품질 샘플을 생성할 수 있다는 실증적인 연구가 부족했다. 하지만 이 논문(DDPM)에서 DPMs이 고품질 샘플을 생성하고, 때때로 다른 모델보다 더 좋은 성능을 보인다. DDPM을 특정 방식으로 파라미터화 하면 다중 노이즈 수준에서 Denoising Score Matching과 동일하며, Annealed Langevin Dynamics와도 유사한 샘플링 방식을 갖는다는 점을 발견 한다. 46번에서 자세하게 설명을 한다. DDPM도 샘플의 품질은 뛰어나지만, log-likelihood 기반 모델들과 비교했을 때 경쟁력 있는 성능이 존재하진 않는다. Loss 중 많은 부분이 눈에 보이지 않는 미세한 이미지 세부 정보를 설명하는데 사용이 된다. log-likelihood model : VAE, Normalizing Flows, Autoregressive Models log 가능도를 최대화 하는 모델들 Background 4번에서 DPMs는 정방향 과정에서 추가된 노이즈(destroy)를 제거하는 방법을 학습하는 과정을 수행한다고 설명하였다. 물리학적으로 미세한 세계에서는 destroy된 상태를 backward로 복원시키는 것이 가능하다. DDPM에서는 노이즈를 점차 추가하여 destroy하는 정방향 과정을 diffusion process이라고 한다. 또한, 노이즈를 제거(denoising)하여 다시 복원하는 확률 분포(노이즈)를 학습하는 과정을 reverse process라고 한다. Diffusion Process Diffusion Process에 대해서 먼저 간단한 설명을 해보려고 한다. $$ q(x_\text{1:T} | x_0) := \prod_\text{t=1}^T q(x_t | x_\text{t-1}), \quad q(x_t | x_\text{t-1}) := \mathcal{N}(x_t ; \sqrt{1 - \beta_t} x_\text{t-1}, \beta_t I) $$
Diffusion Process의 근사 후행 확률은 $q(x_\text{1:T}|x_0)$ 으로 나타낼 수 있으며, 이는 마르코프 연쇄(Markov Chain)로 정의되어 이 과정에서 step마다 가우시안 노이즈를 추가하는 방식으로 작동한다. 이때 노이즈는 $\beta_1, &hellip; ,\beta_T$ 의 형태인 variance schedule에 따라 조절된다. $\beta_t$ 는 reparameterization trick에 의해서 학습이 될 수도 있고, 하이퍼파라미터로 고정될 수 있다. 다음은 $\beta_t$ 에 대하여 reparameterization trick을 적용한 것을 알아본 것이다.
$\beta_t$에 대하여 reparameterization trick을 적용 한 경우 $\beta_t$ 를 gaussian 분포에서 샘플링하는 확률적 변수로 설정한다면:
$\beta_t = \sigma(\tilde{\beta_t}),\qquad \tilde{\beta_t} \sim \mathcal{N}(\mu_\beta, \sigma_\beta^2) $
$\tilde{\beta_t}$ : 가우시안 분포에서 샘플링 된 값 $\sigma(\cdot)$ : activation function을 활용하여 $\beta_t$가 양수임을 보장 $\mu_\beta, \sigma_\beta $ : 학습 가능한 파라미터 위 식의 $\tilde{\beta_t}$ 을 gaussian 분포에서 직접 샘플링 하기 때문에 이는 확률적 연산이 포함되므로 미분이 불가능해진다.
미분이 불가능해지면 손실 함수의 그라디언트를 계산할 수 없게 된다. (학습 불가능) 그렇기 때문에 미분 가능해지기 위하여 $\beta_t$ 에 gaussian 분포에서 직접 샘플링하는 대신, 표준 정규 분포에서 샘플링한 후, 변형하는 방법인 reparametrization trick의 방법을 사용한다.
해당 방법을 사용하면 다음과 같이 표현 될 수 있다: $\tilde{\beta_t} = \mu_\beta &#43; \sigma_\beta \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, 1)$
이제 확률적 연산을 결정적 연산으로 변경하여 $\tilde{\beta_t}$ 를 샘플링하는 과정이 미분 가능해졌다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://goodyoung.github.io/posts/paper/ddpm/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-01-15T17:24:43+09:00" />
<meta property="article:modified_time" content="2025-01-15T17:24:43+09:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)"/>
<meta name="twitter:description" content="개요 Diffusion의 기초인 DDPM에 대한 논문을 리뷰할 것이다. Introduction 최근 몇 년간 다양한 생성 모델(deep generative models) 이 높은 품질의 샘플을 생성하는 성과를 보였다. 에너지 기반 모델(Energy-Based Models) 및 Score Matching 기법도 GAN과 비슷한 수준의 이미지 품질을 생성하는 연구가 등장했다. 이 논문은 Diffusion Probabilistic Models의 발전이다. Diffusion Probabilistic Models (DPMs, 2015): Markov chain을 기반으로 데이터를 점진적으로 샘플링하는 모델 Markov Chain이란? - 어떤 시간에 특정 state에 도달하든, 그 이전에 어떤 state를 거쳐왔든 다음 state로 갈 확률은 항상 같다는 성질이다. DPMs는 변분 추론을 활용해 샘플을 생성하기 위해 **확산 과정(diffusion process)을 반전(reverse)**시키는 방법을 학습한다. 변분 추론(variational inference) : 확률 모델에서 복잡한 후행 확률 분포(posterior distribution)를 근사하는 방법 중 하나이다. 정확한 posterior를 계산하는 것은 intractable하여 $p(z|x)$를 계산하는 것 대신 $q_\theta(z|x)$로 근사하는 방법이다. 즉, 변분 추론을 통해 모델의 역방향 과정의 확률 분포( $p(x_\text{t-1} | x_t)$ )를 근사하여, $p_\theta(x_\text{t-1} | x_t)$ 를 통하여 정방향 과정에서 추가된 노이즈를 제거하는 방법을 학습 DPMs은 정의하기 쉽고 학습이 효율적이지만, 지금까지 고품질 샘플을 생성할 수 있다는 실증적인 연구가 부족했다. 하지만 이 논문(DDPM)에서 DPMs이 고품질 샘플을 생성하고, 때때로 다른 모델보다 더 좋은 성능을 보인다. DDPM을 특정 방식으로 파라미터화 하면 다중 노이즈 수준에서 Denoising Score Matching과 동일하며, Annealed Langevin Dynamics와도 유사한 샘플링 방식을 갖는다는 점을 발견 한다. 46번에서 자세하게 설명을 한다. DDPM도 샘플의 품질은 뛰어나지만, log-likelihood 기반 모델들과 비교했을 때 경쟁력 있는 성능이 존재하진 않는다. Loss 중 많은 부분이 눈에 보이지 않는 미세한 이미지 세부 정보를 설명하는데 사용이 된다. log-likelihood model : VAE, Normalizing Flows, Autoregressive Models log 가능도를 최대화 하는 모델들 Background 4번에서 DPMs는 정방향 과정에서 추가된 노이즈(destroy)를 제거하는 방법을 학습하는 과정을 수행한다고 설명하였다. 물리학적으로 미세한 세계에서는 destroy된 상태를 backward로 복원시키는 것이 가능하다. DDPM에서는 노이즈를 점차 추가하여 destroy하는 정방향 과정을 diffusion process이라고 한다. 또한, 노이즈를 제거(denoising)하여 다시 복원하는 확률 분포(노이즈)를 학습하는 과정을 reverse process라고 한다. Diffusion Process Diffusion Process에 대해서 먼저 간단한 설명을 해보려고 한다. $$ q(x_\text{1:T} | x_0) := \prod_\text{t=1}^T q(x_t | x_\text{t-1}), \quad q(x_t | x_\text{t-1}) := \mathcal{N}(x_t ; \sqrt{1 - \beta_t} x_\text{t-1}, \beta_t I) $$
Diffusion Process의 근사 후행 확률은 $q(x_\text{1:T}|x_0)$ 으로 나타낼 수 있으며, 이는 마르코프 연쇄(Markov Chain)로 정의되어 이 과정에서 step마다 가우시안 노이즈를 추가하는 방식으로 작동한다. 이때 노이즈는 $\beta_1, &hellip; ,\beta_T$ 의 형태인 variance schedule에 따라 조절된다. $\beta_t$ 는 reparameterization trick에 의해서 학습이 될 수도 있고, 하이퍼파라미터로 고정될 수 있다. 다음은 $\beta_t$ 에 대하여 reparameterization trick을 적용한 것을 알아본 것이다.
$\beta_t$에 대하여 reparameterization trick을 적용 한 경우 $\beta_t$ 를 gaussian 분포에서 샘플링하는 확률적 변수로 설정한다면:
$\beta_t = \sigma(\tilde{\beta_t}),\qquad \tilde{\beta_t} \sim \mathcal{N}(\mu_\beta, \sigma_\beta^2) $
$\tilde{\beta_t}$ : 가우시안 분포에서 샘플링 된 값 $\sigma(\cdot)$ : activation function을 활용하여 $\beta_t$가 양수임을 보장 $\mu_\beta, \sigma_\beta $ : 학습 가능한 파라미터 위 식의 $\tilde{\beta_t}$ 을 gaussian 분포에서 직접 샘플링 하기 때문에 이는 확률적 연산이 포함되므로 미분이 불가능해진다.
미분이 불가능해지면 손실 함수의 그라디언트를 계산할 수 없게 된다. (학습 불가능) 그렇기 때문에 미분 가능해지기 위하여 $\beta_t$ 에 gaussian 분포에서 직접 샘플링하는 대신, 표준 정규 분포에서 샘플링한 후, 변형하는 방법인 reparametrization trick의 방법을 사용한다.
해당 방법을 사용하면 다음과 같이 표현 될 수 있다: $\tilde{\beta_t} = \mu_\beta &#43; \sigma_\beta \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, 1)$
이제 확률적 연산을 결정적 연산으로 변경하여 $\tilde{\beta_t}$ 를 샘플링하는 과정이 미분 가능해졌다."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://goodyoung.github.io/posts/paper/ddpm/" /><link rel="prev" href="https://goodyoung.github.io/posts/paper/dcgan/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/goodyoung.github.io\/posts\/paper\/ddpm\/"
        },"genre": "posts","keywords": "논문 리뷰, computer vision, Diffusion, DDPM, Implement","wordcount":  2183 ,
        "url": "https:\/\/goodyoung.github.io\/posts\/paper\/ddpm\/","datePublished": "2025-01-15T17:24:43+09:00","dateModified": "2025-01-15T17:24:43+09:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "GoodYoung"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Good Young">GoodYoung Dev Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Good Young">GoodYoung Dev Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://goodyoung.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>GoodYoung</a></span>&nbsp;<span class="post-category">included in <a href="/categories/paper-review/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Paper Review</a>&nbsp;<a href="/categories/dl/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>DL</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2025-01-15">2025-01-15</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;2183 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;11 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#background">Background</a>
      <ul>
        <li><a href="#diffusion-process">Diffusion Process</a></li>
        <li><a href="#reverse-process">Reverse Process</a></li>
        <li><a href="#object-function-loss">Object Function (Loss)</a></li>
      </ul>
    </li>
    <li><a href="#diffusion-models-and-denoising-autoencoders">Diffusion models and denoising autoencoders</a>
      <ul>
        <li><a href="#forward-process-and-l_t">Forward process and $L_T$</a></li>
        <li><a href="#reverse-process-and-l_text1t-1">Reverse process and $L_\text{1:T −1}$</a></li>
      </ul>
    </li>
    <li><a href="#experiment">Experiment</a></li>
    <li><a href="#implement">Implement</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- image format
<div style="text-align:center;">
<img src="/images/cs231n/lecture4/back-1.png" height="100%" width="80%"> </div>
 -->
<!--$
\begin{aligned}
수식1 \\\\ (한칸뛰기 -> \\\\)
&수식2 (&뒤가 정렬하고싶은 것)
\end{aligned}
$
-->
<h2 id="개요">개요</h2>
<ol start="0">
<li><code>Diffusion</code>의 기초인 <code>DDPM</code>에 대한 논문을 리뷰할 것이다.</li>
</ol>
<hr>
<h2 id="introduction">Introduction</h2>
<div style="text-align:center;">
<img src="/images/paper/ddpm/genmodels.png" height="100%" width="80%"> </div>
<ol>
<li>최근 몇 년간 <strong>다양한 생성 모델(deep generative models)</strong> 이 높은 품질의 샘플을 생성하는 성과를 보였다.</li>
</ol>
<br>
<ol start="2">
<li>에너지 기반 모델(Energy-Based Models) 및 Score Matching 기법도 <code>GAN</code>과 비슷한 수준의 이미지 품질을 생성하는 연구가 등장했다.</li>
</ol>
<br>
<ol start="3">
<li>이 논문은 <code>Diffusion Probabilistic Models</code>의 발전이다.</li>
</ol>
<ul>
<li><code>Diffusion Probabilistic Models (DPMs, 2015): </code> <strong>Markov chain</strong>을 기반으로 데이터를 <strong>점진적으로 샘플링하는 모델</strong></li>
</ul>
  <details>
      <summary> Markov Chain이란? </summary>
      - 어떤 시간에 특정 state에 도달하든, 그 이전에 어떤 state를 거쳐왔든
      다음 state로 갈 확률은 항상 같다는 성질이다.
  </details>
<br>
<ol start="4">
<li><code>DPMs</code>는 <strong>변분 추론을 활용해</strong> 샘플을 생성하기 위해 **확산 과정(diffusion process)을 반전(reverse)**시키는 방법을 학습한다.</li>
</ol>
<ul>
<li><code>변분 추론(variational inference) :</code> 확률 모델에서 복잡한 <code>후행 확률 분포(posterior distribution)</code>를 근사하는 방법 중 하나이다.
<ul>
<li>정확한 <code>posterior</code>를 계산하는 것은 <code>intractable</code>하여 $p(z|x)$를 계산하는 것 대신 $q_\theta(z|x)$로 근사하는 방법이다.</li>
</ul>
</li>
<li>즉, 변분 추론을 통해 <code>모델의 역방향 과정의 확률 분포</code>( $p(x_\text{t-1} | x_t)$ )를 근사하여, $p_\theta(x_\text{t-1} | x_t)$ 를 통하여 정방향 과정에서 <strong>추가된 노이즈를 제거하는 방법을 학습</strong></li>
</ul>
<br>
<ol start="5">
<li><code>DPMs</code>은 정의하기 쉽고 학습이 효율적이지만, 지금까지 고품질 샘플을 생성할 수 있다는 실증적인 연구가 부족했다.</li>
</ol>
<ul>
<li>하지만 이 논문(<code>DDPM</code>)에서 <code>DPMs</code>이 고품질 샘플을 생성하고, 때때로 다른 모델보다 더 좋은 성능을 보인다.</li>
</ul>
<br>
<ol start="6">
<li><code>DDPM</code>을 특정 방식으로 파라미터화 하면 다중 노이즈 수준에서 <code>Denoising Score Matching</code>과 동일하며, <code>Annealed Langevin Dynamics</code>와도 유사한 샘플링 방식을 갖는다는 점을 발견 한다.</li>
</ol>
<ul>
<li><code>46번</code>에서 자세하게 설명을 한다.</li>
</ul>
<br>
<ol start="7">
<li><code>DDPM</code>도 샘플의 품질은 뛰어나지만, <code>log-likelihood</code> 기반 모델들과 비교했을 때 경쟁력 있는 성능이 존재하진 않는다.</li>
</ol>
<ul>
<li><code>Loss</code> 중 많은 부분이 <strong>눈에 보이지 않는 미세한 이미지 세부 정보</strong>를 설명하는데 사용이 된다.</li>
<li><code>log-likelihood model :</code> <code>VAE</code>, <code>Normalizing Flows</code>, <code>Autoregressive Models</code>
<ul>
<li>log 가능도를 최대화 하는 모델들</li>
</ul>
</li>
</ul>
<hr>
<h2 id="background">Background</h2>
<div style="text-align:center;">
<img src="/images/paper/ddpm/process.png" height="100%" width="80%"> </div>
<ol start="8">
<li><code>4번</code>에서 <code>DPMs</code>는 정방향 과정에서 <strong>추가된 노이즈(destroy)를 제거하는 방법</strong>을 학습하는 과정을 수행한다고 설명하였다.</li>
</ol>
<ul>
<li>물리학적으로 미세한 세계에서는 destroy된 상태를 backward로 복원시키는 것이 가능하다.</li>
</ul>
<br>
<ol start="9">
<li><code>DDPM</code>에서는 <strong>노이즈를 점차 추가하여 destroy</strong>하는 정방향 과정을 <code>diffusion process</code>이라고 한다.</li>
</ol>
<br>
<ol start="10">
<li>또한, <code>노이즈를 제거(denoising)</code>하여 다시 복원하는 확률 분포(노이즈)를 학습하는 과정을 <code>reverse process</code>라고 한다.</li>
</ol>
<hr>
<h3 id="diffusion-process">Diffusion Process</h3>
<ol start="11">
<li><code>Diffusion Process</code>에 대해서 먼저 간단한 설명을 해보려고 한다.</li>
</ol>
<br>
<p>$$ q(x_\text{1:T} | x_0) := \prod_\text{t=1}^T q(x_t | x_\text{t-1}), \quad q(x_t | x_\text{t-1}) := \mathcal{N}(x_t ; \sqrt{1 - \beta_t} x_\text{t-1}, \beta_t I) $$</p>
<ol start="12">
<li><code>Diffusion Process</code>의 근사 후행 확률은 $q(x_\text{1:T}|x_0)$ 으로 나타낼 수 있으며,
이는 <code>마르코프 연쇄(Markov Chain)</code>로 정의되어 이 과정에서 step마다 <code>가우시안 노이즈</code>를 추가하는 방식으로 작동한다.</li>
</ol>
<br>
<ol start="13">
<li>이때 <code>노이즈</code>는 $\beta_1, &hellip; ,\beta_T$ 의 형태인 <code>variance schedule</code>에 따라 조절된다.</li>
</ol>
<br>
<ol start="14">
<li>$\beta_t$ 는 <code>reparameterization trick</code>에 의해서 학습이 될 수도 있고, 하이퍼파라미터로 고정될 수 있다.</li>
</ol>
<ul>
<li>
<p>다음은 $\beta_t$ 에 대하여 <code>reparameterization trick</code>을 적용한 것을 알아본 것이다.</p>
<details>
  <summary> $\beta_t$에 대하여 reparameterization trick을 적용 한 경우 </summary>
<ul>
<li>
<p>$\beta_t$ 를 <code>gaussian 분포</code>에서 <strong>샘플링하는 확률적 변수</strong>로 설정한다면:</p>
<p>$\beta_t  = \sigma(\tilde{\beta_t}),\qquad \tilde{\beta_t} \sim  \mathcal{N}(\mu_\beta, \sigma_\beta^2) $</p>
<ul>
<li>$\tilde{\beta_t}$ : 가우시안 분포에서 샘플링 된 값</li>
<li>$\sigma(\cdot)$ : activation function을 활용하여 $\beta_t$가 양수임을 보장</li>
<li>$\mu_\beta, \sigma_\beta $ : 학습 가능한 파라미터</li>
</ul>
</li>
<li>
<p>위 식의 $\tilde{\beta_t}$ 을 <code>gaussian 분포</code>에서 <strong>직접 샘플링</strong> 하기 때문에 이는 <strong>확률적 연산이 포함되므로 미분이 불가능해진다.</strong></p>
<ul>
<li>미분이 불가능해지면 손실 함수의 그라디언트를 <strong>계산할 수 없게 된다.</strong> (학습 불가능)</li>
</ul>
</li>
<li>
<p><strong>그렇기 때문에 미분 가능해지기 위하여</strong> $\beta_t$ 에 <code>gaussian 분포</code>에서 직접 샘플링하는 대신, <code>표준 정규 분포</code>에서 샘플링한 후, 변형하는 방법인 <code>reparametrization trick</code>의 방법을 사용한다.</p>
</li>
<li>
<p>해당 방법을 사용하면 다음과 같이 표현 될 수 있다: <br>
$\tilde{\beta_t} = \mu_\beta + \sigma_\beta \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, 1)$</p>
</li>
<li>
<p>이제 확률적 연산을 결정적 연산으로 변경하여 $\tilde{\beta_t}$ 를 샘플링하는 과정이 <strong>미분 가능해졌다.</strong></p>
</li>
<li>
<p>따라서 <code>경사 하강법(Gradient Descent)</code>을 사용하여 $ \mu_\beta $와 $ \sigma_\beta $ 를 학습할 수 있게 된다.</p>
</li>
</ul>
</details>
</li>
</ul>
<br>
<ol start="15">
<li>$\beta_t$ 가 매우 작을 때 <code>diffusion process</code> 와 <code>reverse process</code>에서 모두 <code>gaussian 분포</code>를 따르게 되어 <strong>동일한 수식 형태를 유지 할 수 있다.</strong></li>
</ol>
<ul>
<li><code>diffusion process</code>에서 결국 $\beta_T$ 시점에 가면 gaussian 분포랑 같게 형성이 된다.</li>
<li><code>reverse process</code>에서 <code>gaussian 분포</code>를 유지하며 근사가 가능해진다.
<ul>
<li>그렇게 되면 <code>reverse process</code>에서 <code>diffusion process</code>를 예측하기 쉬워지게 된다.</li>
</ul>
</li>
</ul>
<br>
<ol start="16">
<li>그리고 $\beta_t$ 를 <code>learnable parameter</code>로 둘 수 있지만, 실험을 해보니 <code>constant</code>로 두어도 <strong>큰 차이가 없어서</strong> <code>constant</code>로 두었다. (<code>Forward process and L_T ,Experiment</code> 부분)</li>
</ol>
<ul>
<li>
<p>초기의 $\beta_t$ 의 값을 작게 설정하다가 T가 증가할수록(<code>= gaussian distribution 에 가까워질수록</code>) 값을 크게 설정한다. (linear하게 증가)</p>
</li>
<li>
<p>본 논문에선 <code>constant</code>로 설정하여도 $x_T$ 시점에서 <code>pure isotropic gaussian</code>을 확보할 수 있다고 주장한다.</p>
<details>
  <summary> Pure Isotropic Gaussian이란? </summary>
<ul>
<li>평균 $\mu$ 가 0인 경우, 공분산 행렬이 $\sum = \sigma^2I$ 형태로 주어지며, 모든 차원의 분산이 동일하고 독립적인 경우이다.
<ul>
<li>등방성(방향성이 없음)이 유지가 된다.</li>
</ul>
</li>
<li>즉, 분포가 표준 가우시안 $\mathcal{N}(0,\mathcal{I})$ 형태를 가질 때를 나타낸다.</li>
</ul>
</details>
</li>
<li>
<p>이 때문에 <code>reverse process</code>를 시작할 때 <code>사전 분포(prior distribution)</code>이 $\mathcal{N}(0,\mathcal{I})$ 로 설정되어 <code>gaussian 분포</code>를 유지하게 된다.</p>
</li>
</ul>
<br>
<ol start="17">
<li>또한, $q(x_\text{1:T}|x_0)$ 을 위 식 그대로 $\beta_t$로 계산하게 되면 문제점이 있다.</li>
</ol>
<br>
<ol start="18">
<li>$x_0$(original image)에서 $x_T$(noisy image)로 전개될 때, 0~T의 모든 수식을 <code>step by step</code>으로 전개해야된다.</li>
</ol>
<ul>
<li>이는, <code>memory</code>를 많이 소모하며, 시간이 오래걸리는 <strong>단점</strong>이 있다.</li>
</ul>
<br>
<p>$$\alpha_t := 1 - \beta_t ,\quad \bar{\alpha_t} := \prod_\text{s=1}^{t} \alpha_s$$</p>
<p>$$q(x_t \mid x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) \mathbf{I})$$</p>
<ol start="19">
<li>그렇기 때문에 $q$ 의 식을 위와 같은 수식으로 변경하여 <code>폐쇄형 해(closed-form solution)</code>으로 샘플링 가능하기 때문에 임의의 시간 $t$ 에서 샘플링 $x_t$를 <strong>직접 계산할 수 있게 된다.</strong></li>
</ol>
<ul>
<li>
<p>이렇게 일반화 식을 만들면 <code>stochastic gradient descent</code>을 이용하여 효율적인 학습이 가능하다.</p>
<details>
  <summary> 폐쇄형 해(closed-form solution)이란? </summary>
<ul>
<li>어떤 수학적 문제의 해(해결 방법)를 유한한 개수의 기본 연산(+, -, ×, ÷, √, exp, log 등)으로 정확하게 표현할 수 있는 경우</li>
<li>수식을 직접 계산할 수 있는 형태</li>
</ul>
</details>
<details>
  <summary> 증명 확인 </summary>
$
\begin{aligned}
q(x_t \mid x_{t-1}) &= \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I) \text{이므로 reparametrization trick을 사용한다면} 
\end{aligned}
$
$$ 
\begin{aligned}
  x_t &= \sqrt{1 - \beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon_{t-1} \quad &(\epsilon_{t-1} \sim \mathcal{N}(0, I)) \\\\
  &= \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon_{t-1}  \\\\
  &= \sqrt{\alpha_t} (\sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2}) + \sqrt{1 - \alpha_t} \epsilon_{t-1} \quad &(\epsilon_{t-2} \sim \mathcal{N}(0, I)) \\\\
  &= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{(1 - \alpha_{t-1}) \alpha_t} \epsilon_{t-2} + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\\\
\end{aligned}
$$
$
\begin{aligned}
\alpha_t (1 - \alpha_{t-1}) + 1 - \alpha_t = 1 - \alpha_t \alpha_{t-1} \text{이므로} (1 - \alpha_t \alpha_{t-1}) I \text{이고 대입하면,}
\end{aligned}
$
$$ 
\begin{aligned}
  x_t &= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \epsilon_{\text{t-2}}^{\prime}, \quad &(\epsilon_{\text{t-2}}^{\prime} \sim \mathcal{N}(0, I)) \\\\
  &= \sqrt{\alpha_t \alpha_{t-1} \alpha_{t-2}} x_{t-3} + \sqrt{1 - \alpha_t \alpha_{t-1} \alpha_{t-2}} \epsilon_{\text{t-3}}^{\prime}, \quad &(\epsilon_{\text{t-3}}^{\prime} \sim \mathcal{N}(0, I)) \\\\
  &= \cdots \\\\
  &= \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon'_0, \quad &(\epsilon'_0 \sim \mathcal{N}(0, I))
\end{aligned}
$$
$
\begin{aligned}
\text{따라서,} \quad q(x_t \mid x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)이다.
\end{aligned}
$
</details>
</li>
</ul>
<br>
<ol start="20">
<li>결론적으로 <code>diffusion process</code>는 $x_0$을 조건부로 <code>latent variables</code> ($x_\text{1:T}$)를 생성해내는 과정이다.</li>
</ol>
<hr>
<h3 id="reverse-process">Reverse Process</h3>
<ol start="21">
<li>다음은 <code>Reverse Process</code>에 대한 설명이다.</li>
</ol>
<ul>
<li><code>Reverse process</code>는 <code>diffusion process</code>의 역과정으로, <code>gaussian noise</code>를 제거해가며 <strong>특정한 패턴을 만들어가는 과정</strong></li>
</ul>
<br>
<ol start="22">
<li><code>Reverse Process</code>는 <code>diffusion process</code>에서 만든 $x_T$(noise)를 다시 복원해야 하는데, 이때 $q(x_\text{t-1} \mid x_t)$를 바로 구할 수 없다.</li>
</ol>
<ul>
<li>그래서 <strong>모델 학습</strong>이 필요한 이유이다.</li>
</ul>
<br>
<ol start="23">
<li>따라서 $q$를 <code>approximation</code>하는 $p_\theta$ 를 $p_\theta(x_\text{t-1} | x_t) \sim q(x_\text{t-1} | x_t) $ 와같이 정의한다. 이를 식으로 표현하면 아래와 같다.</li>
</ol>
<p>$$
p_\theta(x_\text{0:T}) := p(x_T) \prod_{t=1}^{T} p_\theta(x_\text{t-1} \mid x_t), \quad
p_\theta(x_\text{t-1} \mid x_t) := \mathcal{N}(x_\text{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$</p>
<ol start="24">
<li>위 식의 $\mu_\theta(x_t, t)$ 와 $\Sigma_\theta$ 는 학습되어야 할 parameter들이고,
위 식의 시작 지점인 $x_T$의 분포는 $p(x_T) = \mathcal{N}(x_T;,0,I)$ 로 <code>표준정규분포</code>로 정의한다.</li>
</ol>
<hr>
<h3 id="object-function-loss">Object Function (Loss)</h3>
<ol start="25">
<li>이젠 $p_\theta$를 추정하기 위하여 <code>model의 학습 방법</code>을 알아보겠다.</li>
</ol>
<br>
<ol start="26">
<li><code>Model</code>의 목적은 <code>실제 data의 분포</code>인 $p_\theta(x_0)$을 찾아내는 것을 목적으로 하기 때문에 결국 이의 <code>likelihood</code>를 <strong>최대화 하는 것이 목적이다.</strong></li>
</ol>
<ul>
<li>$p_\theta(x_0)$ 를 직접 계산하기엔 어렵기 때문에, <code>변분 추론(variational inference)</code>을 사용하여 <code>diffusion process</code>를 이용한 <code>ELBO(Evidence Lower Bound)</code>를 유도한다.</li>
</ul>
<p>$$
\mathbb{E} \left[ - \log p_\theta(x_0) \right]
\leq \mathbb{E_q} \left[ - \log \frac{p_\theta(x_\text{0:T})} {q(x_\text{1:T} \mid x_0)} \right]
= \mathbb{E_q} \left[ - \log p(x_T) - \sum_{t \geq 1} \log \frac{p_\theta(x_\text{t-1} \mid x_t)}{q(x_t \mid x_\text{t-1})} \right]
=: L
$$</p>
  <details>
    <summary> 자세한 증명 보기 </summary>
  $$
  \begin{aligned}
  -\log p_\theta(x_0) &\leq -\log p_\theta(x_0) + D_\text{KL} \left( q(x_\text{1:T} | x_0) || p_\theta(x_\text{1:T} | x_0) \right) \\\\
  &= -\log p_\theta(x_0) + \mathbb{E_{x_\text{1:T} \sim q(x_\text{1:T} | x_0)}} \left[ \log \frac{q(x_\text{1:T} | x_0)}{p_\theta(x_\text{0:T}) / p_\theta(x_0)} \right] \text{($\log$의 분모가 $x_\text{0:T}$ 인 이유는 아직 모르겠다.)} \\\\
  &= -\log p_\theta(x_0) + \mathbb{E_{x_\text{1:T} \sim q(x_\text{1:T} | x_0)}} \left[ \log \frac{q(x_\text{1:T} | x_0)}{p_\theta(x_\text{0:T})} + \log p_\theta(x_0) \right] \\\\
  &= \mathbb{E_q} \left[ \log \frac{q(x_\text{1:T} | x_0)}{p_\theta(x_\text{0:T})} \right] \\\\
  &= \mathbb{E_q} \left[ -\log \frac{p_\theta(x_\text{0:T})}{q(x_\text{1:T} | x_0)} \right] \\\\
  \end{aligned}
  $$
<ul>
<li>2번째 식에서 $\log$ 의 분모식이 $x_\text{0:T}$ 인 이유를 추론해보자면 <code>ELBO</code>는 상한을 설정하는 것이다.</li>
<li>따라서, <strong>전체 확률 분포</strong> $p_\theta(x_\text{0:T})$를 기준으로 변분 추론을 전개하고 있다고 생각이 든다.</li>
</ul>
  </details>
<br>
<ol start="27">
<li>그렇기 때문에 이를 식으로 나타내면 <code>위의 식</code>과 같다.</li>
</ol>
<br>
<ol start="28">
<li><code>위의 식</code>을 좀 더 쉽게 계산하기 위해 아래와 같은 <code>Gaussian</code> 분포 간의 <code>KL divergence</code> 형태로 식을 변형한다.</li>
</ol>
<br>
<p>$$
\mathbb{E_q} \Bigg[
D_\text{KL} \left( q(x_T | x_0) || p(x_T) \right) + \sum_{t &gt; 1} D_\text{KL} \left( q(x_\text{t-1} | x_t, x_0) || p_\theta(x_\text{t-1} | x_t) \right)- \log p_\theta(x_0 | x_1)\Bigg]
$$</p>
<ul>
<li>왼쪽 항 부터 $L_T, L_\text{T-1},  L_0$ 이다.</li>
</ul>
  <details>
    <summary> 자세한 증명 보기 </summary>
  <div style="text-align:center;">
  <img src="/images/paper/ddpm/proof-1.png" height="100%" width="80%"> </div>
  </details>
<br>
<ol start="29">
<li>위 식에서 <code>각각의 term</code>이 가지는 의미를 하나씩 살펴보면 다음과 같다.</li>
</ol>
<br>
<ol start="30">
<li>$L_T$(regularization) : $p$ (diffusion process)가 <code>generate</code>하는 $noise(x_T)$와 $q$가 $x_0$ 라는 데이터가 주어졌을 때 <code>generate</code>하는 $noise(x_T)$ 간의 분포 차이이다.</li>
</ol>
<br>
<ol start="31">
<li>$L_\text{T-1}$(denoising process) : $p$와 $q$의 <code>reverse</code> / <code>forward process</code>의 분포 차이이다. <strong>이들을 최대한 비슷한 방향으로 학습한다.</strong></li>
</ol>
<ul>
<li>즉, $p$라는 <code>조건부 gaussian 분포</code>는 $q$라는 <code>조건부 gaussian 분포</code>를 <code>approximation</code>하도록 <strong>학습이 된다는 것을 알 수 있다.</strong></li>
</ul>
<br>
<ol start="32">
<li>$L_0$(reconstruction) : latent $x_1$으로부터 data $x_0$를 추정하는 likelihood. <strong>이를 maximize하는 방향으로 학습한다.</strong></li>
</ol>
<ul>
<li><code>negative log likelihood</code> 이므로 <code>maximize</code>하는 방향으로 학습이 된다.</li>
</ul>
<br>
<ol start="33">
<li>각 term들의 자세한 내용은 <code>Diffusion models and denoising autoencoders</code>에서 다루겠다.</li>
</ol>
<br>
<ol start="34">
<li>마지막으로 $q(x_\text{t-1} | x_t)$ 는 계산하기 어렵지만 $q(x_\text{t-1} | x_t,x_0)$는 쉽게 계산을 할 수 있게 된다. 해당 식과 자세한 증명은 아래에 있다.</li>
</ol>
<ul>
<li>$x_t$에서 $x_\text{t-1}$을 바로 구하는 것은 어렵지만 $x_0$을 <strong>조건으로 주면 쉽게 구할 수 있다.</strong></li>
</ul>
<br>
<p>$$
q(x_{t-1} | x_t, x_0) = \mathcal{N} \left( x_{t-1} ; \tilde{\mu}_t(x_t, x_0), \tilde{\beta}_t I \right),
$$</p>
<p>$$\text{where} \quad \tilde{\mu_t} (x_t, x_0) := \frac{\sqrt{\bar{\alpha_\text{t-1}}} \beta_t}{1 - \bar{\alpha_t}}
x_0 + \frac{\sqrt{\alpha_t} (1 - \bar{\alpha_{t-1}})}{1 - \bar{\alpha_t}} x_t\quad \text{and} \quad\tilde{\beta_t}
:= \frac{1 - \bar{\alpha_{t-1}}}{1 - \bar{\alpha_t}} \beta_t
$$</p>
  <details>
    <summary> 자세한 증명 보기 </summary>
  <div style="text-align:center;">
  <img src="/images/paper/ddpm/proof-2.png" height="100%" width="80%"> </div>
  </details>
<hr>
<h2 id="diffusion-models-and-denoising-autoencoders">Diffusion models and denoising autoencoders</h2>
<ol start="35">
<li><code>Diffusion model</code>의 설계 시 foward process, $\beta_t$, model 구조 등의 선택에 따라 달라지는 복잡한 모델이다.</li>
</ol>
<br>
<ol start="36">
<li>해당 챕터에서는 이를 <strong>단순화 하기 위한 방법</strong>을 설명을 한다.</li>
</ol>
<hr>
<h3 id="forward-process-and-l_t">Forward process and $L_T$</h3>
<ol start="37">
<li><code>16번</code>에서 설명했듯이 $\beta_t$를 <code>learnable parameter</code>로 두는 것이 아니라, <code>constant</code>로 고정한다.</li>
</ol>
<br>
<ol start="38">
<li>따라서, <code>28번</code>에서 설명한 최종 <code>Loss term</code> 중 $L_T$의 식에서 posterior $q$는 <strong>학습이 되는 파라미터가 존재하지 않는다.</strong></li>
</ol>
<ul>
<li>그래서 학습 중에 <strong>무시할 수 있게 된다.</strong></li>
</ul>
<hr>
<h3 id="reverse-process-and-l_text1t-1">Reverse process and $L_\text{1:T −1}$</h3>
<ol start="39">
<li><code>23번</code>의 <code>reverse process</code>의 식 $p_\theta(x_\text{t-1} \mid x_t) := \mathcal{N}(x_\text{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$ 에서
$\mu_\theta(x_t, t)$ 와 $\Sigma_\theta$ 는 학습되어야 할 <code>parameter들</code>이라고 설명한 바가 있다.</li>
</ol>
<ul>
<li>$\mu_\theta(x_t, t)$는 평균, 즉 모델이 예측하는 깨끗한 데이터 $x_\text{t-1}$​ 의 값</li>
<li>$\Sigma_\theta$ 는 분산, 즉 모델이 예측한 값의 불확실성</li>
</ul>
<br>
<ol start="40">
<li>주입된 <code>noise 크기</code>인 $\beta_t$를 이미 알고있기 때문에 이를 활용하여 분산($\Sigma_\theta$)을 <strong>대신 한다.</strong> <code>학습 대상이었던 분산</code>을 각 시점에서 <strong>누적된 노이즈 크기로 상수화</strong> 하게 된다.</li>
</ol>
<ul>
<li>
<p>논문에서는 $\sigma^2 = \beta_t$ 와 $\sigma^2 = \tilde\beta_t$ 의 실험 결과가 비슷하다고 설명한다.</p>
<details>
  <summary> 두개의 차이점 </summary>
<ul>
<li>$\sigma^2 = \beta_t$ : 단순히 정방향 과정에서 사용된 $\beta_t$ 값을 그대로 <code>reverse process</code>에서 사용하겠다는 방법이다.</li>
<li>$\sigma^2 = \tilde\beta_t$ : 정방향 과정에서 <code>누적된 노이즈</code>도 반영하겠다는 방법이다.</li>
<li><code>Diffusion model</code>은 <code>다중 스텝</code>을 거치므로 <code>개별 스텝</code>의 미세한 차이는 결과에 큰 영향을 미치지 못하기 때문에 결과가 비슷하다.
<ul>
<li>즉, <strong>스텝별 미세한 분산 차이가 최종적으로 누적될 때 무시할 수 있을 정도로 작을 수 있다.</strong></li>
</ul>
</li>
</ul>
</details>
</li>
</ul>
<br>
<ol start="41">
<li>따라서 $\Sigma_\theta(x_t, t) = \sigma_t^2 = \tilde\beta_t = t$시점까지의 누적된 $noise$ 가 된다.</li>
</ol>
<ul>
<li>$\tilde{\beta_t} := \frac{1 - \bar{\alpha_{t-1}}}{1 - \bar{\alpha_t}} \beta_t$</li>
<li>평균 $\mu_\theta(x_t, t)$ 만이 학습되어야 할 <code>parameter</code>이다.</li>
</ul>
<br>
<div style="text-align:center;">
<img src="/images/paper/ddpm/reverse-1.png" height="100%" width="80%"> </div>
<ol start="42">
<li>그렇기 때문에 <code>위 그림</code> 처럼 <code>denoising process</code> loss term($L_\text{t-1}$)의 <strong>목적식을 재구성</strong> 할 수 있게 된다.</li>
</ol>
<ul>
<li><strong>평균만이</strong> 학습대상이므로, 각각의 <code>mean function</code>간의 차이로 <strong>재정의 할 수 있게 된다.</strong></li>
</ul>
<br>
<p>$$
x_t(x_0, \epsilon) = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
$$</p>
<ol start="43">
<li><code>19번</code>의 식을 <code>reparametrization trick</code>을 사용하여 표현하면 <code>위 식</code>이 된다. 이 식을 <code>위 그림</code>에 <strong>대입 하면</strong> <code>아래의 수식</code>으로 정리가 된다.</li>
</ol>
<br>
<p>$$\mathbb{E_{x_0, \epsilon}} \Bigg[ \frac{1}{2 \sigma_t^2} \Big|\Big|  \frac{1}{\sqrt{\alpha_t}} \Big( x_t(x_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon \Big) - \mu _ {\theta} \Big( x_t(x_0, \epsilon), t \Big) \Big|\Big|^2 \Bigg] $$</p>
<ol start="44">
<li><code>위 수식</code>을 보면 $\mu _ {\theta} (x_t, t)$ 는 주어진 $t$시점에 $\frac{1}{\sqrt{\alpha_t}} ( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon)$의 <strong>식을 예측을 해야되는 것을 알 수 있다.</strong></li>
</ol>
<br>
<ol start="45">
<li>$x_t$(input) 와 $t$는 주어진다. 따라서 <code>남은 예측 대상(변수)은</code> noise($\epsilon$) 뿐이다.</li>
</ol>
<ul>
<li>$\epsilon$을 제외한 나머지 변수는 구할 수 있는 값들이다.</li>
</ul>
<br>
<ol start="46">
<li>또한 이는 $p$분포의 평균($\mu _ {\theta}$)이 $q$분포의 평균($\frac{1}{\sqrt{\alpha_t}}$)을 <strong>예측하는 것으로 생각할 수 있다.</strong></li>
</ol>
<br>
<ol start="46">
<li>다르게 생각한다면, <code>p분포</code>를 <code>q분포</code>를 기반으로 <code>parameterization</code>해서 얻을 수 있다면 더욱 간단할 것이다. 아래는 그렇게 변형한 수식이다.</li>
</ol>
<ul>
<li><code>6번</code>에 대한 설명
<ul>
<li>이 부분이 <code>denoising matching</code>의 <strong>핵심이다.</strong></li>
</ul>
</li>
</ul>
<br>
<p>$$
\mu_{\theta}(x_t, t) = \tilde{\mu_t} \left( x_t, \frac{1}{\sqrt{\bar{\alpha_t}}} \left( x_t - \sqrt{1 - \bar{\alpha_t}} \epsilon _ {\theta}(x_t) \right) \right) = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha_t}}} \epsilon_{\theta}(x_t, t) \right)
$$</p>
<ul>
<li>위 식을 이용하면 $x_\text{t-1}$을 바로 계산하는 것이 아니라 noise($\epsilon$)을 예측하여 $x_t$에서 빼는 방식을 취한다.</li>
</ul>
<ol start="47">
<li>최종적으로 <code>44번 위 수식</code>과 <code>위 수식</code>을 조합한다면 <strong>DDPM의 최종 Loss Term이 도출 된다.</strong></li>
</ol>
<ul>
<li><code>본 논문</code>에선 <code>계수 term</code>을 제외한 식의 <code>Loss</code>를 사용한다.</li>
<li><code>Loss</code>가 굉장히 간단한 식으로 정의된다.
<ul>
<li><strong>Noise를 예측하는 방식의 훈련이 진행되도록 설계가 되었다.</strong></li>
</ul>
</li>
</ul>
<br>
<p>$$
\text{Loss} _ {\text{DDPM}} = \mathbb{E_{x_0, \epsilon}} \Bigg[ \frac{\beta_t^2}{2 \sigma_t^2 \alpha_t (1 - \bar{\alpha}_t)} \Bigg| \epsilon - \epsilon _ {\theta} \big( \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t \big) \Bigg|^2
\Bigg]
$$</p>
<p>$$
= \mathbb{E_{x_0, \epsilon}} \Bigg[ \Big( \epsilon - \epsilon _ {\theta} \big( \sqrt{\bar{\alpha}_t} + \sqrt{1 - \bar{\alpha}_t} \epsilon, t \big) \Big)^2 \Bigg]
$$</p>
<hr>
<h2 id="experiment">Experiment</h2>
<div style="text-align:center;">
<img src="/images/paper/ddpm/result-1.png" height="70%" width="50%"> </div>
<ol start="48">
<li>평균을 예측하는 것이 아니라, <strong>noise를 예측하는게 결과가 더 좋게 나온다.</strong></li>
</ol>
<br>
<ol start="49">
<li>또한 <code>마지막 Loss</code>에서 <code>계수 term</code>을 <strong>제거한 것</strong>이 더욱 결과가 좋게 나온다고 나온다.</li>
</ol>
<br>
<ol start="50">
<li>왜냐하면 <code>계수 term</code>에서 $t$가 증가할 수록 <strong>분모가 더 빠르게 증가하기 때문에</strong>, $t$가 <strong>증가할수록 그 값이 작아지는 경향을 갖게 된다.</strong></li>
</ol>
<ul>
<li><code>계수 term</code>은 Loss에서 <strong>가중치 역할</strong>을 하게 된다.</li>
<li><strong>항이 크면 손실이 더 강조, 작으면 덜 강조가 된다.</strong></li>
</ul>
<br>
<ol start="51">
<li>따라서 <code>계수 term</code>이 있으면 $T$(large t)시점에선 줄어들기 때문에 결론적으로 <code>Loss의 영향</code>이 줄어들게 된다.</li>
</ol>
<br>
<ol start="52">
<li>그렇기 때문에 <code>계수 term</code>을 제외한 학습의 결과가 더 좋게 나온다.</li>
</ol>
<ul>
<li>$T$(large t)의 <strong>Loss 비중을 높여</strong>, 모델이 <code>noise가 심한 이미지</code>(large t시점의 상태)의 <code>denoising</code>에 집중하도록 유도가 된다.</li>
</ul>
<hr>
<h2 id="implement">Implement</h2>
<ol start="53">
<li>코드에 대한 구현은 <a href="https://github.com/goodyoung/myMLstudy/blob/main/DL%20Implement/Diffusion/DDPM/study_ddpm.ipynb" target="_blank" rel="noopener noreffer ">여기</a>에 해두었다.</li>
</ol>
<br>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li>
<p>전체 흐름</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=ybvJbvllgJk" target="_blank" rel="noopener noreffer ">https://www.youtube.com/watch?v=ybvJbvllgJk</a></li>
<li><a href="https://www.youtube.com/watch?v=LAYDUobuCko" target="_blank" rel="noopener noreffer ">https://www.youtube.com/watch?v=LAYDUobuCko</a></li>
</ul>
</li>
<li>
<p>논문 이해 참고</p>
<ul>
<li><a href="https://developers-shack.tistory.com/9" target="_blank" rel="noopener noreffer ">https://developers-shack.tistory.com/9</a></li>
<li><a href="https://www.youtube.com/watch?v=_JQSMhqXw-4&amp;t=2s" target="_blank" rel="noopener noreffer ">https://www.youtube.com/watch?v=_JQSMhqXw-4&t=2s</a></li>
<li><a href="https://jang-inspiration.com/ddpm-1" target="_blank" rel="noopener noreffer ">https://jang-inspiration.com/ddpm-1</a></li>
<li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" target="_blank" rel="noopener noreffer ">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a></li>
<li><a href="https://kyujinpy.tistory.com/95" target="_blank" rel="noopener noreffer ">https://kyujinpy.tistory.com/95</a></li>
</ul>
</li>
<li>
<p>기타 지식</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=vy8q-WnHa9A" target="_blank" rel="noopener noreffer ">https://www.youtube.com/watch?v=vy8q-WnHa9A</a> (reparametrization trick)</li>
</ul>
</li>
<li>
<p>논문 구현</p>
<ul>
<li><a href="https://github.com/w86763777/pytorch-ddpm" target="_blank" rel="noopener noreffer ">https://github.com/w86763777/pytorch-ddpm</a></li>
<li><a href="https://github.com/CodingVillainKor/SimpleDeepLearning/blob/main/DDPM_notebook.ipynb" target="_blank" rel="noopener noreffer ">https://github.com/CodingVillainKor/SimpleDeepLearning/blob/main/DDPM_notebook.ipynb</a></li>
</ul>
</li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2025-01-15</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://goodyoung.github.io/posts/paper/ddpm/" data-title="[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)" data-hashtags="논문 리뷰,computer vision,Diffusion,DDPM,Implement"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://goodyoung.github.io/posts/paper/ddpm/" data-hashtag="논문 리뷰"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://goodyoung.github.io/posts/paper/ddpm/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://goodyoung.github.io/posts/paper/ddpm/" data-title="[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://goodyoung.github.io/posts/paper/ddpm/" data-title="[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://goodyoung.github.io/posts/paper/ddpm/" data-title="[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://goodyoung.github.io/posts/paper/ddpm/" data-title="[Paper Review]Denoising Diffusion Probabilistic Models(DDPM)" data-description=""><i class="fab fa-blogger fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/">논문 리뷰</a>,&nbsp;<a href="/tags/computer-vision/">computer vision</a>,&nbsp;<a href="/tags/diffusion/">Diffusion</a>,&nbsp;<a href="/tags/ddpm/">DDPM</a>,&nbsp;<a href="/tags/implement/">Implement</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/paper/dcgan/" class="prev" rel="prev" title="[Paper Review]Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks(DCGAN)"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[Paper Review]Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks(DCGAN)</a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
  
</footer>
</div>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"goodylung/blog-comment"}},"lightgallery":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-86432198-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body>
</html>
