<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[CS231n] 10. Recurrent Neural Networks - Good Young</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="[CS231n] 10. Recurrent Neural Networks" />
<meta property="og:description" content="개요 CS231n의 10강에 대한 내용을 정리 할 것이다. Recurrent Neural Networks 이번 강의에서는 Recurrent Neural Networks에 대해서 설명을 한다. 지금까지의 networks는 one-to-one의 구조를 띈 모델이지만 위 그림과 같이 여러 구조를 띌 수 있게 된다. 따라서 각 구조 별로 다양한 task로 활용할 수 있다. one-to-many image captioning many-to-one sentiment classification many-to-many machine translation videio classification on frame level $$h_t = f_W(h_\text{t-1},x_t)$$
다음은 RNN의 기본 수식이다. 이전 상태($h_\text{t-1}$, hidden state)와 입력 값($x_t$)을 계산하여 new state로 나오게 된다. 더 자세한 수식은 위 그림과 같다. 위의 수식을 기반으로 RNN의 Computational Graph로 표현을 하게 된다면 위 그림과 같다. 보면 각 스텝에서 다 같은 W를 사용하는 것을 확인할 수 있게 된다. 위 그림은 RNN에서 Many-to-Many일 때 Loss 계산 까지 표현되는 그림인데 각각의 time-step마다 local gradient를 계산하게 되고 그것이 합쳐진 L까지 가서 upstream gradient로 내려오게 된다. 다음은 Many-to-One일 때 인데 최종 output인 y가 summarize context를 모든 time-step에 따른 하나의 결과를 담고 있다. 다음은 One-to-Many인데 이것은 fix size 형태로 입력이 되고 variable size인 output을 출력하는 형태이다. 이러한 Many-to-One구조와 One-to-Many를 섞은 구조인 Seq2Seq구조도 있다. Encoder에서 다양한 크기의 input이 들어오고 그것의 전체를 요약하는 $h_t$가 있게 된다. Encoder에서 나온 vector를 Decoder로 넘겨 다양하게 출력을 할 수 있게 한다. 이때 입력, 출력의 크기를 조절하기 위하여 입력 토큰, 출력 토큰을 지정하여 모델이 처음과 끝을 알 수 있게 한다. 이 구조는 번역을 하는 task에서 사용할 수 있게 된다. (영어 -&gt; franch) 이제는 하나의 문자를 입력 받고 다음으로 올 문자를 예측하는 모델을 설명할 것이다. 문자를 모델에 입력하기 위하여 하나의 벡터로 넣기 위하여 embedding 작업을 거치는데 embedding 방법 중 one-hot-encoding의 방법을 사용하였다. 그 후 그것에 가중치 행렬($W_\text{xh}$)을 곱하여 hidden layer로 들어가고 또 그게 다시 output layer로 출력이 된다. 여기서 hello라는 결과를 보여야 하기 때문에 맨 처음에 e라는 출력값을 가진다. 하지만 이 경우 잘못 예측을 하여 o로 예측을 한 경우이다. 다음으로 e가 input으로 들어가고 새로운 hidden state를 만든다. 이러한 과정을 계속 거치면 이 모델은 이전의 문장들의 문맥을 참고하여 다음 문자가 무엇일지 예측을 할 수 있게 되는 것이다. 그렇다면 이 모델의 Test time에서는 어떻게 작동을 하고 있는지 보여준다. 이 모델을 잘 활용을 하기 위해서는 sampling이라는 샘플링 기법을 활용하는 것이다. 위 그림은 모델이 output layer를 거쳐 softmax를 취하여 확률 분포를 사용하여 sampling을 한 과정을 나타낸다. 해당 경우에 e는 뽑힐 확률이 굉장히 작았음에도 불구하고 운이 좋게 e가 샘플링 되었다. 또한 이 샘플링으로 나온 e를 다음 input으로 넣어주고 반복 과정을 거쳐 test를 하게 된다. 가장 높은 스코어를 선택하지 않고 샘플링을 하는 이유는 모델에서 다양성을 얻을 수 있게되기 때문이다. 항상 h를 첫 input으로 놓는다고 할 때, 확률분포로 샘플링을 하게 된다면 그럴듯한 다양한 문장들을 출력할 수 있어 이것이 출력의 다양성으로 이어진다. 다음은 RNN에서 역전파를 사용했을 때를 나타낸다. 각 스텝마다의 loss를 계산해서 최종적인 output을 나타내게 되는데 시퀀스가 너무 길게 되면 문제가 생길수도 있다고 한다. 길면 메모리 사용량도 많고 학습이 너무 느릴 것이다. data point의 모든 요소에 대한 기울기를 계산하는 것은 엄청난 비용을 초래한다. 따라서 이러한 문제를 해결하기 위하여 나온 방법은 truncated backpropagation이다. 입력이 너무 길다고 하더라도 train할 때 한 스텝을 일정 단위로 자르고 단계를 진행하기 때문에 위의 문제를 해결할 수 있다. 이전에 계산한 hidden state는 계속 유지하고 반복해야 한다. backpropagation은 현재 배치만큼만 진행해야 한다. Image Captioning 다음은 Image captioning에 관한 설명이다. Image captioning을 하기 위해선 CNN에 Image를 넣고 CNN의 result vector를 다시 RNN에 넣어서 caption에 사용 될 문자를 하나씩 생성해가는 방식이다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://goodyoung.github.io/posts/cs231n/lecture10/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-21T16:55:43+09:00" />
<meta property="article:modified_time" content="2024-08-21T16:55:43+09:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[CS231n] 10. Recurrent Neural Networks"/>
<meta name="twitter:description" content="개요 CS231n의 10강에 대한 내용을 정리 할 것이다. Recurrent Neural Networks 이번 강의에서는 Recurrent Neural Networks에 대해서 설명을 한다. 지금까지의 networks는 one-to-one의 구조를 띈 모델이지만 위 그림과 같이 여러 구조를 띌 수 있게 된다. 따라서 각 구조 별로 다양한 task로 활용할 수 있다. one-to-many image captioning many-to-one sentiment classification many-to-many machine translation videio classification on frame level $$h_t = f_W(h_\text{t-1},x_t)$$
다음은 RNN의 기본 수식이다. 이전 상태($h_\text{t-1}$, hidden state)와 입력 값($x_t$)을 계산하여 new state로 나오게 된다. 더 자세한 수식은 위 그림과 같다. 위의 수식을 기반으로 RNN의 Computational Graph로 표현을 하게 된다면 위 그림과 같다. 보면 각 스텝에서 다 같은 W를 사용하는 것을 확인할 수 있게 된다. 위 그림은 RNN에서 Many-to-Many일 때 Loss 계산 까지 표현되는 그림인데 각각의 time-step마다 local gradient를 계산하게 되고 그것이 합쳐진 L까지 가서 upstream gradient로 내려오게 된다. 다음은 Many-to-One일 때 인데 최종 output인 y가 summarize context를 모든 time-step에 따른 하나의 결과를 담고 있다. 다음은 One-to-Many인데 이것은 fix size 형태로 입력이 되고 variable size인 output을 출력하는 형태이다. 이러한 Many-to-One구조와 One-to-Many를 섞은 구조인 Seq2Seq구조도 있다. Encoder에서 다양한 크기의 input이 들어오고 그것의 전체를 요약하는 $h_t$가 있게 된다. Encoder에서 나온 vector를 Decoder로 넘겨 다양하게 출력을 할 수 있게 한다. 이때 입력, 출력의 크기를 조절하기 위하여 입력 토큰, 출력 토큰을 지정하여 모델이 처음과 끝을 알 수 있게 한다. 이 구조는 번역을 하는 task에서 사용할 수 있게 된다. (영어 -&gt; franch) 이제는 하나의 문자를 입력 받고 다음으로 올 문자를 예측하는 모델을 설명할 것이다. 문자를 모델에 입력하기 위하여 하나의 벡터로 넣기 위하여 embedding 작업을 거치는데 embedding 방법 중 one-hot-encoding의 방법을 사용하였다. 그 후 그것에 가중치 행렬($W_\text{xh}$)을 곱하여 hidden layer로 들어가고 또 그게 다시 output layer로 출력이 된다. 여기서 hello라는 결과를 보여야 하기 때문에 맨 처음에 e라는 출력값을 가진다. 하지만 이 경우 잘못 예측을 하여 o로 예측을 한 경우이다. 다음으로 e가 input으로 들어가고 새로운 hidden state를 만든다. 이러한 과정을 계속 거치면 이 모델은 이전의 문장들의 문맥을 참고하여 다음 문자가 무엇일지 예측을 할 수 있게 되는 것이다. 그렇다면 이 모델의 Test time에서는 어떻게 작동을 하고 있는지 보여준다. 이 모델을 잘 활용을 하기 위해서는 sampling이라는 샘플링 기법을 활용하는 것이다. 위 그림은 모델이 output layer를 거쳐 softmax를 취하여 확률 분포를 사용하여 sampling을 한 과정을 나타낸다. 해당 경우에 e는 뽑힐 확률이 굉장히 작았음에도 불구하고 운이 좋게 e가 샘플링 되었다. 또한 이 샘플링으로 나온 e를 다음 input으로 넣어주고 반복 과정을 거쳐 test를 하게 된다. 가장 높은 스코어를 선택하지 않고 샘플링을 하는 이유는 모델에서 다양성을 얻을 수 있게되기 때문이다. 항상 h를 첫 input으로 놓는다고 할 때, 확률분포로 샘플링을 하게 된다면 그럴듯한 다양한 문장들을 출력할 수 있어 이것이 출력의 다양성으로 이어진다. 다음은 RNN에서 역전파를 사용했을 때를 나타낸다. 각 스텝마다의 loss를 계산해서 최종적인 output을 나타내게 되는데 시퀀스가 너무 길게 되면 문제가 생길수도 있다고 한다. 길면 메모리 사용량도 많고 학습이 너무 느릴 것이다. data point의 모든 요소에 대한 기울기를 계산하는 것은 엄청난 비용을 초래한다. 따라서 이러한 문제를 해결하기 위하여 나온 방법은 truncated backpropagation이다. 입력이 너무 길다고 하더라도 train할 때 한 스텝을 일정 단위로 자르고 단계를 진행하기 때문에 위의 문제를 해결할 수 있다. 이전에 계산한 hidden state는 계속 유지하고 반복해야 한다. backpropagation은 현재 배치만큼만 진행해야 한다. Image Captioning 다음은 Image captioning에 관한 설명이다. Image captioning을 하기 위해선 CNN에 Image를 넣고 CNN의 result vector를 다시 RNN에 넣어서 caption에 사용 될 문자를 하나씩 생성해가는 방식이다."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://goodyoung.github.io/posts/cs231n/lecture10/" /><link rel="prev" href="https://goodyoung.github.io/posts/paper/deit/" /><link rel="next" href="https://goodyoung.github.io/posts/paper/vae/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[CS231n] 10. Recurrent Neural Networks",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/goodyoung.github.io\/posts\/cs231n\/lecture10\/"
        },"genre": "posts","keywords": "LSTM, RNN, Neural Networks, CS231n","wordcount":  1053 ,
        "url": "https:\/\/goodyoung.github.io\/posts\/cs231n\/lecture10\/","datePublished": "2024-08-21T16:55:43+09:00","dateModified": "2024-08-21T16:55:43+09:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "GoodYoung"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Good Young">GoodYoung Dev Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Good Young">GoodYoung Dev Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[CS231n] 10. Recurrent Neural Networks</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://goodyoung.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>GoodYoung</a></span>&nbsp;<span class="post-category">included in <a href="/categories/dl/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>DL</a>&nbsp;<a href="/categories/theory/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Theory</a>&nbsp;<a href="/categories/lecture/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Lecture</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2024-08-21">2024-08-21</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;1053 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#recurrent-neural-networks">Recurrent Neural Networks</a></li>
    <li><a href="#image-captioning">Image Captioning</a></li>
    <li><a href="#image-captioning-with-attention">Image Captioning with Attention</a></li>
    <li><a href="#multilayer-rnns">MultiLayer RNNs</a></li>
    <li><a href="#lstm">LSTM</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- image format
<div style="text-align:center;">
<img src="/images/cs231n/lecture4/back-1.png" height="100%" width="80%"> </div>
 -->
<h2 id="개요">개요</h2>
<ol start="0">
<li><code>CS231n</code>의 10강에 대한 내용을 정리 할 것이다.</li>
</ol>
<hr>
<h2 id="recurrent-neural-networks">Recurrent Neural Networks</h2>
<ol>
<li>이번 강의에서는 <code>Recurrent Neural Networks</code>에 대해서 설명을 한다.</li>
</ol>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-network.png" height="100%" width="80%"> </div>
<ol start="2">
<li>지금까지의 networks는 <code>one-to-one</code>의 구조를 띈 모델이지만 위 그림과 같이 <strong>여러 구조를 띌 수 있게 된다.</strong></li>
</ol>
<br>
<ol start="3">
<li>따라서 각 구조 별로 다양한 <code>task로</code> 활용할 수 있다.</li>
</ol>
<ul>
<li><code>one-to-many</code>
<ul>
<li>image captioning</li>
</ul>
</li>
<li><code>many-to-one</code>
<ul>
<li>sentiment classification</li>
</ul>
</li>
<li><code>many-to-many</code>
<ul>
<li>machine translation</li>
<li>videio classification on frame level</li>
</ul>
</li>
</ul>
<p>$$h_t = f_W(h_\text{t-1},x_t)$$</p>
<ol start="4">
<li>다음은 <code>RNN</code>의 기본 수식이다. 이전 상태($h_\text{t-1}$, hidden state)와 입력 값($x_t$)을 계산하여 <code>new state</code>로 나오게 된다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-2.png" height="100%" width="80%"> </div>
<ol start="5">
<li>더 자세한 수식은 <code>위 그림</code>과 같다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-3.png" height="100%" width="80%"> </div>
<ol start="6">
<li>위의 수식을 기반으로 <code>RNN의</code> <code>Computational Graph</code>로 표현을 하게 된다면 <code>위 그림</code>과 같다.</li>
</ol>
<br>
<ol start="7">
<li>보면 <code>각 스텝</code>에서 다 같은 <code>W</code>를 사용하는 것을 확인할 수 있게 된다.</li>
</ol>
<br>
<ol start="8">
<li><code>위 그림</code>은 <code>RNN</code>에서 <code>Many-to-Many</code>일 때 <code>Loss</code> 계산 까지 표현되는 그림인데 각각의 time-step마다 <code>local gradient</code>를 계산하게 되고 그것이 합쳐진 <code>L</code>까지 가서 <code>upstream gradient</code>로 내려오게 된다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-4.png" height="100%" width="80%"> </div>
<ol start="9">
<li>다음은 <code>Many-to-One</code>일 때 인데 최종 output인 y가 <code>summarize context</code>를 모든 <code>time-step</code>에 따른 하나의 결과를 담고 있다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-5.png" height="100%" width="80%"> </div>
<ol start="10">
<li>다음은 <code>One-to-Many</code>인데 이것은 <code>fix size</code> 형태로 입력이 되고 <code>variable size</code>인 <code>output</code>을 출력하는 형태이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-6.png" height="100%" width="80%"> </div>
<ol start="11">
<li>이러한 <code>Many-to-One</code>구조와 <code>One-to-Many</code>를 섞은 구조인 <code>Seq2Seq</code>구조도 있다.</li>
</ol>
<br>
<ol start="12">
<li><code>Encoder</code>에서 다양한 크기의 input이 들어오고 그것의 전체를 요약하는 $h_t$가 있게 된다.</li>
</ol>
<br>
<ol start="13">
<li><code>Encoder</code>에서 나온 vector를 <code>Decoder</code>로 넘겨 다양하게 출력을 할 수 있게 한다.</li>
</ol>
<ul>
<li>이때 입력, 출력의 크기를 조절하기 위하여 <code>입력 토큰</code>, <code>출력 토큰</code>을 지정하여 모델이 처음과 끝을 알 수 있게 한다.</li>
<li>이 구조는 번역을 하는 task에서 사용할 수 있게 된다. (영어 -&gt; franch)</li>
</ul>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-7.png" height="100%" width="80%"> </div>
<ol start="14">
<li>이제는 <strong>하나의 문자를 입력 받고 다음으로 올 문자를 예측하는 모델</strong>을 설명할 것이다.</li>
</ol>
<br>
<ol start="15">
<li>문자를 모델에 입력하기 위하여 하나의 벡터로 넣기 위하여 <code>embedding</code> 작업을 거치는데 <code>embedding</code> 방법 중 <code>one-hot-encoding</code>의 방법을 사용하였다.</li>
</ol>
<br>
<ol start="16">
<li>그 후 그것에 가중치 행렬($W_\text{xh}$)을 곱하여 <code>hidden layer</code>로 들어가고 또 그게 다시 <code>output layer</code>로 출력이 된다.</li>
</ol>
<br>
<ol start="17">
<li>여기서 <code>hello</code>라는 결과를 보여야 하기 때문에 맨 처음에 <code>e</code>라는 출력값을 가진다. 하지만 이 경우 잘못 예측을 하여 <code>o</code>로 예측을 한 경우이다.</li>
</ol>
<br>
<ol start="18">
<li>다음으로 <code>e</code>가 input으로 들어가고 새로운 <code>hidden state</code>를 만든다. 이러한 과정을 계속 거치면 이 모델은 이전의 문장들의 문맥을 참고하여 다음 문자가 무엇일지 예측을 할 수 있게 되는 것이다.</li>
</ol>
<br>
<ol start="19">
<li>그렇다면 이 모델의 <code>Test time</code>에서는 어떻게 작동을 하고 있는지 보여준다. 이 모델을 잘 활용을 하기 위해서는 <code>sampling</code>이라는 샘플링 기법을 활용하는 것이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-8.png" height="100%" width="80%"> </div>
<ol start="20">
<li><code>위 그림</code>은 모델이 <code>output layer</code>를 거쳐 <code>softmax</code>를 취하여 확률 분포를 사용하여 sampling을 한 과정을 나타낸다.</li>
</ol>
<ul>
<li>해당 경우에 e는 뽑힐 확률이 굉장히 작았음에도 불구하고 운이 좋게 e가 샘플링 되었다.</li>
</ul>
<br>
<ol start="21">
<li>또한 이 샘플링으로 나온 e를 다음 input으로 넣어주고 반복 과정을 거쳐 <code>test</code>를 하게 된다.</li>
</ol>
<br>
<ol start="22">
<li>가장 높은 스코어를 선택하지 않고 샘플링을 하는 이유는 모델에서 다양성을 얻을 수 있게되기 때문이다.</li>
</ol>
<ul>
<li>항상 h를 첫 input으로 놓는다고 할 때, 확률분포로 샘플링을 하게 된다면 그럴듯한 다양한 문장들을 출력할 수 있어 이것이 출력의 다양성으로 이어진다.</li>
</ul>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-back.png" height="100%" width="80%"> </div>
<ol start="23">
<li>다음은 <code>RNN</code>에서 역전파를 사용했을 때를 나타낸다. 각 스텝마다의 <code>loss</code>를 계산해서 최종적인 <code>output</code>을 나타내게 되는데 시퀀스가 너무 길게 되면 문제가 생길수도 있다고 한다.</li>
</ol>
<ul>
<li>길면 메모리 사용량도 많고 학습이 너무 느릴 것이다.</li>
<li><strong>data point의 모든 요소에 대한 기울기를 계산하는 것은 엄청난 비용을 초래한다.</strong></li>
</ul>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/rnn-trunback.png" height="100%" width="80%"> </div>
<ol start="24">
<li>따라서 이러한 문제를 해결하기 위하여 나온 방법은 <code>truncated backpropagation</code>이다.</li>
</ol>
<br>
<ol start="25">
<li>입력이 너무 길다고 하더라도 train할 때 <strong>한 스텝을 일정 단위로 자르고 단계를 진행</strong>하기 때문에 <code>위의 문제</code>를 해결할  수 있다.</li>
</ol>
<ul>
<li>이전에 계산한 <code>hidden state</code>는 계속 유지하고 반복해야 한다.</li>
<li><code>backpropagation</code>은 현재 배치만큼만 진행해야 한다.</li>
</ul>
<hr>
<h2 id="image-captioning">Image Captioning</h2>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/image-captioning.png" height="100%" width="80%"> </div>
<ol start="26">
<li>다음은 <code>Image captioning</code>에 관한 설명이다. <code>Image captioning</code>을 하기 위해선 <code>CNN</code>에 <code>Image</code>를 넣고 CNN의 <code>result vector</code>를 다시 <code>RNN</code>에 넣어서 <code>caption</code>에 사용 될 문자를 하나씩 생성해가는 방식이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/image-captioning-2.png" height="100%" width="80%"> </div>
<ol start="27">
<li><code>위 그림</code>을 보면 CNN에서 마지막 출력(<code>softmax</code>) 전에 값들을 RNN의 모델의 <code>input</code>으로 <code>&lt;start&gt; 토큰</code>과 함께 넣고 <strong>이미지 정보를 추가하기 위하여 세번째 가중치 행렬을 추가</strong>한다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/image-captioning-3.png" height="100%" width="80%"> </div>
<ol start="28">
<li>그 후 <code>sampling</code>을 통하여 <strong>output을 뽑고 그 단어를 다시 다음 스텝의 입력으로 넣는</strong> 과정을 <code>&lt;END&gt; 토큰</code>이 나올 때 까지 반복하게 된다.</li>
</ol>
<ul>
<li><code>Image captioning</code>은 <code>supervised learning</code>이기 때문에 <code>label</code>이 있어야 한다.</li>
</ul>
<hr>
<h2 id="image-captioning-with-attention">Image Captioning with Attention</h2>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/image-captioning-4.png" height="100%" width="80%"> </div>
<ol start="29">
<li><code>Image captioning</code>을 <code>attetion mechanism</code>과 함께 사용하는 예시를 설명할 것이다.</li>
</ol>
<br>
<ol start="30">
<li>Image를 <code>CNN</code>으로 먼저 <code>Feature map vector</code>를 뽑고 이 벡터는 각각의 벡터가 공간 정보를 가지고 있는 것이다.</li>
</ol>
<br>
<ol start="31">
<li>이 벡터를 사용해서 <code>RNN</code>을 활용을 하는데 $h_\text{0}$은 이미지의 위치에 대한 분포를 계산하고, 그것의 결과인 $a_\text{0}$이 다시 <code>feature map</code>과 계산을 하여 <strong>이미지에서 살펴보고자 하는 위치에 대한 분포</strong>를 나타내는 $z_1$ 도 함께 생성하게 된다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/image-captioning-5.png" height="100%" width="80%"> </div>
<ol start="32">
<li>이때 계산된 $z_1$은 다음 번 단계일 때 input으로 들어가고 그 후 <code>위 그림</code>과 같이 두개의 출력으로 나타내게 된다.</li>
</ol>
<ul>
<li>이것이 계속 끝날 때 까지 반복이 된다.</li>
</ul>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/image-captioning-6.png" height="100%" width="80%"> </div>
<ol start="33">
<li>따라서 위 그림은 모델이 <code>caption</code>을 만들기 위하여 <code>attention</code>하는 것을 시각화 하는 그림이다.</li>
</ol>
<br>
<ol start="34">
<li>따라서 모델이 caption을 만들기 위하여 실제로 의미 있는 부분을 집중하고 있는 것을 확인 할 수 있게 된다.</li>
</ol>
<br>
<ol start="35">
<li>이러한 방법으로 <code>Visual Question Answering Task</code>도 가능하다.</li>
</ol>
<hr>
<h2 id="multilayer-rnns">MultiLayer RNNs</h2>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/image-captioning-7.png" height="100%" width="80%"> </div>
<ol start="36">
<li>지금까지는 <code>hidden state</code>가 하나인 RNN을 배웠지만 <code>hidden state</code>가 여러개인 <code>multilayer rnn</code>도 가능하다는 슬라이드이다.</li>
</ol>
<br>
<ol start="37">
<li><code>RNN</code>을 한 번 돌리고 <code>hidden state</code>가 생기고 이것이 바로 <code>다른 RNN cell</code>의 <code>input</code>으로 들어가는 것을 확인 할 수 있게 된다.</li>
</ol>
<ul>
<li>모델이 깊어질수록 성능이 더 좋아진다.</li>
<li>보통 layer를 2~3개를 쌓는다.</li>
</ul>
<hr>
<h2 id="lstm">LSTM</h2>
<ol start="38">
<li>이러한 <code>RNN</code>에도 문제점이 있다. 바로 RNN의 <code>gradient update</code> 과정에서 발생하는 문제점이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/lstm-1.png" height="100%" width="80%"> </div>
<ol start="39">
<li><code>위 그림</code>은 <code>RNN</code>에서 <code>backward pass</code>일 때의 모습이다. 이때 $h_t$에 대한 미분 값을 얻게 되고 loss에 대한 $h_\text{t-1}$의 미분값을 계산을 하게 된다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/lstm-2.png" height="100%" width="80%"> </div>
<ol start="40">
<li><code>위 그림</code>은 해당 과정을 <code>여러 셀</code>일 때 나오게 되는 그림이다. 이때 보면 $h_0$의 <code>gradient</code>를 구하려고 하면 각 셀의 <strong>같은 값을 가지는</strong><code>W</code>가 개입하게 된다.</li>
</ol>
<br>
<ol start="41">
<li>이 때 계속 곱해지는 <code>W</code>의 값을 1보다 크면 결국 <code>exploding </code>될 것이고 1보다 작으면 <code>gradient</code>가 사라지는 <code>vanishing gradient</code>현상이 일어날 것이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/lstm-3.png" height="100%" width="80%"> </div>
<ol start="42">
<li>따라서 이러한 문제를 해결하기 위하여 <code>LSTM</code>이 나오게 되었다. <code>LSTM</code>은 한 셀에 두개의 hidden state를 가지고 있다. $c_t, h_t (cell state, hidden state)$</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/lstm-4.png" height="100%" width="80%"> </div>
<ol start="43">
<li><code>위 그림</code>은 LSTM의 구조를 나타낸다. <code>LSTM</code>은 각각 다른 4개의 <code>weight 행렬</code>에 <code>이전 상태</code>에서 온 <code>x</code>와 <code>h</code>를 합쳐 행렬 곱을 하여 4개의 gate로 output을 내게 된다.</li>
</ol>
<br>
<ol start="44">
<li><code>f gate</code>는 <strong>이전 스텝의 cell 정보를 얼마나 지울지에 대한 망각 게이트</strong> 이고 이것이 가능한 이유는 <strong>sigmoid를 activation으로 하기 때문에</strong> 0,1사이의 값으로 조절 할 수 있게 된다.</li>
</ol>
<br>
<ol start="45">
<li><code>i gate</code>는 input gate이고 $x_t$에 대한 가중치이고 <code>g gate</code>는 gate gate이고 <strong>input cell을 얼마나 포함</strong>시킬지 결정하는 가중치 행렬이다. 또한 <code>o gate</code>는 output gate로 <strong>cell을 얼마나 드러낼 것인지에 대한 가중치 행렬이다.</strong></li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/lstm-5.png" height="100%" width="80%"> </div>
<ol start="46">
<li>이런 <code>LSTM cell</code> 구조를 더욱 명확히 나타내기 위한 그림이다. 이전 <code>cell state</code>와 <code>hidden state</code>를 입력으로 받고 $h_\text{t-1}$와 $x_t$를 stack하여 가중치 행렬과 계산하고 각각 $c_t$와 $h_t$를 계산 하는 것을 확인 할 수 있다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture10/lstm-6.png" height="100%" width="80%"> </div>
<ol start="47">
<li>다음은 <code>LSTM cell의 gradient</code> 과정을 나타낸 것이다. <code>LSTM</code>은 역전파를 수행할 때 $c_t$에 대한 <strong>역전파만</strong> 수행하여 <strong>forget gate에 upstream gradient가 곱해지는 것을 확인</strong>이 된다.</li>
</ol>
<ul>
<li>왜냐하면 $c_\text{t-1} * fgate$ 이므로 <code>행렬 곱</code>이므로 <code>gradient update 입장</code>에서 봤을 때 $fgate$만 업데이트 시 사용이 된다.</li>
</ul>
<br>
<ol start="48">
<li>따라서 같은 <code>W</code>의 값이 계속 곱해지는 <code>vanilla rnn</code>과 달리 forget gate의 값이 스텝마다 달라지기 때문에 <strong>이러한 문제를 해결할 수 있게 되었다.</strong></li>
</ol>
<ul>
<li>그렇다고 <code>vanishing gradient</code>의 문제가 완전히 해결된 것은 아니지만 <code>vanilla rnn</code>보다는 심하지는 않다.
<ul>
<li>매 스텝마다 <code>f</code>의 값이 달라지기 때문이다.</li>
</ul>
</li>
<li>forget gate의 sigmoid 값으로 <strong>bias를 1에 가깝게 만들어주면</strong> <code>vanishing gradient</code>를 많이 약화시킬 수 있습니다.</li>
<li><strong>W 값이 곱해지지 않아되기 때문에 마치 고속도로 처럼 gradient를 위한 빠른 처리</strong></li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://inni-iii.tistory.com/15" target="_blank" rel="noopener noreffer ">https://inni-iii.tistory.com/15</a></li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2024-08-21</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://goodyoung.github.io/posts/cs231n/lecture10/" data-title="[CS231n] 10. Recurrent Neural Networks" data-hashtags="LSTM,RNN,Neural Networks,CS231n"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://goodyoung.github.io/posts/cs231n/lecture10/" data-hashtag="LSTM"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://goodyoung.github.io/posts/cs231n/lecture10/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://goodyoung.github.io/posts/cs231n/lecture10/" data-title="[CS231n] 10. Recurrent Neural Networks"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://goodyoung.github.io/posts/cs231n/lecture10/" data-title="[CS231n] 10. Recurrent Neural Networks"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://goodyoung.github.io/posts/cs231n/lecture10/" data-title="[CS231n] 10. Recurrent Neural Networks"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://goodyoung.github.io/posts/cs231n/lecture10/" data-title="[CS231n] 10. Recurrent Neural Networks" data-description=""><i class="fab fa-blogger fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/lstm/">LSTM</a>,&nbsp;<a href="/tags/rnn/">RNN</a>,&nbsp;<a href="/tags/neural-networks/">Neural Networks</a>,&nbsp;<a href="/tags/cs231n/">CS231n</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/paper/deit/" class="prev" rel="prev" title="[Paper Review]Training data-efficient image transformers &amp; distillation through attention(DeiT)"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[Paper Review]Training data-efficient image transformers & distillation through attention(DeiT)</a>
            <a href="/posts/paper/vae/" class="next" rel="next" title="[Paper Review]Auto-Encoding Variational Bayes(VAE)">[Paper Review]Auto-Encoding Variational Bayes(VAE)<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
  
</footer>
</div>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"goodylung/blog-comment"}},"lightgallery":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-86432198-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body>
</html>
