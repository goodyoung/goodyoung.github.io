<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[CS231n] 05.Convolutional Neural Networks - Good Young</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="[CS231n] 05.Convolutional Neural Networks" />
<meta property="og:description" content="개요 CS231n의 5강에 대한 내용을 정리 할 것이다. 저번 강에서는 W를 업데이트 하는 과정 Chain-Rule과 간단한 Neural Networks에 대해서 배웠는데 이번 강에서는 Convolutional Neural Networks에 대해서 배울 것이다. A bit of history 위 그림을 보면 Hubel &amp; Wiesel이 고양이 실험을 했는데 이때 시각 피질 안의 뉴런이 local receptive field를 가지게 된다는 것을 알게 되었다. 또한 이렇게 겹쳐지는 receptive field들이 전체 시야를 이루게 된다는 사실을 알게 되었다. 어떤 뉴런은 low level, 또 어떤 뉴런은 high level의 특징들을 포착하는 것의 조합으로 이루게 된다. 이러한 지식을 기반으로 image처리를 위해 98년에 Lenet, 2012년에 AlexNet이 등장하게 되었다. Convolutional Neural Networks 저번 시간에 node들이 linear하게 모두 연결되어 있는 층을 Fully Connected (FC)층이라고 한다. 또 이 FC층이 행렬의 내적 계산을 통한 아주 효율적인 계산을 할 수 있다고 배웠다. 따라서 위 그림을 보면 하나의 layer는 하나의 연산을 통해 계산을 하여 편의성을 더해주는 사실을 볼 수 있다. 하지만 이미지 처리를 할 땐 위의 FC층이 좋지 않다. 왜냐하면 이미지의 spatial(공간적)정보가 손실이 되기 때문이다. 이러한 문제점을 해결하기 위하여 Convolutional Neural Networks (CNN)이 등장하게 되었다. CNN에 대해 더 자세히 알아보면 위 그림과 같은 이미지가 있고 필터가 존재한다. 이 필터는 우리가 linear classification에서 배웠던 W의 역할을 한다. 이런 필터는 input image위를 아래와 같이 슬라이딩 하면서 요소별 곱을 하고 그것을 또 하나의 합으로 나타낸다.
위 그림에선 3 * 3의 크기의 filter가 5 * 5의 크기의 image 위를 슬라이딩 하고 있다. 이 filter에 중요한 사실이 있다. 바로 filter의 depth 크기는 input volume의 depth랑 항상 같다는 점이다. 왜냐하면 우리가 시각적으로 보기에 image위를 슬라이딩 하는 것 처럼 보이지만 실제로의 연산은 $w^Tx$에서 image에서 filter가 겹쳐지는 부분만큼 가져온 후 1차원으로 늘린 연산이다. 따라서 위 그림과 같이 5*5*3의 크기인 filter연산은 곧 75-1D의 내적 연산(1차원)을 수행하는 것으로 이해하면 될 것 같다. 이렇게 연산을 수행하기 때문에 input volume의 depth랑 filter depth랑 같아야 filter의 내적 연산을 수행할 수 있게 된다. 이렇게 filter가 슬라이딩을 하여 연산을 한 번 모두 하면 위 그림과 같이 하나의 activation map이 나온다. 만약 필터가 6개가 있다면 앞서 말한 내적 연산을 6번 수행하여 ouput의 depth가 6인 activation map이 나오게 된다. 각 필터는 input volume에서 특정 유형의 템플릿이나 개념을 찾는다. 6개의 각각 다른 가중치를 지닌 activation map으로 생각하면 된다. 이런 layer들을 연속적으로 쌓아나가면 그것이 convolution network가 된다. 이런 convolution network에서는 처음에 low-level(edge 등등)의 특징을 추출하고 점점 깊어지면 high-level의 복잡하고 추상적인 개념들이 나타나게 된다. 이 정보들을 FC층에 넣고 각 class 수의 확률 연산을 하게되면 분류가 이루어진다. 왜 FC층이 필요하며, 어떻게 분류가 이루어지는지 의문을 가졌다. high-level features는 넓은 reception field를 가지고 있다. (점점 깊어질 수록 이미지의 resolution이 줄어들기 때문) 이러한 복잡하고 풍부한 정보를 포함하고 있는 feature들을 linear하게 놓고 모든 정보를 연결(Fully connected)을 하여 각각의 class별 weight를 계산을 하게 되면 해당 이미지가 class별 확률(softmax)이 나오게 될 것이다. 따라서 CNN으로 feature를 추출하고 FC 층에서 분류하는 이유는 이러한 과정을 통해 각 클래스별 확률을 효과적으로 계산할 수 있기 때문입니다. 이러한 방법들은 앞서 history에서 말한 인간의 인식 능력에서의 시각피질과 유사한 특징을 보이는 것을 알 수 있다. 픽셀은 항상 일관된 순서를 가지며, 서로 인접한 픽셀끼리 영향을 준다. 만약 모든 근처의 픽셀이 빨간색이라면 해당 픽셀도 빨간색일 가능성이 높다. 이렇게 픽셀은 주변 픽셀 값과 비교하여 정보를 추측할 수 있습니다. 이런 특성을 locality라고 합니다. 따라서 위 그림과 같이 sub sampling과정을 통해 image의 resolution을 줄이고 local feature들에 대한 연산을 통해 global feature(high-level)로 나아가 weight 변수를 줄이고 변화에 무관한 invariance를 얻게 되는 것이다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://goodyoung.github.io/posts/cs231n/lecture5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-12T20:01:34+09:00" />
<meta property="article:modified_time" content="2024-07-12T20:01:34+09:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[CS231n] 05.Convolutional Neural Networks"/>
<meta name="twitter:description" content="개요 CS231n의 5강에 대한 내용을 정리 할 것이다. 저번 강에서는 W를 업데이트 하는 과정 Chain-Rule과 간단한 Neural Networks에 대해서 배웠는데 이번 강에서는 Convolutional Neural Networks에 대해서 배울 것이다. A bit of history 위 그림을 보면 Hubel &amp; Wiesel이 고양이 실험을 했는데 이때 시각 피질 안의 뉴런이 local receptive field를 가지게 된다는 것을 알게 되었다. 또한 이렇게 겹쳐지는 receptive field들이 전체 시야를 이루게 된다는 사실을 알게 되었다. 어떤 뉴런은 low level, 또 어떤 뉴런은 high level의 특징들을 포착하는 것의 조합으로 이루게 된다. 이러한 지식을 기반으로 image처리를 위해 98년에 Lenet, 2012년에 AlexNet이 등장하게 되었다. Convolutional Neural Networks 저번 시간에 node들이 linear하게 모두 연결되어 있는 층을 Fully Connected (FC)층이라고 한다. 또 이 FC층이 행렬의 내적 계산을 통한 아주 효율적인 계산을 할 수 있다고 배웠다. 따라서 위 그림을 보면 하나의 layer는 하나의 연산을 통해 계산을 하여 편의성을 더해주는 사실을 볼 수 있다. 하지만 이미지 처리를 할 땐 위의 FC층이 좋지 않다. 왜냐하면 이미지의 spatial(공간적)정보가 손실이 되기 때문이다. 이러한 문제점을 해결하기 위하여 Convolutional Neural Networks (CNN)이 등장하게 되었다. CNN에 대해 더 자세히 알아보면 위 그림과 같은 이미지가 있고 필터가 존재한다. 이 필터는 우리가 linear classification에서 배웠던 W의 역할을 한다. 이런 필터는 input image위를 아래와 같이 슬라이딩 하면서 요소별 곱을 하고 그것을 또 하나의 합으로 나타낸다.
위 그림에선 3 * 3의 크기의 filter가 5 * 5의 크기의 image 위를 슬라이딩 하고 있다. 이 filter에 중요한 사실이 있다. 바로 filter의 depth 크기는 input volume의 depth랑 항상 같다는 점이다. 왜냐하면 우리가 시각적으로 보기에 image위를 슬라이딩 하는 것 처럼 보이지만 실제로의 연산은 $w^Tx$에서 image에서 filter가 겹쳐지는 부분만큼 가져온 후 1차원으로 늘린 연산이다. 따라서 위 그림과 같이 5*5*3의 크기인 filter연산은 곧 75-1D의 내적 연산(1차원)을 수행하는 것으로 이해하면 될 것 같다. 이렇게 연산을 수행하기 때문에 input volume의 depth랑 filter depth랑 같아야 filter의 내적 연산을 수행할 수 있게 된다. 이렇게 filter가 슬라이딩을 하여 연산을 한 번 모두 하면 위 그림과 같이 하나의 activation map이 나온다. 만약 필터가 6개가 있다면 앞서 말한 내적 연산을 6번 수행하여 ouput의 depth가 6인 activation map이 나오게 된다. 각 필터는 input volume에서 특정 유형의 템플릿이나 개념을 찾는다. 6개의 각각 다른 가중치를 지닌 activation map으로 생각하면 된다. 이런 layer들을 연속적으로 쌓아나가면 그것이 convolution network가 된다. 이런 convolution network에서는 처음에 low-level(edge 등등)의 특징을 추출하고 점점 깊어지면 high-level의 복잡하고 추상적인 개념들이 나타나게 된다. 이 정보들을 FC층에 넣고 각 class 수의 확률 연산을 하게되면 분류가 이루어진다. 왜 FC층이 필요하며, 어떻게 분류가 이루어지는지 의문을 가졌다. high-level features는 넓은 reception field를 가지고 있다. (점점 깊어질 수록 이미지의 resolution이 줄어들기 때문) 이러한 복잡하고 풍부한 정보를 포함하고 있는 feature들을 linear하게 놓고 모든 정보를 연결(Fully connected)을 하여 각각의 class별 weight를 계산을 하게 되면 해당 이미지가 class별 확률(softmax)이 나오게 될 것이다. 따라서 CNN으로 feature를 추출하고 FC 층에서 분류하는 이유는 이러한 과정을 통해 각 클래스별 확률을 효과적으로 계산할 수 있기 때문입니다. 이러한 방법들은 앞서 history에서 말한 인간의 인식 능력에서의 시각피질과 유사한 특징을 보이는 것을 알 수 있다. 픽셀은 항상 일관된 순서를 가지며, 서로 인접한 픽셀끼리 영향을 준다. 만약 모든 근처의 픽셀이 빨간색이라면 해당 픽셀도 빨간색일 가능성이 높다. 이렇게 픽셀은 주변 픽셀 값과 비교하여 정보를 추측할 수 있습니다. 이런 특성을 locality라고 합니다. 따라서 위 그림과 같이 sub sampling과정을 통해 image의 resolution을 줄이고 local feature들에 대한 연산을 통해 global feature(high-level)로 나아가 weight 변수를 줄이고 변화에 무관한 invariance를 얻게 되는 것이다."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://goodyoung.github.io/posts/cs231n/lecture5/" /><link rel="prev" href="https://goodyoung.github.io/posts/paper/r-cnn/" /><link rel="next" href="https://goodyoung.github.io/posts/cs231n/lecture6/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[CS231n] 05.Convolutional Neural Networks",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/goodyoung.github.io\/posts\/cs231n\/lecture5\/"
        },"genre": "posts","keywords": "Chain Rule, Neural Networks, CS231n","wordcount":  668 ,
        "url": "https:\/\/goodyoung.github.io\/posts\/cs231n\/lecture5\/","datePublished": "2024-07-12T20:01:34+09:00","dateModified": "2024-07-12T20:01:34+09:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "GoodYoung"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Good Young">GoodYoung Dev Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Good Young">GoodYoung Dev Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[CS231n] 05.Convolutional Neural Networks</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://goodyoung.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>GoodYoung</a></span>&nbsp;<span class="post-category">included in <a href="/categories/dl/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>DL</a>&nbsp;<a href="/categories/theory/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Theory</a>&nbsp;<a href="/categories/lecture/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Lecture</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2024-07-12">2024-07-12</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;668 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;4 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#a-bit-of-history">A bit of history</a></li>
    <li><a href="#convolutional-neural-networks">Convolutional Neural Networks</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- image format
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/back-1.png" height="100%" width="80%"> </div>
 -->
<h2 id="개요">개요</h2>
<ol start="0">
<li><code>CS231n</code>의 5강에 대한 내용을 정리 할 것이다.</li>
</ol>
<br>
<ol>
<li>저번 강에서는 <code>W</code>를 업데이트 하는 과정 <code>Chain-Rule</code>과 간단한 <code>Neural Networks</code>에 대해서 배웠는데 이번 강에서는 <code>Convolutional Neural Networks</code>에 대해서 배울 것이다.</li>
</ol>
<hr>
<h2 id="a-bit-of-history">A bit of history</h2>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image.png" height="100%" width="80%"> </div>
<ol start="2">
<li><code>위 그림</code>을 보면 <code>Hubel &amp; Wiesel</code>이 고양이 실험을 했는데 이때 시각 피질 안의 뉴런이 <code>local receptive field</code>를 가지게 된다는 것을 알게 되었다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-2.png" height="100%" width="80%"> </div>
<ol start="3">
<li>또한 이렇게 겹쳐지는 receptive field들이 전체 시야를 이루게 된다는 사실을 알게 되었다.</li>
</ol>
<br>
<ol start="4">
<li>어떤 뉴런은 <code>low level</code>, 또 어떤 뉴런은 <code>high level</code>의 특징들을 포착하는 것의 조합으로 이루게 된다.</li>
</ol>
<br>
<ol start="5">
<li>이러한 지식을 기반으로 <code>image처리</code>를 위해 98년에 <code>Lenet</code>, 2012년에 <code>AlexNet</code>이 등장하게 되었다.</li>
</ol>
<hr>
<h2 id="convolutional-neural-networks">Convolutional Neural Networks</h2>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-3.png" height="100%" width="80%"> </div>
<ol start="6">
<li>저번 시간에 <code>node</code>들이 linear하게 모두 연결되어 있는 층을 <code>Fully Connected (FC)층</code>이라고 한다.</li>
</ol>
<ul>
<li>또 이 <code>FC층</code>이 행렬의 <code>내적 계산</code>을 통한 아주 효율적인 계산을 할 수 있다고 배웠다.</li>
</ul>
<br>
<ol start="7">
<li>따라서 <code>위 그림</code>을 보면 하나의 layer는 하나의 연산을 통해 계산을 하여 편의성을 더해주는 사실을 볼 수 있다.</li>
</ol>
<br>
<ol start="8">
<li>하지만 이미지 처리를 할 땐 위의 <strong>FC층이 좋지 않다</strong>. 왜냐하면 이미지의 <code>spatial(공간적)정보</code>가 손실이 되기 때문이다.</li>
</ol>
<br>
<ol start="9">
<li>이러한 문제점을 해결하기 위하여 <code>Convolutional Neural Networks (CNN)</code>이 등장하게 되었다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-4.png" height="100%" width="80%"> </div>
<ol start="10">
<li>CNN에 대해 더 자세히 알아보면 <code>위 그림</code>과 같은 이미지가 있고 필터가 존재한다. 이 필터는 우리가 linear classification에서 배웠던 <code>W</code>의 역할을 한다.</li>
</ol>
<br>
<ol start="11">
<li>
<p>이런 필터는 input image위를 아래와 같이 <code>슬라이딩</code> 하면서 요소별 곱을 하고 그것을 또 하나의 합으로 나타낸다.</p>
<img src="/images/cs231n/lecture5/filter.gif" height="100%" width="50%">
<ul>
<li><code>위 그림</code>에선 <em>3 * 3</em>의 크기의 filter가 <em>5 * 5</em>의 크기의 image 위를 <strong>슬라이딩 하고 있다.</strong></li>
</ul>
</li>
</ol>
<br>
<ol start="12">
<li>이 filter에 <code>중요한 사실</code>이 있다. <strong>바로 filter의 depth 크기는 input volume의 depth랑 항상 같다는 점이다.</strong></li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/filter-2.png" height="100%" width="70%"></div>
<ol start="13">
<li>왜냐하면 우리가 시각적으로 보기에 <strong>image위를 슬라이딩 하는 것 처럼 보이지만</strong> 실제로의 연산은 $w^Tx$에서 <strong>image에서 filter가 겹쳐지는 부분만큼 가져온 후 1차원으로 늘린 연산이다.</strong></li>
</ol>
<br>
<ol start="14">
<li>따라서 <code>위 그림</code>과 같이 <em>5*5*3</em>의 크기인 filter연산은 곧 <u><em>75-1D</em>의 내적 연산(1차원)을 수행하는 것으로 이해하면 될 것 같다.</u></li>
</ol>
<br>
<ol start="15">
<li>이렇게 연산을 수행하기 때문에 <strong>input volume의 depth랑 filter depth랑 같아야</strong> filter의 내적 연산을 수행할 수 있게 된다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-5.png" height="100%" width="70%"></div>
<ol start="16">
<li>이렇게 filter가 슬라이딩을 하여 연산을 한 번 모두 하면 <code>위 그림</code>과 같이 하나의 <code>activation map</code>이 나온다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-6.png" height="100%" width="70%"></div>
<ol start="17">
<li>만약 <strong>필터가 6개가 있다면</strong> 앞서 말한 <strong>내적 연산을 6번 수행</strong>하여 ouput의 depth가 6인 <code>activation map</code>이 나오게 된다.</li>
</ol>
<ul>
<li>각 필터는 input volume에서 <strong>특정 유형의 템플릿이나 개념을 찾는다.</strong></li>
<li>6개의 각각 다른 가중치를 지닌 <code>activation map</code>으로 생각하면 된다.</li>
</ul>
<br>
<ol start="18">
<li>이런 layer들을 <strong>연속적으로 쌓아나가면</strong> 그것이 <code>convolution network</code>가 된다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-7.png" height="100%" width="70%"></div>
<ol start="19">
<li>이런 convolution network에서는 처음에 <code>low-level(edge 등등)</code>의 특징을 추출하고 <strong>점점 깊어지면</strong> <code>high-level</code>의 복잡하고 추상적인 개념들이 나타나게 된다.</li>
</ol>
<br>
<ol start="20">
<li>이 정보들을 FC층에 넣고 각 class 수의 확률 연산을 하게되면 분류가 이루어진다.</li>
</ol>
<ul>
<li>왜 <code>FC층이</code> 필요하며, 어떻게 분류가 이루어지는지 의문을 가졌다.</li>
<li><code>high-level features</code>는 넓은 <code>reception field</code>를 가지고 있다. (점점 깊어질 수록 이미지의 <code>resolution이</code> 줄어들기 때문)</li>
<li>이러한 <strong>복잡하고 풍부한 정보를 포함하고 있는 feature</strong>들을 linear하게 놓고 <strong>모든 정보를 연결</strong>(Fully connected)을 하여 <strong>각각의 class별 weight</strong>를 계산을 하게 되면 해당 이미지가 class별 확률(softmax)이 나오게 될 것이다.</li>
<li>따라서 CNN으로 feature를 추출하고 <code>FC 층</code>에서 분류하는 이유는 이러한 과정을 통해 <strong>각 클래스별 확률을 효과적으로 계산</strong>할 수 있기 때문입니다.</li>
</ul>
<br>
<ol start="21">
<li>이러한 방법들은 앞서 <code>history</code>에서 말한 <strong>인간의 인식 능력에서의 시각피질과 유사한 특징</strong>을 보이는 것을 알 수 있다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-8.png" height="100%" width="70%"></div>
<ol start="22">
<li>픽셀은 항상 일관된 순서를 가지며, <strong>서로 인접한 픽셀끼리 영향을 준다</strong>.</li>
</ol>
<br>
<ol start="23">
<li>만약 모든 근처의 픽셀이 <code>빨간색이라면</code> 해당 픽셀도 <code>빨간색일 가능성</code>이 높다. 이렇게 픽셀은 <code>주변 픽셀 값과 비교하여 정보를 추측</code>할 수 있습니다. 이런 특성을 <code>locality</code>라고 합니다.</li>
</ol>
<br>
<ol start="24">
<li>따라서 <code>위 그림</code>과 같이 <code>sub sampling</code>과정을 통해 <strong>image의 resolution을 줄이고</strong> local feature들에 대한 연산을 통해 <code>global feature(high-level)</code>로 나아가 <code>weight 변수를 줄이고</code> 변화에 무관한 <code>invariance</code>를 얻게 되는 것이다.</li>
</ol>
<br>
<ol start="25">
<li><code>Convolution의 표준 정의</code>는 다음과 같다.
$$f[x, y] * g[x, y] = \sum_{n_1 = -\infty}^{\infty} \sum_{n_2 = -\infty}^{\infty} f[n_1, n_2] \cdot g[x - n_1, y - n_2]$$</li>
</ol>
<br>
<ol start="26">
<li>이제까지 대략적인 <code>Convolution</code>이 작동하는 방법에 대해 알아보았고 다음은 <code>filter</code>의 <code>Stride</code>에 관한 내용이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-9.png" height="100%" width="70%"></div>
<ol start="27">
<li><code>Stride</code>는 filter의 보폭, filter가 슬라이딩을 할 때 <strong>얼만큼 움직일지를</strong> 결정하는 것이다.</li>
</ol>
<br>
<ol start="28">
<li><code>filter</code>가 한 번의 연산을 거친 후 <code>output size</code>는 다음과 <code>같은 식</code>으로 구한다.</li>
</ol>
<br>
<ol start="29">
<li>하지만 이것만 활용하면 filter가 가장자리의 정보를 많이 얻기 쉽지 않다. 그래서 나온 개념이 <code>padding</code>이다.</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-10.png" height="100%" width="70%"></div>
<ol start="30">
<li><code>Padding</code>은 input에 0을 더하여 가장자리의 정보도 얻을 수 있게 한다.</li>
</ol>
<br>
<ol start="31">
<li>또한 <code>Padding</code>은 network가 깊어질 때  image의 <code>resolution를</code> 동일하게 유지시키려고도 많이 사용하게 된다.</li>
</ol>
<br>
<ol start="32">
<li>따라서 Padding까지 고려한 output size는 다음과 같다.
$$ (\frac{W+2P-F}{S}, \frac{H+2P-F}{S})$$</li>
</ol>
<br>
<div style="text-align:center;">
<img src="/images/cs231n/lecture5/image-11.png" height="100%" width="70%"></div>
<ol start="33">
<li>
<p>다음은 <code>pooling</code>에 관한 설명이다. <code>Pooling</code>은 이미지의 <code>resolution</code>을 줄이는 역할을 하게된다. 여기서 중요한 점은 오로지 resolution($(W,H)$)의 변화만 있지 <code>depth</code>에 변화는 없다.</p>
<img src="/images/cs231n/lecture5/maxpooling.png" height="100%" width="50%">
<ul>
<li>pooling에 방법에는 <strong>크게 두가지가</strong> 있는데 <code>average pooling</code>과 <code>max pooling</code>이 있다.</li>
<li><code>max pooling</code>의 연산은 <code>위 그림</code>과 같고 주로 <code>max pooling</code>을 사용한다.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://chasuyeon.tistory.com/entry/cs231n-5%EA%B0%95-%EC%A0%95%EB%A6%AC-Convolutional-Neural-Networks" target="_blank" rel="noopener noreffer ">https://chasuyeon.tistory.com/entry/cs231n-5%EA%B0%95-%EC%A0%95%EB%A6%AC-Convolutional-Neural-Networks</a></li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2024-07-12</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://goodyoung.github.io/posts/cs231n/lecture5/" data-title="[CS231n] 05.Convolutional Neural Networks" data-hashtags="Chain Rule,Neural Networks,CS231n"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://goodyoung.github.io/posts/cs231n/lecture5/" data-hashtag="Chain Rule"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://goodyoung.github.io/posts/cs231n/lecture5/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://goodyoung.github.io/posts/cs231n/lecture5/" data-title="[CS231n] 05.Convolutional Neural Networks"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://goodyoung.github.io/posts/cs231n/lecture5/" data-title="[CS231n] 05.Convolutional Neural Networks"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://goodyoung.github.io/posts/cs231n/lecture5/" data-title="[CS231n] 05.Convolutional Neural Networks"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://goodyoung.github.io/posts/cs231n/lecture5/" data-title="[CS231n] 05.Convolutional Neural Networks" data-description=""><i class="fab fa-blogger fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/chain-rule/">Chain Rule</a>,&nbsp;<a href="/tags/neural-networks/">Neural Networks</a>,&nbsp;<a href="/tags/cs231n/">CS231n</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/paper/r-cnn/" class="prev" rel="prev" title="[Paper Review]Rich feature hierarchies for accurate object detection and semantic segmentation"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[Paper Review]Rich feature hierarchies for accurate object detection and semantic segmentation</a>
            <a href="/posts/cs231n/lecture6/" class="next" rel="next" title="[CS231n] 06.Training Neural Networks">[CS231n] 06.Training Neural Networks<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
  
</footer>
</div>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"goodylung/blog-comment"}},"lightgallery":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-86432198-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body>
</html>
