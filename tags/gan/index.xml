<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>GAN - Tag - Good Young</title>
        <link>https://goodyoung.github.io/tags/gan/</link>
        <description>GAN - Tag - Good Young</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 27 Aug 2025 19:15:17 &#43;0900</lastBuildDate><atom:link href="https://goodyoung.github.io/tags/gan/" rel="self" type="application/rss+xml" /><item>
    <title>[CS236] 9. GANs - 1</title>
    <link>https://goodyoung.github.io/posts/cs236/lecture9/</link>
    <pubDate>Wed, 27 Aug 2025 19:15:17 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/cs236/lecture9/</guid>
    <description><![CDATA[개요 이번 포스트에서는 CS236 강의의 8강을 설명한다. 우리는 지금까지 여러 생성 모델들을 배웠다. AutoRegreesive Model, Variational Autoencoder, Normalizing Flow. 이들은 모두 실제 데이터 분포 $p_\text{data}$ 에 제일 가까운 $p_\theta$ 를 찾으려고 했다. 가장 가까운 $\theta$ 를 찾기 위하여 Maximum log-likelihood(MLE)를 학습 목표로 삼았다. 그렇다면, 높은 log-likelihood가 무조건 좋은 품질의 생성을 의미할까? 아니다. likelihood가 낮더라도 sampling의 품질은 꽤 좋을 수 있다. 그래서 이번 lecture에서는 MLE에 기반하지 않는 다양한 종류의 훈련 목적 함수를 알아볼 것이다. 높은 likelihood -&gt; 나쁜 품질은 어떻게 하면 될까? 자세한 내용은 아래 toggle을 확인하면 된다.
높은 likelihood -> 나쁜 품질 예시 아래의 슬라이드를 보면, 99퍼센트의 noise를 추출하는 $p_\theta$ 이지만 높은 차원으로 갈 수록이 모델은 실제 $p_\text{data}$ 를 나타내는 예시를 볼 수 있다. 그렇게 되면 이 모델은 MLE는 매우 좋을 것이며, 샘플의 품질은 매우 나쁠 것이다. 그렇다면 낮은 likelihood -&gt; 좋은 품질은 어떻게 하면 될까? 그 방법은 모델을 overfitting을 하면 된다.
결론적으로 기존과 달리, 우리는 위 그림의 $d(p_\text{data}||p_\theta)$ 의 다른 대안을 알아볼 것이다. Two-Sample Test 그렇다면 어떤 다른 방법이 있을까. 바로 두 개의 분포에서 생성한 결과를 가지고 그 생성한 결과가 서로 같다면 귀무가설(두 분포가 같다)을 받아드리고, 다르다면 기각하는 방식으로 MLE 없이 두 개의 분포 유사도를 측정할 수 있는 Two-Sample Test 방식이 있다. 두 분포가 같음을 측정할 때 만약 두 분포의 평균만 사용한다면, 우리는 분포의 확률조차도 구할 필요가 없는 것이다.
하지만, 통계적으로 고차원의 데이터에서 단지 평균만으로 측정한다면, 올바른 측정이 어렵다. 위와 같이 생각해야할 것들이 많기 때문이다. (단지, 평균만 같아도 두 분포가 같다고 할 수 없는 것(왼쪽 첫번째 그림) 처럼)
그렇다면 자동적으로 이 두 분포의 차이를 어떻게 알까? 방법은 분류기를 학습하는 것이다. (GAN에서 Discriminator 역할) 본질적으로는, 우리가 딥러닝 분류기의 역할은 두(여러) 그룹의 샘플을 구별하고 구분할 수 있는 특징을 자동적으로 분류하는 것이다. 이를 Two-Sample Test에 적용시키겠다는 것이다. Generative Adversarial Network (GAN) Discriminator 1일 때 real, 0일 때 fake 를 구별하는 2진 분류기가 있다고 하자. 그렇게 되면 우리가 사용할 통계량은 이 분류기의 loss일 것이다.(loss가 적으면 잘 구별한다는 것이고, 높으면 구별하기 어렵다는 것으로 해석할 수 있다.) 땨라서 이 분류기의 목표는 이 통계량을 최대화하거나 loss를 최소화하는 것이다. $$ \begin{aligned} \max_{D_\phi} V(p_\theta, D_\phi) &amp;= \mathbb{E_{x \sim p_{\text{data}}}}[\log D_\phi(x)] + \mathbb{E_{x \sim p_\theta}}[\log(1 - D_\phi(x))] \\ &amp;\approx \sum_{x \in S_1} \log D_\phi(x) + \sum_{x \in S_2} \log(1 - D_\phi(x)) \end{aligned} $$
$p_\theta$: Fixed generative model $p_\text{data}$: 데이터 셋 $D_\phi(x)$: Discriminator 이것은 고정된 생성 모델이 있을 때, 분류기의 목적 함수이다. 따라서 오직 분류기의 최적화 관점만 생각해야한다. 이 분류기는 $S1$에 대해서 1(real, 진짜로 인식)로 , $S2$에 대해서 0(fake, 가짜로 인식)로 잘 분류할 수 있게 학습하도록 한다. 이렇기 때문에 $D_\phi(x)$ 의 값은 샘플 $x$ 가 실제 데이터 분포에 속할 확률을 나타내는 것으로 해석할 수 있다. (데이터 분포와 유사하면 1, 아니면 0이기 때문이다.) $$ D_\theta^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_\theta(x)} $$
그래서 위의 Discriminator 식을 최적화 한다면 위와 같은 식으로 표현할 수 있는데, 이는 x가 Discriminator에 들어왔을 때 전체 분포의 확률 중에 실제 데이터 분포일 확률을 나타낸다. 따라서, 만약 $p_\text{data} = p_\theta$ 라면($p_\text{data}$와 $p_\theta$의 분포가 같다면) 값은 1/2이 나올 것이다. Generator 그렇다면 Discriminator를 속이기 위해 Generator ($p_\theta$)를 최적화 하는 방법을 정의해보자. Flow-model 처럼 유사하게 동작하지만, 역변환은 필요 없다. 쉬운 분포 p(z)에서 z를 뽑고 $G_\theta$ 에 넣어 x를 생성하는 것에 초점이 맞춰져 있다.]]></description>
</item>
<item>
    <title>[Paper Review]Generative Adversarial Nets(GAN)</title>
    <link>https://goodyoung.github.io/posts/paper/gan/</link>
    <pubDate>Mon, 02 Sep 2024 14:52:43 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/gan/</guid>
    <description><![CDATA[개요 VAE논문 다음으로 Generative분야에서 기초가 되는 논문인 GAN에 관한 리뷰를 할 것이다. Introduction 다양한 data환경에서 확률 분포를 잘 표현할 수 있는 풍부하고 계층적인 모델을 발견하는 것이 딥러닝의 잠재력이다. 딥러닝의 두드러진 성공 사례는 풍부한 감각 input을 class label로 매핑하는 판별 모델이다. 이런 성공은 backpropagation과 dropout의 algorithm, gradient를 가진 조각별 선형적 유닛들(ReLU)에 기반을 두고 있다. 그동안 Deep generative model은 큰 영향을 끼치진 못했다. Likelihood에 대한 추정과 관련된 전략에서 발생하는 계산을 근사화하는 것이 어렵고, 조각별 선형적 유닛들을 활용하여 generative에서 활용하는 것도 어렵기 때문이다. 따라서 본 논문은 이런 어려움들을 피할 수 있는 추정 절차를 제안한다. 제안된 adversarial nets은 generative model은 discriminative model과 맞서게 된다. Discriminative model은 model 분포에서 나온 것인지 data 분포에서 나온 것인지 구분하는 방법을 학습한다. Generative model은 위조자와 비슷하게 생각할 수 있다. 이는 fake 지폐를 만들어 경찰의 탐지 없이 사용하려고 한다. 반면 discriminative model은 경찰에 비유할 수 있다. 이런 fake 지폐를 탐지하려고 한다. 이런 상황 속에서 두개의 model이 자신들의 방법을 개선하려고 한다. 결국 위조지폐가 진짜 지폐와 구별되지 않게 되게 된다. 이 framework는 다양한 모델과 최적화 방법에 대해서 특정한 training algorithm을 도출할 수 있다. Generative 모델이 MLP을 통해 random noise를 통과시켜 sample을 생성하는 특수한 경우를 탐구합니다. 이런 특수한 경우를 적대적 신경망(Adversarial Nets)이라고 부른다. Generative, discriminative model 둘 다 backpropagation을 통하여 업데이트를 하며 generative model을 통하여 sampling을 할 땐 forward만 수행한다. Adversarial nets 이젠 Adversarial nets에 대한 설명을 할 것 이다. Adversarial modeling framework는 both multilayer perceptron 일 때 곧바로 적용할 수 있다. Data x에 $p_g$ 분포를 배우기 위하여 사전에 noise 변수 $p_z(z)$를 선언한다. 그 후 $G(z;\theta_g)$의 data space에 매핑을 하게 된다. 이 때 $G$는 파라미터 $\theta_g$를 지닌 미분 가능한 함수이다. 또한 두번째 multilayer perceptron이고 output이 하나의 scalar가 나오는 $D(x;\theta_d)$가 있게 된다. 이때 $D(x)$는 $p_g$분포와는 다른 $x$로부터 나왔을 확률을 representation한다. 이때 나온 output(single scalar)이 1: real ~ 0: fake일 확률을 나타낸다. 본 논문에서 나오는 훈련은 $D$는 훈련 샘플과 $G$에서 나온 샘플 (fake image) 모두에 대해 올바른 label(real or fake)을 할당하는 확률을 최대화하도록 훈련이 된다. 또 동시에 $G$를 $log(1-D(G(z))$ 를 사용하여 최소화 하는 방식으로 훈련을 하게 된다. 위의 내용을 총 정리한 $V(G,D)$ 의 목적 함수(Object Function)를 나타내면 아래의 식이다. $$\min_G \max_D V(D, G) = E_{x \sim p_{\text{data}}(x)} [\log D(x)] + E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$$
위의 Adversarial net을 나타내는 목적 함수를 좀 더 살펴 보도록 할 것 이다. $\min_G \max_D V(D, G)$ 의 부분을 먼저 살펴보자면 $V(D, G)$ 식에서 $G$ 는 낮추고자 하고 $D$ 는 높이고자 하는 것을 알 수 있다. $D$의 목표는 진짜 데이터에 대해 높은 확률을 부여하고 가짜 데이터에 대해 낮은 값을 부여하도록 하는 역할이기 때문에 최대화를 목표로 한다. $G$의 목표는 생성된 데이터가 $D$에게 진짜 데이터 처럼 보이게 하는 역할이기 때문에 최소화를 목표로 한다. $E_{x \sim p_{\text{data}}(x)} [\log D(x)]$ 은 원본 데이터 $p_\text{data}(x)$에서 한개의 데이터인 $x$를 sampling을 하여 그 $x$를 $D$에 넣은 값에 $log$를 취한 값의 기대값을 나타낸다. 따라서 앞서 13번을 보면 사전에 noise 변수인 $p_z(z)$ 를 선언한다고 나와 있다. 따라서 $E_{z \sim p_z(z)} [\log(1 - D(G(z)))]$ 의 식은 하나의 noise 분포 $p_z(z)$ 에서 한 값을 sampling하여 그 $x$ 를 생성자 $G$ 에 넣고 가짜 이미지를 만든 다음에 $D$에 넣고 $1-D$의 형태로 만든 값에 $log$를 취한 값의 기대값을 나타낸다. 그래서 이런 두 항을 $D$의 관점에서 봤을 때 maximize하기 때문에 원본 데이터(x)에 대해서는 real(1)을 찾을 수 있도록 하고 반면에 가짜 이미지(z)가 들어왔을 때는 그 이미지가 fake(0)인지 분류할 수 있게 가능하게 한다.]]></description>
</item>
</channel>
</rss>
