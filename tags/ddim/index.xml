<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>DDIM - Tag - Good Young</title>
        <link>https://goodyoung.github.io/tags/ddim/</link>
        <description>DDIM - Tag - Good Young</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 13 Feb 2025 15:14:36 &#43;0900</lastBuildDate><atom:link href="https://goodyoung.github.io/tags/ddim/" rel="self" type="application/rss+xml" /><item>
    <title>[Paper Review]Denoising Diffusion Implicit Models(DDIM)</title>
    <link>https://goodyoung.github.io/posts/paper/ddim/</link>
    <pubDate>Thu, 13 Feb 2025 15:14:36 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/ddim/</guid>
    <description><![CDATA[ 개요 DDPM 이후 DDPM의 샘플링 속도를 개선하여 보다 빠른 생성이 가능한 DDIM에 대하여 논문 리뷰 할 것이다. Introduction Deep generative model은 여러 분야에서 높은 품질의 샘플을 생성할 능력을 보여준다. GAN은 다른 어떤 생성 모델보다 더 높은 품질의 샘플을 생성 할 수 있다. 그러나 GAN은 매우 특정한 최적화 기법과 네트워크 구조를 선택해야 돼서, data 분포가 여러 모드를 충분히 학습하지 못하는 현상이 발견된다. 따라서 최근 연구에선 DDPM 같은 생성 모델이 GAN과 유사한 성능을 생성할 수 있다. DDPM과 같은 모델들은 adversarial training을 하지 않고, gaussian noise가 다양한 정도로 추가된 샘플을 복원하도록 denoising autoencoder를 훈련하는 방식으로 동작한다. 샘플링 과정은 Markov chain 방식을 따르며, 처음에는 화이트 노이즈에서 시작하여 점점 denoising하여 이미지를 복원하는 방식으로 진행된다. 이는 Langevin dynamics와 forward diffusion과정을 역전시키는 두 가지 방식으로 구현이 된다. DDPM과 같은 모델들은 샘플을 생성하는데 많은 반복이 필요하다는 것이 문제점이다. 따라서 GAN에 비하여 속도가 매우 느리다. 또한 이미지의 크기가 커질수록 더욱 심각해진다. 따라서 본 논문은 DDPM과 GAN의 효율성 차이를 줄이기 위해 DDIMs을 제안한다. DDIM은 암시적 확률 모델(implicit probabilistic models)(Mohamed &amp; Lakshminarayanan, 2016)과 밀접한 관련이 있다. 암시적 확률 모델은 DDPM과 동일한 목적 함수로 훈련된다는 점에서 유사하다. 본 논문에서는 기존 DDPM의 Markov Chain 확산 과정을 Non-Markovian 확산 과정으로 일반화 한다. Non-Markov를 사용하면 짧은 마르코프 체인을 구성할 수 있게 된다. 이는, 샘플링 속도를 획기적으로 줄일 수 있게 된다. 따라서 동일한 신경망(목적 함수)를 사용하면서도, Markov가 아닌 다양한 확산 과정을 선택함으로써 더욱 넓은 범위의 생성 모델을 자유롭게 선택할 수 있다. 또한, DDIM은 DDPM과 비교하여 세 가지의 장점을 지닌다.
샘플링 속도를 더욱 가속화 해도 DDPM과 비교하여 더 뛰어난 샘플 품질을 제공한다. DDIM에 일관성 속성이 있기 때문에 초기 latent variable에서 출발하여 높은 수준의 특징을 공유하게 된다. 초기 latent variable을 조작하여 의미적으로 유의미한 이미지 보간을 수행할 수 있다. Background 해당 부분에서는 DDPM의 전반적인 내용에 대해서 설명을 한다. 이는 이전의 글에 더 자세히 나와 있다. DDPM의 샘플링 속도가 너무 느려 이를 해결하기 위해 DDIM이 등장하여 속도를 개선한다. Variational Inference For Non-Markovian Forward Processes 생성 모델은 inference process의 역(reverse)을 추정하기 때문에, 많은 반복을 줄이기 위해 inference process에 대한 새로운 접근이 필요하다.
DDPM의 핵심적인 관찰은 DDPM의 목적함수가 오직 marginal probability distribution(주변 확률 분포) $q(x_t \mid x_0)$에만 의존하고 joint distribution $q(x_\text{1:T}\mid x_0)$엔 직접적으로 의존하지 않는다는 점이다.
즉, 동일한 주변 확률 분포를 가지는 다양한 분포가 존재하기 때문에, Markovian 특성을 갖지 않는 대체적인 생성 과정을 설계할 수 있다.
Non-Markovian 추론 과정을 사용하더라도 DDPM과 동일한 대리 목적 함수를 유지할 수 있다. Non-Markovian Forward Porcesses ]]></description>
</item>
</channel>
</rss>
