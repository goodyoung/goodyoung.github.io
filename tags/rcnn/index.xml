<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>RCNN - Tag - Good Young</title>
        <link>https://goodyoung.github.io/tags/rcnn/</link>
        <description>RCNN - Tag - Good Young</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 17 Jul 2024 18:19:31 &#43;0900</lastBuildDate><atom:link href="https://goodyoung.github.io/tags/rcnn/" rel="self" type="application/rss+xml" /><item>
    <title>[Paper Review]Fast R-CNN</title>
    <link>https://goodyoung.github.io/posts/paper/fast-rcnn/</link>
    <pubDate>Wed, 17 Jul 2024 18:19:31 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/fast-rcnn/</guid>
    <description><![CDATA[개요 Object Detection분야에서 널리 사용되는 딥러닝 모델인 Fast R-CNN에 대한 논문 리뷰를 해보려고 한다. 이번 Fast R-CNN은 R-CNN의 단점을 고안하고자 나온 모델이다. Introduction 본 논문이 나온 시기의 detection은 classification보다 더 복잡한 모델로 해결을 했는데 multi stage pipeline을 가진 모델들은 slow하고 inelegant하다. 이런 complexity는 object의 localization 때문에 일어난다. 이는 두가지 문제점을 지니고 있는데 수많은 후보 object들이 제안된다 이 후보들이 정확한 localization을 하기 위해 다시 refine해야 된다. 따라서 본 논문에서는 이전 R-CNN과는 달리 single-stage(분류하고 공간 정보를 강화하는) 훈련 기법을 제안한다 VGG16을 사용했으며 R-CNN보다 9배 빠르고, SppNet보다 3배 빠르다. 그리고 논문에서는 이전 모델인 R-CNN의 몇가지 단점을 설명한다. 훈련 시 multi-stage pipeline이다.
object proposals을 cnn을 통하여 특징 추출을 하고 그것들의 feature를 svm이 분류를 해주고 마지막으로 bounding box regressor를 통해 3단계를 거친다. 훈련 시 공간과 시간적으로 낭비가 된다.
svm, bounding-box regressor를 할 때, 오버헤드가 심하다 마지막으로 이미지를 test를 할 때 이미지당 47초가 걸린다.
R-CNN은 계산량 공유 없이 각각의 object마다 계산을 해서 오래걸린다. SppNet은 이러한 점을 극복했다. SppNet은 전체 이미지의 feature map을 계산 한 후 거기서 각각의 object proposal을 분류 한다. proposal을 위해 feature에서 고정된 크기로 추출한다. 그리고 다중 출력 크기로 추출한 다음 그것을 spatial pytamid pooling에서 합친다. 이를 통해 테스트 시간(10~100배)과 훈련 시간(3배)을 크게 줄일 수 있습니다. 근데 이러한 SppNet도 단점이 있다. 여러 단계를 거친 pipeline이라는 것이다. 하지만 R-CNN과 달리, SppNet에서 제안된 미세 조정 알고리즘은 공간 피라미드 풀링 이전의 합성곱 층들을 업데이트할 수 없다. 이러한 제한 사항(고정된 합성곱 층들)은 매우 깊은 네트워크의 정확도를 제한한다. 따라서 이런 단점들을 보안하고자 Fast R-CNN을 고안했다. Fast R-CNN은 몇가지 장점이 있다. 다른 것들 보다 높은 mAP(점수) multi task loss를 사용한 single-stage 훈련 기법 모든 network layer가 update된다. 특징 추출에 disk storage가 필요하지 않다. 사진은 Fast R-CNN의 architecture의 overview이다. Fast R-CNN은 input으로 전체 이미지를 넣고 그와 함께 object proposal (selective search로 구해둠)의 set을 같이 넣는다. 그럼 network는 여러 conv를 거쳐 conv feature map을 생성한다. 그럼 각각의 RoI pooling layer은 추출한다. 고정된 크기의 feature vector가 생성이 된다. (ROI들은 각각 다른 크기를 지녔기 때문) 그 후 Fully Connected (FC)층으로 가며 이것은 또 2가지 분기로 나뉜다. 하나는 (K +1 class의)softmax 확률 추정치를 구한다 다른 하나는 각 K 개의 객체 클래스에 대해 4개의 실수 값을 출력합니다. 4개의 값 집합 각각은 K 개 클래스 중 하나에 대한 세밀한 바운딩 박스 위치를 인코딩합니다. RoI pooling layer RoI pooling layer는 max pooling을 사용하여 region of interest(RoI)를 고정된 크기의 spatial small feature map으로 변환한다. Selective search를 통해 resion proposal을 얻게 된다. 이때 spatial small feature map의 $H, W$의 값은 특정 RoI와는 독립적인 하이퍼 파라미터이다. RoI는 합성곱 특징 맵(conv feature map) 내의 사각형 창을 의미합니다. 각각의 RoI는 **(r,c,h,w)**의 특징을 지니고 있는데 **(r,c)**는 top-left를 의미하고 height와 width는 (h,w)를 의미한다. RoI max pooling은 $h × w$ 크기의 RoI 창을 $h/H × w/W$ 크기의 grid를 만든다. 그 후 grid에 max pooling하여 해당 $H × W$ 크기의 출력 grid 셀에 넣는 방식으로 동작합니다. Pooling은 표준 max pooling에서처럼 각 feature map channel에 독립적으로 적용됩니다. 이는 Sppnet에서 하나의 pyramid level만 사용한 것과 동일하다. 결론적으로 원래 이미지를 CNN에 통과시킨 후 나온 feature map에 이전에 생성한 RoI를 projection시키고, 이 RoI를 FC layer input 크기에 맞게 고정된 크기로 변형할 수가 있다. 이를 통해 RCNN 처럼 2000번의 CNN연산 필요 없이, 단 한번의 연산으로 속도를 대폭 높일 수 있게 된다.]]></description>
</item>
<item>
    <title>[Paper Review]Rich feature hierarchies for accurate object detection and semantic segmentation</title>
    <link>https://goodyoung.github.io/posts/paper/r-cnn/</link>
    <pubDate>Wed, 10 Jul 2024 16:01:50 &#43;0900</pubDate>
    <author>GoodYoung</author>
    <guid>https://goodyoung.github.io/posts/paper/r-cnn/</guid>
    <description><![CDATA[개요 Object Detection분야에서 널리 사용되는 딥러닝 모델인 RCNN에 대한 논문 리뷰를 해보려고 한다. RCNN은 이미지 내에서 객체를 정확하게 탐지하고 분류하는 문제를 해결하기 위해 개발되었다. Abstract 최근 몇 년간 Object Detection 분야가 정체 상태에 있었다. 그동안 가장 성능이 좋은 방법론은 low-level image feature와 high-level context를 섞는 것이다. 본 논문에서는 간단하고 확장 가능한 object-algorithm을 제시한다. 이는 VOC2012에서 SOTA 결과 대비 30%나 향상된 mAP를 보여준다. 본 논문에서는 두가지 방법을 사용한다 high-capacity cnn을 하위의 region proposal에 적용시킨다. 이를 통해 RCNN이라고 불린다. data가 부족할 때, 사전 학습 된 모델을 도메인 특화 미세 조정을 하면 성능이 크게 향상된다. 따라서 region proposal을 CNN과 결합했기 때문에 R-CNN(Regions with CNN features)라고 한다. Introduction 지난 10년간 visual recognition task에서의 진전은 SIFT와 HOG의 사용에 의존되어 왔다. 둘 다 컴퓨터 비전에서 널리 사용되는 두 가지 이미지 특징 추출 기법이다. SIFT: 다양한 스케일과 회전에 대해 불변인 키포인트와 불변인 특징을 만드는 기법이다. HOG: 이미지의 지역적인 형태나 외곽선을 표현하는 방법으로, 물체 탐지, 특히 사람 탐지에 사용된다. 2010~2012년가지 소폭적인 개선만 이루어 졌다. AlexNet의 개발로 인하여 CNN이 크게 향상이 되었다. 그 후 Classification이 Object Detection의 결과에 어느정도의 영향을 미치는지에 대해 관건이었다. 본 논문은 HOG와 같은 기법들과 비교하여 CNN이 Object Detection 성능을 향상시켰음을 보여준다. 이러한 결과를 얻기 위하여 두가지 문제에 집중하였다. Deep network에서의 localizing object 작은 양의 detection data로 높은 capacity model 훈련하기 Classification과는 달리 Object Detection에서는 localization이 문제이다.이를 해결하기 위한 방법은 2가지 방법이 있다. Regression problem으로 설정 실용적으로 좋지 않다. (30%의 결과가 나온다) Sliding-window detector를 구축 본 논문의 CNN은 좀 더 깊은(다섯 개의 CNN layer) layer를 구축하였는데 이는 높은 spatial resolution을 유지하기 어렵다. 따라서 이는 객체의 정확한 위치를 찾는데 어려움이 있다는 것이고 이 역시 아직 남아있는 과제임을 나타낸다. 본 논문은 첫 번째 문제를 Recognition using region을 통해 해결하려고 한다. 위 그림 처럼 Region-proposal을 통해 2000개의 카테고리를 만들고 이를 CNN을 사용해 고정적인 길이의 특징 벡터를 추출 한다. 이때 입력되는 이미지의 사이즈도 고정되어야 하기 때문에 아핀 변환 등으로 이미지를 추출한 후 입력으로 사용한다. 그 후 이를 선형 SVM으로 분류한다. 이는 영역의 크기에 상관없이 동일한 크기로 변환이 된다. 본 논문에서는 이를 Region-proposal과 CNN을 같이 사용하므로 R-CNN이라고 한다. 본 논문은 두 번째의 문제를 사전 학습 미세조정에 따른 비지도 사전 훈련을 허용하여 해결했다. ILSVRC인 임의의 큰 데이터로 지도 학습을 한 모델에 PASCAL의 작은 데이터를 domain 특화 미세 조정을 하는 패러다임을 제시한다. 이를 통해 결과가 33%가 올랐다. Object Detection with R-CNN 크게 3가지 모듈을 포함하고 있다. Category-independent region proposal Large Convolutional neural network Class specific linear SVM 본 논문에서는 Region-proposal을 생성하기 위해 Selective Search방법을 이용한다.
Selective Search란 색상, 질감, 영역크기 등을 이용해 non-objective segmentation을 수행한다. 이 작업을 통해 좌측 제일 하단 그림과 같이 많은 small segmented areas들을 얻을 수 있다. Bottom-up 방식으로 small segemented areas들을 합쳐서 더 큰 segemented areas들을 만든다. 두 번째의 작업을 반복하여 최종적으로 2000개의 region proposal을 생성한다. 또한 본 논문에서는 AlexNet의 모델을 사용하여 $227 * 227$의 고정적 크기인 이미지를 받게 한다.
따라서 임의의 다양한 크기를 가진 영역들을 고정된 크기로 바꾸는 작업인 warping의 과정을 거친다. 2000장의 region-proposal이 selective-search에 의해 나오면 ground-truth와 IoU를 비교하여 0.5 보다 큰 경우를 positive로 구분하고 그 외를 negative로 구분한다. 또한 positive랑 negative가 겹치는 객체를 정확히 탐지하기 위하여 IoU overlap threshold를 사용하여 IoU 임계치를 주어 객체 탐지 성능을 높인다.]]></description>
</item>
</channel>
</rss>
